<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[风(三)]]></title>
    <url>%2F2017%2F09%2F04%2F%E9%A3%8E_%E4%B8%89%2F</url>
    <content type="text"><![CDATA[你知道，压马路是个体力活，没有吃的我走不动. 所以我们就顺便去逛了个超市，嗯，我能想到最浪漫的事就是和你一起逛超市，买好吃的。 😬 还好买了吃的，为了找旅馆你都快带我走遍整个北海市了。 你说你非要找到你之前跟你爸妈来北海住的那家旅馆，可把我给累坏了。 不过有吃的我就不跟你计较了，当然我也知道你的心意，不然我早就生气了，像我这么易怒的体质。 哼(｀へ´) 北海除了银滩，最令人难以忘怀的应属我们吃的那家炸酱面了，每天必备，餐餐都吃，也不觉得腻。 你看，就像喜欢了你这么多年。 长这么大没买过站票，却陪你站了两次，就像很多事情以为这辈子都不会做的呢。 北海之行除去那些不开心的，我们都是真正的开心过，快乐过，单纯的，不单纯的，反正都发生了。 那时的你，总是喜欢说，和我在一起，感觉一点都不真实，仿佛像一场梦，怕梦醒来，我就不见了。 你说，我就像从漫画里走出来的少女。 这句话是你在去北海的火车上跟我说的，你现在已经不记得了。 可是我却当真了。 人们常说，说者无意，听者有心。 很多说过的话做过的事，一转身可能就忘了。 那么多的事，遇见过那么多的人，怎么可能会一一记得呢。 可是，那有什么关系呢？我记得就好了啊。 美好的，我都想要收藏着。 你说，和我在一起你才有恋爱的感觉。 你说，和我在一起，就是你最大的梦想。 你说，你的生活没有了我，还有什么意义。 你说，那么多的你说，我却只记得那些夸我的每一句，那些美好的，我都一一珍藏着。 我知道，它们可能都有后缀，因为每一次的争吵，你都会把后缀说出来。 可是，我的记性越来越差了，不想记住太多东西了，只是还是会觉得难过罢了。 我知道，争吵是难以避免的，只是有时候，真的会让人透不过气来。 从前天真的我，无法想象撕心裂肺，痛不欲生，这样的词到底是一种怎样的心境？是你，让我切身体会到了。 也是我，让你费心了。 连呼吸都会痛的日子里，你是不是也会感同身受？ 同是一个人， 他能带你走向天堂，也能让你跌落地狱，最让人无法理解的是，你竟然一点都不恨他，一点也不。 这样的气氛，太过奇怪，还是说点开心的事情吧。 还记得我们从北海回来的火车上做过最幼稚的事吗？ 又一次站着回来的！我现在，很严肃的问你？你到底是不是故意的？你说！ 对一个喜欢了这么多年，心仪已久的女孩子，你觉得自己做得对吗？ 你现在，去找一个女生，你问问她，第一次旅行，叫她陪你站十八个小时，她不打死你，回来我打死你！ 我觉得当时我肯定是站傻了，不然就是真的喜欢你，不然以我的性子，说什么都不愿意站的。 可能真的是脑袋进水了。 我前面所指的幼稚的事不是这个，这个是两个傻子才能干出来事情，是吧，十八，大傻子。 我发现，你在哪里，你都想轻薄我， 你的色狼本质从七星公园就展露无疑，而且一发不可收拾， 无处不在，无孔不入，在火车上你都还想要染指我，你说，你是不是肾虚！ 你肾虚是有原因的，知道吧？ 不过我能想到最幼稚也最浪漫的事，就是我们在火车上，只要火车一进去隧道你就说要亲我，刺不刺激，开不开心？ 哈哈哈哈哈哈(ಡωಡ)hiahiahia 我是开心的，而且是发自内心的开心哦。 我都记得，你是不是忘了！是哪只狗亲的我，你说吧。 以前那只狗还天天打电话给我，现在都没有了，哼！ 12年的夏天，是我们在一起时间最长，最无忧无虑，最开心的，也最喜欢的夏天。 因为你，我开始有点喜欢夏天了。 我一直以来，都讨厌着炎热的夏天，因为它太过于炙热，我认为阳光是有毒的，你却让我对它改变了看法。 那一年的夏天，有那么一个人，他夏了夏人。 夏天里的那片海，我看到了一个人，他对我傻傻的笑着，两个人，不说话也觉得那般美好。 那一年的夏天，桂林的每一个角落，每一条街道，都有我们走过的影子。 那些不可磨灭的痕迹，清晰的刻印在脑海里，放在心上。]]></content>
      <categories>
        <category>飘</category>
      </categories>
      <tags>
        <tag>风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[风(二)]]></title>
    <url>%2F2017%2F09%2F03%2F%E9%A3%8E_%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[我们有一句没一句的说着些什么， 现在都不大记得清了，在说话间，你顺势牵起了我的手， 走过大街穿过小巷，我就这样跟在你的身后，心跳加速地跳动着，手心都出汗了。 你带我来到一间店里，点了一笼包子和饺子，我一点都不饿，看着你狼吞虎咽的样子， 那时的我都没对你翻脸，说明对你是真的很喜欢了。 说到我们的第一次约会，不得不提七星公园，那里有太多记忆里的美好，当然不是所有美好都是单纯的。 记得你为了抱我，故意骗我说有毛毛虫，现在想来，你是很有心机的嘛。 当然也不是每一次约会，我们都能愉快的玩耍，期间也有过争执，每一次的情况都愈演愈烈，谁都不愿意妥协，这里就不一一阐述了，反正都是你的错就对了٩( •̀㉨•́ )و get！哈哈哈哈哈⁽˙³˙⁾◟(๑•́ ₃ •̀๑)◞⁽˙³˙⁾ 其实我最开心的，是你每次见到我都会夸我，不善言辞的你，说的话都是发自内心的，我都信了。 我们第一次旅游，去的北海，记得当时你计划了好久，可是还是没买到票， 你说，你是不是很笨(´▽｀)ノ♪！当时只剩下无座了，你说要不我们坐汽车吧，我去买票。 我说，我不喜欢坐汽车还是坐火车吧。 然后你知道的，两个人傻傻的站了九个小时，可是那时候一点也不觉得累，心里还是乐开了花。 那时候，我感受得到，你是想把好的都给我，是真的想要对我好。 那时候的我们什么都不想，在一起就是最开心的事情。 有点小怀念呢。 言归正传，到达北海已经下午了，白痴的你加上笨拙的我，放着车子不坐，硬是从火车站走到了市区，浪漫吧？ 我们最不缺的就是浪漫的压马路，一条又一条，一段路接着一段路，一处又一处的风景，都把我给晒黑了。 你说，怎么办。]]></content>
      <categories>
        <category>飘</category>
      </categories>
      <tags>
        <tag>风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[风(一)]]></title>
    <url>%2F2017%2F09%2F01%2F%E9%A3%8E_%E4%B8%80%2F</url>
    <content type="text"><![CDATA[应该是论我们走了多少公里的路(ಡωಡ)hiahiahia 写给你的。 不知从何时开始已经不再喜欢用书写文字的方式来表达自己的心情了，或多或少是因为年纪的关系，不过想一下，应该不是，只是太懒罢了，给自己找的借口。 记得你以前总说，我写的文字里找不到关于你的任何影子，你总是告诉我，写点什么吧。 而我只是笑而不应。 很多时候，不是不想写，更多的是不知道从何写起，笨拙如我，写出的文字太过局限，怕是写不出个所以然来。 那些关于我们的美好，怕被我写得乱七八糟，无从下笔。 而那些关于我们不开心的事情，我根本不想提及。 所以，每次下笔却变得不知道要写些什么。 这次要是再不写点什么，怕是要真的写不出什么了。 哈哈哈哈哈哈哈(ಡωಡ)hiahiahia 先说明，此篇凌乱毫无章法，看不懂我也没有办法了。 请往下看， 从2017追溯到2005，这中间我们共享了彼此12年的光阴。 从见字如”面”到”信”手拈来，好奇到了解，始终还是差了点什么，却又说不上来。 那时的我，还是懵懂无知的初中生，你亦只是写字好看的白痴罢了。 与你的相识，只不过是缘于同学之间的书信往来。 而你写在别人信笺背面的字，只一眼，就注定了开始，以至现在的万劫不复。 故事的开始，我只是希望你是一个明媚而不忧伤的美少女，无奈你却是情商负值二百五的白痴少年，而我也只不过是中二病晚期的笨蛋罢了。 虽然开始得并不顺利，磕磕碰碰总算是让姐姐给成功拿下了，虽然那时姐姐还不是姐姐，姐姐还是个男生。 嗯，在下李叶涛，不知有何贵干？ 容我笑一下，哈哈哈哈哈哈哈 好了，回归正题，这不是你想要的文艺篇，所以别一副生无可恋的样子，好不啦？ 冥冥中的相遇，注定了之后的种种，通过书信，我们走进了彼此想象的世界，却走不进彼此现实的生活。 从此的每天，都盼着你的来信，忐忑的，开心的心情，不言而喻。 字里行间都是简单纯真的童趣，而我每次读你的信，都会一个人傻笑好久，好久。 那是一种课堂上想起你，嘴角就不自觉上扬的开心。 初中生活，承载了美好的你我，却留不住短暂的时光，回头发现剩下来的只有往来的书信，厚厚一沓，之后了无音讯。 高中生活，不紧不慢，却还是让我不经意会想起你来，原来，有些人，不管在哪，都是会有人惦记的呢。 只是你不知道罢了。 我尝试着盲目写信，却不想真的得到了回应，现在想来当时太过开心，以至于忘记了对你提出控诉，为什么，你只字未提？ 之后，我们还是像中学那般好。 可你的点到为止，让我以为只是朋友的那种好，后来的发展，是我始料未及的，慢慢我们开始了疏远，到最后，渐渐的没有了联系。 大学的生活，枯燥无味，让人提不起半点兴趣，而命运之轮又开始在我们之间运转。 当我问出那句，你喜欢我吗？仿佛用尽了我所有的运气，才得来了心中想要的回应。 那一晚辗转反侧，兴奋得不能入眠，心里的涟漪泛起一层又一层，情不自禁，不能自已。 你看，你总说我学不会主动，可是我们之间最重要的三次都是我握有的主动权。 第一次，初中相识，第二次，高中再见，第三次，大学在一起。 我们开启了肆无忌惮的恋爱模式，毫无顾忌的样子，简直令人发指。 虽然有言于过实的成分。 那时的我们，开心并快乐着，不会去想太多，却还是会争吵，我们的争吵就像小孩子之间前一秒还在闹，后一秒转身就要和好。 你看你，多笨啊。 我们第一次的约会你还记得吗？我一下车就看见一个特别二的人对着我傻笑半天然后说他饿了要去吃东西，这剧情展开，仿佛我走错了片场。]]></content>
      <categories>
        <category>飘</category>
      </categories>
      <tags>
        <tag>风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单的游戏服务器框架demo(源码已经放在GitHub)]]></title>
    <url>%2F2017%2F08%2F27%2F%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A1%86%E6%9E%B6demo(%E6%BA%90%E7%A0%81%E5%B7%B2%E7%BB%8F%E6%94%BE%E5%9C%A8GitHub)%2F</url>
    <content type="text"><![CDATA[GitHubGitHub地址 框架简介一个简单的游戏服务器框架demo 框架概要采用C++开发，依赖 : boost库 MySQL数据库 google-glog日志记录框架 curl库 主要处理游戏客户端和游戏数据库的数据交换。通信采用socket发送协议包的方式，服务器根据协议包命令码去做相应的逻辑处理，并将处理结果返回给游戏客户端，即完成了前后端的数据交换。 框架处理流程：客户端连接→ 服务器分配线程池中的线程处理→ 线程将协议数据递交给Worker → Worker调用统一协议处理逻辑Process开始处理→ Process对协议命令码分类，并将协议包内容递交给相应的业务类→ 业务类处理完成后调用统一处理逻辑Process处理完成→ Worker将返回数据递交给线程并返回给客户端 协议处理流程：客户端初次连接服务器，发送心跳→ 服务器返回连接成功状态→ 客户端发起本次协议→ 业务类处理数据库操作并将数据返回给客户端 他日将改进之处 降低模块间耦合度 新业务协议的添加略显繁琐, business模块可以遵循开闭原则来适当重构 编写维护工具 数据传输协议待优化 编写测试工具]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>boost</tag>
        <tag>mysql</tag>
        <tag>glog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe服务端笔记(二)]]></title>
    <url>%2F2017%2F07%2F29%2Fkbe%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%AC%94%E8%AE%B0(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[FixedMessages：FixedMessages存储所有固定消息（有显示制定id的消息，当然，这并不表示非固定消息就没有id，也是有的，只是不是显示制定的）。 它的构造地方如下（lib/network/message_handler.cpp）：123456789101112MessageHandlers::MessageHandlers():msgHandlers_(),msgID_(1),exposedMessages_()&#123; g_fm = Network::FixedMessages::getSingletonPtr(); if(g_fm == NULL) g_fm = newNetwork::FixedMessages; Network::FixedMessages::getSingleton().loadConfig(&quot;server/messages_fixed.xml&quot;); messageHandlers().push_back(this);&#125; 意即MessageHandlers构造的时候，如果它还没构造，那就构造。它的初始化（配置）是由loadConfig接口来完成的，代码见上。 loginapp Loginapp组件主要用来处理账户登录/注册的业务 消息与handler映射的建立：两次包含xxx_interface.h，实现声明和定义：每个app组件的接口定义都在xxxapp_interface.cpp中开始，代码如下：123456789#include&quot;loginapp_interface.h&quot;#defineDEFINE_IN_INTERFACE#defineLOGINAPP#include&quot;loginapp_interface.h&quot;namespaceKBEngine&#123;namespaceLoginappInterface&#123;&#125;&#125; 所有的戏法都是通过包含loginapp_interface.h前后定义了DEFINE_IN_INTERFACE和LOGINAPP来完成的。第一次的包含就是各种变量，类的声明（当然也有一些类是声明类时使用类inline函数定义完成了，比如MESSAGE_ARGS0/1/2……）。我们看看loginapp_interface.h中的代码： 消息与handlers的存储首先是这一句：NETWORK_INTERFACE_DECLARE_BEGIN(LoginappInterface)此句展开的话声明和定义了Network::MessageHandlers messageHandlers（记住它们都在LoginappInterface命名空间内），展开宏之后的代码看起来像这样（是的，你的眼睛是好的，没有}闭合）：声明：12345namespaceLoginappInterface &#123;extern Network::MessageHandlers messageHandlers;定义：namespaceLoginappInterface &#123; Network::MessageHandlers messageHandlers; 消息与handle建立映射然后是这一句：LOGINAPP_MESSAGE_DECLARE_ARGS0(importClientMessages, NETWORK_FIXED_MESSAGE)此句展开的话分明声明和定义了一个importClientMessagesLoginappMessagehandler0的类，这个类继承自Network::MessageHandler，这里就是实现了handle的虚函数接口；声明和定义了importClientMessagesLoginappMessagehandler0的一个名为importClientMessages的全局变量；声明和定义了importClientMessagesArgs0的类，这个类继承自Network::MessageArgs。我们一个个地分析一下：首先展开下面的宏：1LOGINAPP_MESSAGE_DECLARE_ARGS0(importClientMessages, NETWORK_FIXED_MESSAGE) 之后是这样：12345678910111213141516#defineLOGINAPP_MESSAGE_DECLARE_ARGS0(NAME, MSG_LENGTH) \LOGINAPP_MESSAGE_HANDLER_ARGS0(NAME) \NETWORK_MESSAGE_DECLARE_ARGS0(Loginapp, NAME, \ NAME##LoginappMessagehandler0, MSG_LENGTH)展开LOGINAPP_MESSAGE_HANDLER_ARGS0(NAME)之后分别得到importClientMessagesLoginappMessagehandler0的声明和定义：声明：classimportClientMessagesLoginappMessagehandler0 : public Network::MessageHandler&#123;public:virtualvoidhandle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s);&#125;;定义：voidimportClientMessagesLoginappMessagehandler0::handle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s)&#123; KBEngine::Loginapp::getSingleton().importClientMessages(pChannel);&#125; （handle/handler，傻傻分不清楚。。。这里的handle是xxxApp中真正用来处理这个消息的接口，而这里的handler提供一个中间层的作用，集中处理一些通用的工作，可以将耦合减少一点）上面完成了相当于是importClientMessages消息的handler的声明和定义，下面则将这个类实例化之后添加到messageHandlers：12345#defineNETWORK_MESSAGE_DECLARE_ARGS0(DOMAIN, NAME, MSGHANDLER, \ MSG_LENGTH) \ NETWORK_MESSAGE_HANDLER(DOMAIN, NAME, MSGHANDLER, MSG_LENGTH, 0)\ MESSAGE_ARGS0(NAME) \ 展开NETWORK_MESSAGE_HANDLER(DOMAIN, NAME, MSGHANDLER, MSG_LENGTH, 0)之后得到importClientMessages的handler类（importClientMessagesLoginappMessagehandler0）的名为importClientMessages的全局变量（不过欣慰的是他们都在各自的XXXInterface命名空间内）。声明：externconstimportClientMessagesLoginappMessagehandler0&amp;importClientMessages; 定义：12importClientMessagesLoginappMessagehandler0* pimportClientMessages = static_cast&lt;importClientMessagesLoginappMessagehandler0*&gt;(messageHandlers.add(&quot;Loginapp::importClientMessages&quot;,new importClientMessagesArgs0, NETWORK_FIXED_MESSAGE, newimportClientMessagesLoginappMessagehandler0);constimportClientMessagesLoginappMessagehandler0&amp;importClientMessages = *pimportClientMessages; 下面的MESSAGE_ARGS0(NAME)展开后对importClientMessagesArgs0进行了声明和定义（其他它声明的时候就已经完成了全部的定义），声明的时候就是个空语句：声明兼定义：1234567891011121314151617181920212223classimportClientMessagesArgs0 : public Network::MessageArgs&#123;public:importClientMessagesArgs0() :Network::MessageArgs() &#123;&#125; ~importClientMessagesArgs0() &#123;&#125;staticvoidstaticAddToBundle(Network::Bundle&amp;s) &#123; &#125;staticvoidstaticAddToStream(MemoryStream&amp;s) &#123; &#125;virtual int32 dataSize(void) &#123;return 0; &#125;virtualvoidaddToStream(MemoryStream&amp;s) &#123; &#125;virtualvoidcreateFromStream(MemoryStream&amp;s) &#123; &#125;&#125;; 唯一需要小注意一下的就是importClientMessagesArgs0的声明（兼定义）是和importClientMessagesLoginappMessagehandler0的实例的声明和定义是错开的，因为后者实例化添加到messageHandlers的时候需要new一个importClientMessagesArgs0的实例。 流程的伪代码稍微整理一下之后，使用LOGINAPP_MESSAGE_HANDLER_ARGSn建立一个消息到handler的映射的代码很像是这样： 声明：（第一次包含loginapp_interface.h产生的代码） 12345678910111213141516171819202122232425262728293031classimportClientMessagesLoginappMessagehandler0 : public Network::MessageHandler&#123;public:virtualvoidhandle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s);&#125;;externconstimportClientMessagesLoginappMessagehandler0&amp;importClientMessages;classimportClientMessagesArgs0 : public Network::MessageArgs&#123;public:importClientMessagesArgs0() :Network::MessageArgs() &#123;&#125; ~importClientMessagesArgs0() &#123;&#125;staticvoidstaticAddToBundle(Network::Bundle&amp;s) &#123; &#125;staticvoidstaticAddToStream(MemoryStream&amp;s) &#123; &#125;virtual int32 dataSize(void) &#123;return 0; &#125;virtualvoidaddToStream(MemoryStream&amp;s) &#123; &#125;virtualvoidcreateFromStream(MemoryStream&amp;s) &#123; &#125;&#125;; 定义：（定义DEFINE_IN_INTERFACE和LOGINAPP之后第二次包含loginapp_interface.h产生的代码） 1234567891011voidimportClientMessagesLoginappMessagehandler0::handle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s)&#123; KBEngine::Loginapp::getSingleton().importClientMessages(pChannel);&#125;importClientMessagesLoginappMessagehandler0* pimportClientMessages = static_cast&lt;importClientMessagesLoginappMessagehandler0*&gt;(messageHandlers.add(&quot;Loginapp::importClientMessages&quot;,newimportClientMessagesArgs0, NETWORK_FIXED_MESSAGE,newimportClientMessagesLoginappMessagehandler0);constimportClientMessagesLoginappMessagehandler0&amp;importClientMessages = *pimportClientMessages; 消息id：固定消息与非固定消息要接着v0.0.3的分析继续写，回过头来要看之前写的东西说实话自己都有点难以理解。。。不过出于幸运或者努力，总算是看懂了;-(，读源代码（感觉特别是C++）本来就不是件容易的事，所以读源代码一定要做好长期战斗的准备。上面我们分析到了，其实一个消息，就是由这样一个宏来和它的handle建立链接的：LOGINAPP_MESSAGE_DECLARE_ARGS0(importClientMessages, NETWORK_FIXED_MESSAGE)通过上面的分析，我们得知，实际上建立消息和handle映射，起到核心作用的接口是messageHandlers.add(xxx, xxxx)，所以我们跟进去看看（lib/network/message_handler.cpp）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869MessageHandler* MessageHandlers::add(std::stringihName, MessageArgs* args, int32msgLen, MessageHandler* msgHandler)&#123; if(msgID_ == 1) &#123; //printf(&quot;\n------------------------------------------------------------------\n&quot;); //printf(&quot;KBEMessage_handlers begin:\n&quot;); &#125; //bool isfixedMsg = false; FixedMessages::MSGInfo* msgInfo = FixedMessages::getSingleton().isFixed(ihName.c_str()); if(msgInfo == NULL) &#123; while(true) &#123; if(FixedMessages::getSingleton().isFixed(msgID_)) &#123; msgID_++; //isfixedMsg = true; &#125; else &#123; break; &#125; &#125;; msgHandler-&gt;msgID = msgID_++; &#125; else &#123; msgHandler-&gt;msgID = msgInfo-&gt;msgid; &#125; msgHandler-&gt;name = ihName; msgHandler-&gt;pArgs = args; msgHandler-&gt;msgLen = msgLen; msgHandler-&gt;exposed = false; msgHandler-&gt;pMessageHandlers = this; msgHandler-&gt;onInstall(); msgHandlers_[msgHandler-&gt;msgID] = msgHandler; if(msgLen == NETWORK_VARIABLE_MESSAGE) &#123; //printf(&quot;\tMessageHandlers::add(%d): name=%s, msgID=%d, size=Variable.\n&quot;, // (int32)msgHandlers_.size(), ihName.c_str(), msgHandler-&gt;msgID); &#125; else &#123; if(msgLen == 0) &#123; msgHandler-&gt;msgLen = args-&gt;dataSize(); if(msgHandler-&gt;type() == NETWORK_MESSAGE_TYPE_ENTITY) &#123; msgHandler-&gt;msgLen += sizeof(ENTITY_ID); &#125; &#125; //printf(&quot;\tMessageHandlers::add(%d): name=%s, msgID=%d, size=Fixed(%d).\n&quot;, // (int32)msgHandlers_.size(), ihName.c_str(), msgHandler-&gt;msgID, msgHandler-&gt;msgLen); &#125; //if(isfixedMsg) // printf(&quot;\t\t!!!message is fixed.!!!\n&quot;); returnmsgHandler;&#125; 大意可以理解为，首先看看消息名称是不是一个固定消息，我们跟进去看看（lib/network/fixed_messages.cpp）：123456789101112131415161718192021222324252627FixedMessages::MSGInfo* FixedMessages::isFixed(constchar* msgName)&#123; MSGINFO_MAP::iteratoriter = _infomap.find(msgName); if(iter != _infomap.end()) &#123; MSGInfo* infos = &amp;iter-&gt;second; returninfos; &#125; returnNULL;&#125;//-------------------------------------------------------------------------------------boolFixedMessages::isFixed(MessageIDmsgid)&#123; MSGINFO_MAP::iteratoriter = _infomap.begin(); while (iter != _infomap.end()) &#123; FixedMessages::MSGInfo&amp;infos = iter-&gt;second; if(infos.msgid == msgid) returntrue; ++iter; &#125; returnfalse;&#125; 固定消息通过通读FixedMessages（fixed_message.h/.cpp）可以看到这个_infomap是在loadConfig中建立的，这个_infomap就是所谓的固定消息（fixed message）与其id的映射表。loadConfig就是检视server/messages_fixed.xml，将其中的消息名称与其id关联建立这个映射表。我们继续接着看MessageHandlers::add接口。 非固定消息对于isFixed为假的消息（非固定消息），则为其生成一个id（随着调用add的次序依次递增），这个id是在MessageHandlers类中唯一的，而每个组件的MessageHandlers又是处于自己的命名空间内，所以当出现某个组件的非固定消息时，则会为其生成单一组件内唯一的id（但这个id并不是所有组件内唯一的）。于是可能出现这种情况，Loginapp::xxxx与Dbmgr::yyyy都是非固定消息，但他们却有着同样的消息id，此时若有其他组件发送其中任一消息给其他组件，接受消息的组件将无法识别到底是Loginapp::xxxx或者是Dbmgr::yyyy。当然，只要我们将非固定消息发送给所属的组件，则不会有问题（上例中任何组件将Loginapp::xxxx发送给loginapp都是不会出乱子的）。 dbmgr dbmgr组件主要负责数据库相关的事务，比如：账户登录/注册事务；账户充值]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNP（UNIX网络编程）13章到31章笔记整理（结合TLPI和APUE两书的笔记整理）(二)]]></title>
    <url>%2F2017%2F07%2F29%2F%E9%87%8D%E8%AF%BBUNP%EF%BC%88UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%EF%BC%8913%E7%AB%A0%E5%88%B031%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%88%E7%BB%93%E5%90%88TLPI%E5%92%8CAPUE%E4%B8%A4%E4%B9%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%89(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[16章 16.3节 ： 非阻塞connect 有三个用途： 我们想在connect的时候处理其他事情 可以同时建立多个连接 可以通过select设置一个更短一点的超时时间 实现步骤： 用fcntl把套接字设置为非阻塞 处理客户端和服务器都在同一主机上的情况 使用select设置超时，并处理超时情况 处理当连接建立的时候，描述符变为可写；以及当连接建立遇到错误的时候， 描述符变为可写并可读的情况 16.6节 ： 非阻塞accept， 用于解决下面问题： “用select检测socket状态，如果有连接就调用accept，这样如果在select检测到由连接请求，在调用accept之前，这个请求断开了，然后调用accept的时候就会阻塞在哪里，除非这时有另外一个连接请求，如果没有，则一直被阻塞在那里。” 解决方案： 使用select在一个监听套接字准备好要被accept时总是把套接字设置为非阻塞 26章和30章介绍了线程和并发/并行的服务器设计范式，等下篇TLPI/APUE的笔记一起整理吧]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNP（UNIX网络编程）13章到31章笔记整理（结合TLPI和APUE两书的笔记整理）(一)]]></title>
    <url>%2F2017%2F07%2F28%2F%E9%87%8D%E8%AF%BBUNP%EF%BC%88UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%EF%BC%8913%E7%AB%A0%E5%88%B031%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%88%E7%BB%93%E5%90%88TLPI%E5%92%8CAPUE%E4%B8%A4%E4%B9%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%89(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[因为UNP第三部分（第三版13-31章）的内容结合APUE（UNIX环境高级编程）和TLPI（The Linux Programming Interface）来看才能比较清晰，所以笔记整理会穿插很多这两本书的内容 13章引申知识，作业控制以及相关命令： 另注： 注：但是如上方到后台执行的进程，其父进程还是当前终端shell的进程，而一旦父进程退出，则会发送hangup信号给所有子进程，子进程收到hangup以后也会退出。 13.4节：自定义一个daemon_init函数，涉及到知识点为“如何创建一个daemon（守护进程）”，实现步骤如下： fork之后杀掉父进程（此时子进程被init收养）这是为了为下一步setsid做准备，因为只有不是进程组首进程的进程才能调用setsid， setsid，创建一个新的会话并断开与之前的控制终端的关系， 再次fork并杀掉首进程， 这样就确保了子进程不是一个会话首进程， 根据linux中获取终端的规则（只有会话首进程才能请求一个控制终端）， 这样进程永远不会重新请求一个控制终端 清楚进程的umask，确保daemon创建文件和目录时拥有相应的权限 修改进程的当前工作目录， 通常修改到/目录 关闭进程所有不再需要的文件描述符 打开/dev/null使文件描述符0、1、2指向这个设备， 以防止daemon调用在这些描述符上做I/O操作的库函数而不会意外的失败 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &quot;unp.h&quot;#include &lt;syslog.h&gt;#define MAXFD 64extern int daemon_proc; /* defined in error.c */intdaemon_init(const char *pname, int facility)&#123; int i; pid_t pid; if ( (pid = Fork()) &lt; 0) return (-1); else if (pid) _exit(0); /* parent terminates */ /* child 1 continues... */ if (setsid() &lt; 0) /* become session leader */ return (-1); Signal(SIGHUP, SIG_IGN); if ( (pid = Fork()) &lt; 0) return (-1); else if (pid) _exit(0); /* child 1 terminates */ /* child 2 continues... */ daemon_proc = 1; /* for err_XXX() functions */ chdir(&quot;/&quot;); /* change working directory */ /* close off file descriptors */ for (i = 0; i &lt; MAXFD; i++) close(i); /* redirect stdin, stdout, and stderr to /dev/null */ open(&quot;/dev/null&quot;, O_RDONLY); open(&quot;/dev/null&quot;, O_RDWR); open(&quot;/dev/null&quot;, O_RDWR); openlog(pname, LOG_PID, facility); return (0); /* success */&#125; nohup和setsid用法 如果我们要在退出shell的时候继续运行进程，则需要使用nohup忽略hangup信号，或者setsid将父进程设为init进程；1234567891011121314151617181920212223242526272829303132333435363738394041b@b-VirtualBox:~/my_temp_test$ nohup ./o_multi_thread_process &amp;[1] 3487b@b-VirtualBox:~/my_temp_test$ nohup: ignoring input and appending output to ‘nohup.out’^Cb@b-VirtualBox:~/my_temp_test$ jobs[1]+ Running nohup ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ ps -ef | grep multib 3487 3004 0 20:05 pts/3 00:00:00 ./o_multi_thread_processb 3488 3487 0 20:05 pts/3 00:00:00 ./o_multi_thread_processb 3491 3004 0 20:05 pts/3 00:00:00 grep --color=auto multib@b-VirtualBox:~/my_temp_test$ bg %1bash: bg: job 1 already in backgroundb@b-VirtualBox:~/my_temp_test$ fg %1nohup ./o_multi_thread_process^Z[1]+ Stopped nohup ./o_multi_thread_processb@b-VirtualBox:~/my_temp_test$ bg %1[1]+ nohup ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ jobs -l[1]+ 3487 Running nohup ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ fg %1nohup ./o_multi_thread_process^Cb@b-VirtualBox:~/my_temp_test$ jobsb@b-VirtualBox:~/my_temp_test$ ps -ef | grep multib 3499 3004 0 20:11 pts/3 00:00:00 grep --color=auto multib@b-VirtualBox:~/my_temp_test$ setsid ./o_multi_thread_process &amp;[1] 3502b@b-VirtualBox:~/my_temp_test$ ProcessA: 3503 step1ProcessA: 3503 thread 139947724490496 step2ProcessA: 3503 thread 139947724490496 step3ProcessB: 3504 step1ProcessB: 3504 step2ProcessB: 3504 step3^C[1]+ Done setsid ./o_multi_thread_processb@b-VirtualBox:~/my_temp_test$ ps -ef | grep multib 3503 1256 0 20:12 ? 00:00:00 ./o_multi_thread_processb 3504 3503 0 20:12 ? 00:00:00 ./o_multi_thread_processb 3507 3004 0 20:12 pts/3 00:00:00 grep --color=auto multib@b-VirtualBox:~/my_temp_test$ jobs disown用法 那么对于已经在后台运行的进程，该怎么办呢？可以使用disown命令1234567891011121314b@b-VirtualBox:~/my_temp_test$ ./o_multi_thread_process &amp;[1] 3523b@b-VirtualBox:~/my_temp_test$ ProcessA: 3523 step1ProcessA: 3523 thread 140501901821696 step2ProcessA: 3523 thread 140501901821696 step3ProcessB: 3524 step1ProcessB: 3524 step2ProcessB: 3524 step3^Cb@b-VirtualBox:~/my_temp_test$ jobs -l[1]+ 3523 Running ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ disown -h %1b@b-VirtualBox:~/my_temp_test$ jobs[1]+ Running ./o_multi_thread_process &amp;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab笔记整理]]></title>
    <url>%2F2017%2F07%2F09%2Fcrontab%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[crontab命令被用来提交和管理用户的需要周期性执行的任务，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称 m h dom mon dow command分 时 日 月 周 命令 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 例子 */1 * * * * sed -i &#39;$a\nani&#39; /home/b/my_temp_test/practice.cpp每隔一分钟就在practice.cpp文件的最后一行插入字符串“nani” 3,15 8-11/2 * 12 0 sed -i &#39;$a\nani&#39; /home/b/my_temp_test/practice.cpp12月的周日的8-11时的时间段每隔两个小时就在第3分钟和第15分钟的时候，在practice.cpp文件的最后一行插入字符串“nani”]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第三章到第十一章笔记整理(二)]]></title>
    <url>%2F2017%2F07%2F03%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%88%B0%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[第七章 7.5节 ： 通用套接字选项， 常用的有 SO_KEEPALIVE SO_REVBUF SO_SNDBUF SO_REUSEADDR 7.9节 ： tcp套接字选项， 常用的有 TCP_NODELAY TCP_MAXSEG 7.11节 ：fcntl函数，常用的用法是使用F_SETFL命令设置O_NOBLOCK文件状态标志， 我们可以把一个套接字设置为非阻塞型。 第八章 8.11节 ： UDP的connect函数，可以获得性能提升，因为未连接的udp每次sendto发送数据报的时候都要连接然后发送然后断开， 之后第二个数据报又要重复上述步骤，而连接后的udp套接字只需要连接然后发送第一个数据报然后发送第二个、第三个就行了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第三章到第十一章笔记整理(一)]]></title>
    <url>%2F2017%2F07%2F02%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%88%B0%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[因为第二章之后基本都是纯Socket API的内容， 第三章到第十一章的笔记整理合并到一起。 第三章 3.4 ：字节排序函数，涉及到大小端，处理网络字节序和主机字节序的转换 3.6 ： 地址转换函数，吹在ASCII字符串与网络字节序的二进制值之间转换网际地址第四章 4.9节：close函数， 涉及到描述符引用计数，所以多进程并发服务器才可以共享已连接套接字，因为父进程调用close函数知识把该套接字标记成已关闭并导致该套接字描述符减1。只要引用计数的值仍大于0，就不会引发tcp的四分组连接终止序列 第五章 5.9节：处理SIGCHLD信号， 涉及到僵死进程（子进程终止时给父进程发送了一个SIGCHLD信号，若父进程未加处理，则子进程进入僵死状态），所以要建立该信号处理函数，并在函数中调用waitpid来处理 5.10节 ：使用wait或者waitpid来处理已终止的子进程，通常是使用waitpid并指定WNOHANG选项，来告知waitpid在有尚未终止的子进程在运行时不要阻塞。 第六章 同步I/O操作：导致请求进程阻塞，知道I/O操作完成 异步I/O操作：不导致请求进程阻塞 6.3节 ： select函数，必须得清楚select跟linux特有的epoll的区别， 有三点： 数量限制 ： select默认只支持1024个；epoll并没有最大数目限制 内存拷贝 ： select需要把fd_set数据结构从用户态到内核态来回拷贝； 而epoll是基于mmap技术用同一块内存实现的 效率 ： select每次都要遍历所有文件描述符， 集合越大速度越慢；而epoll维护着一个就绪列表， 每次只需要简单的从列表里取出就行了，只有活跃的socket才会触发相关callback 6.6节 ： shutdown函数，shutdown可以不用管引用计数就激发tcp的正常连接终止序列。当关闭连接的写这一半，对于tcp连接， 这称为半关闭（half-close）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第二章笔记修正（结合TLPI和APUE两书的笔记整理）]]></title>
    <url>%2F2017%2F06%2F05%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0%E7%AC%94%E8%AE%B0%E4%BF%AE%E6%AD%A3%EF%BC%88%E7%BB%93%E5%90%88TLPI%E5%92%8CAPUE%E4%B8%A4%E4%B9%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%89%2F</url>
    <content type="text"><![CDATA[为加深理解, 故本章老笔记内容大幅删减重写.第二章重点如下 : TCP (Transmission Control Protocol)传输控制协议. 特性如下 : 面向连接 全双工 可靠, 关心确认/超时/重传等, 保证顺序 流量控制 字节流, 没有任何记录边界 UDP (User Datagram Protocol)用户数据报协议. 特性如下 : 无连接 不可靠, 不保证顺序/是否到达/是否重复 每个数据报都有一个长度 TCP三路握手(three-way handshake) TCP选项 : MSS选项 发送SYN的TCP一端使用本选项通告对端他的最大分节大小(maximum segment size) 窗口规模选项 时间戳选项, 对于高速网络连接是必要的. TCP连接终止 : TCP状态转换图 TCP连接的分组交换 TIME_WAIT状态存在的理由 : 可靠地实现TCP全双工连接的终止 允许老的重复分节在网络中消逝 分节是TCP传递给IP的数据单元 Linux下面一共有65535个端口 其中1–1023是系统保留的， 1024–65535是供用户使用的。 0到1024是众所周知的端口（知名端口，常用于系统服务等，例如http服务的端口号是80)。个人写的应用程序，尽量不要使用0到1024之间的端口号。 套接字对是一个定义该连接的两个端点的四元组: 本地IP地址 本地TCP端口号 外地IP地址 外地TCP端口号 缓冲区大小及限制 IPv4数据报的最大大小为65535字节, 因为其总长度字段占据16位 以太网的MTU是1500字节, IPv4要求的最小链路MTU是68字节, 这允许最大的IPv4首部(包括20字节的固定长度部分和最多40字节的选项部分)拼接最小的片段 在两个主机之间的路径中最小的MTU成为路径MTU 当一个IP数据报将从某个接口送出时, 如果他的大小超过相应链路的MTU, IPv4和IPv6都将执行分片 IPv4首部的”不分片(don’t fragment)”位(即DF位)若被设置, 那么不管是发送这些数据报的主机还是转发他们的路由器, 都不允许对他们分片 IPv4和IPv6都定义了最小重组缓冲区大小(minimum reassembly buffersize), IPv4的主机要求不能超过576字节的数据， 所以很多使用UDP的IPv4应用（如DNS）都避免产生大于这个大小的数据报 MSS : TCP最大分节大小， 在以太网中使用IPv4的MSS值为1460（以太网的MTU - IPv4首部 - TCP首部 = 1500 - 20 - 20） TCP输出示意图 : UDP输出示意图 (因为UDP是不可靠的, 他不必保存应用进程数据的一个副本, 因此无需一个真正的发送缓冲区, 所以为虚线框): 常见因特网应用所使用的协议 ping ： ICMP DNS ： UDP、TCP DHCP : UDP SSH : TCP FTP : TCP HTTP : TCP]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第一章笔记修正]]></title>
    <url>%2F2017%2F06%2F02%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%E4%BF%AE%E6%AD%A3%2F</url>
    <content type="text"><![CDATA[又准备从头看一遍unp, 把一些老笔记放到博客里来就当网盘吧, 顺便修正以及删减一些之前不够精炼的老笔记内容. 第一章重点如下 : OSI (open systems interconnection), 即计算机通信开放系统互联模型 OSI分为七层, 从上到下依次为 应用层 表现层 会话层 传输层 网络层 数据链路层 物理层 对于网际网协议族, OSI顶上三层合并为一层, 称为应用层. 传输层对应着tcp/udp等, 网络层对应着IPv4/IPv6, OSI的数据链路层和物理层是随系统提供的设备驱动程序和网络硬件 套接字编程接口是从OSI顶上三层(网际协议的应用层)进入传输层的接口. 为何套接字要设计为顶上三层进入传输层的接口??因为OSI顶上三层处理具体网络应用的所有细节却对通信细节了解很少;底下四层对具体网络应用了解不多, 却处理所有的通信细节.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe服务端笔记(一)]]></title>
    <url>%2F2017%2F04%2F01%2Fkbe%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%AC%94%E8%AE%B0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[main看起来似乎所有的组件都有一个这样的宏(KBENGINE_MAIN)来包裹main函数123456intKBENGINE_MAIN(intargc, char* argv[])&#123; ENGINE_COMPONENT_INFO&amp;info = g_kbeSrvConfig.getXXX(); returnkbeMainT&lt;XXX&gt;(argc, argv, YYY, info.externalPorts_min, info.externalPorts_max, info.externalInterface, 0, info.internalInterface);&#125; 这个宏展开是这样子：123456789101112131415kbeMain(intargc, char* argv[]); \intmain(intargc, char* argv[]) \&#123; \ loadConfig(); \ g_componentID = genUUID64(); \ parseMainCommandArgs(argc, argv); \ char dumpname[MAX_BUF] = &#123;0&#125;; \ kbe_snprintf(dumpname, MAX_BUF, &quot;%&quot;PRAppID, g_componentID); \ KBEngine::exception::installCrashHandler(1, dumpname); \ intretcode = -1; \ THREAD_TRY_EXECUTION; \ retcode = kbeMain(argc, argv); \ THREAD_HANDLE_CRASH; \ returnretcode; \&#125; \ 稍微整理一下之后main函数看起来很像是这个样子：1234567891011121314151617181920intkbeMain(intargc, char* argv[]);intmain(intargc, char* argv[])&#123; loadConfig(); g_componentID = genUUID64(); parseMainCommandArgs(argc, argv);chardumpname[MAX_BUF] = &#123;0&#125;; kbe_snprintf(dumpname, MAX_BUF, &quot;%&quot;PRAppID, g_componentID); KBEngine::exception::installCrashHandler(1, dumpname);intretcode = -1; THREAD_TRY_EXECUTION;retcode = kbeMain(argc, argv); THREAD_HANDLE_CRASH;return (retcode);&#125;intkbeMain(intargc, char* argv[])&#123; ENGINE_COMPONENT_INFO&amp;info = g_kbeSrvConfig.getXXX(); return kbeMainT&lt;XXX&gt;(argc, argv, YYY, info.externalPorts_min, info.externalPorts_max, info.externalInterface, 0, info.internalInterface);&#125; 基本可以理解为每个组件的main函数流程都是一样的，只是在特化kbeMainT时所给参数不一样。 ServerConfig：ServerConfig涉及到服务端每个组件的各种配置选项，比如数据库访问。它的构造在组件名.cpp中，比如loginapp就在loginapp.cpp，machine就在machine.cpp中，loginapp的如下（server/loginapp/loginapp.cpp）：12ServerConfigg_serverConfig;KBE_SINGLETON_INIT(Loginapp); 它的初始化（配置）工作主要由loadConfig接口完成，如下（lib/server/kbemain.h）：12345678910inlinevoidloadConfig()&#123; Resmgr::getSingleton().initialize(); // &quot;../../res/server/kbengine_defs.xml&quot; g_kbeSrvConfig.loadConfig(&quot;server/kbengine_defs.xml&quot;); // &quot;../../../assets/res/server/kbengine.xml&quot; g_kbeSrvConfig.loadConfig(&quot;server/kbengine.xml&quot;);&#125; Resmgr：Resmgr负责管理kbe的所有资源管理，比如资源路径，环境变量。Resmgr的构造地方如下（lib/network/fixed_messages.cpp）：1234567FixedMessages::FixedMessages():_infomap(),_loaded(false)&#123; newResmgr(); Resmgr::getSingleton().initialize();&#125; 我们可以理解为FixedMessages构造的时候Resmgr就构造了。 Resmgr的初始化（配置）工作主要由initialize接口完成，代码如上。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe的UE4的demo大体解读]]></title>
    <url>%2F2017%2F03%2F11%2Fkbe%E7%9A%84UE4%E7%9A%84demo%E5%A4%A7%E4%BD%93%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[写到一半发现论坛的热门帖子里官方写了个u3d的demo源码解析, 内容几乎重复, u3d跟ue4的demo框架流程几乎都是差不多的, 直接给出官方帖子的链接好了, 尴尬:http://bbs.kbengine.org/forum.php?mod=viewthread&amp;tid=166]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe之ubuntu下的编译]]></title>
    <url>%2F2017%2F02%2F10%2Fkbe%E4%B9%8Bubuntu%E4%B8%8B%E7%9A%84%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[感觉之前的博客已经整理了大多数之前的关于基础的私人笔记, 现在应该可以讨论一下实操的东西了.先来一发之前的kbe在ubuntu下的编译笔记吧, 因为官方对于ubuntu下的kbe编译文档是有问题的. 编译步骤 安装openssl : sudo apt-get install libssl-dev 安装mysql : sudo apt-get install libmysqld-dev sudo apt-get install mysql-server 编译kbe : cd kbengine/kbe/src chmod -R 755 . make]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe之1分钟完成安装]]></title>
    <url>%2F2017%2F02%2F09%2Fkbe%E4%B9%8B1%E5%88%86%E9%92%9F%E5%AE%8C%E6%88%90%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[官方是有自动化的安装py脚本的, 不过还是有很多小坑的.不过其实脚本主要也就是只做两件事, 其他都是可选的: 配置环境变量 安装mysql 安装步骤 安装kbe之前请提前在mysql里 建一个数据库(比如建一个数据库kbe_database) 一个至少拥有select,insert,update,delete,create,drop权限的用户(比如这个用户是kbe_user) (具体详情请谷歌, 本篇文章是讲kbe的安装的, 不讨论mysql, 弄完mysql之后就可以开始下面的1分钟kbe安装教程啦) 找到你的kbe根目录, 然后进入根目录, 比如你的kbe根目录是kbengine, 则 : cd kbengine sudo python kbengine/kbe/tools/server/install/installer.py install 然后它就会问你 :Install KBEngine to Linux-account(No input is kbe): 为了简单起见, 建议直接填写你当前的linux用户名称, 比如我的是”b” 然后就是开始配置环境变量了, 它就会显示 12345678Check the dependences:- kbe_environment: checking...ERROR: KBE_ROOT: is error! The directory or file not found:KBE_ROOT//kbeKBE_ROOT=KBE_ROOT current: reset KBE_ROOT(No input is [/home/b/kbengine-0.9.18/]): 直接敲回车 他之后显示的都直接敲回车, 用默认的就可以, 直到他开始问你mysql的东西, 到mysql他会问 12- mysql: checking...- MySQL is installed on the remote machine?[yes/no] 这里我们直接填yes, 然后就直接填我们之前建立好的数据库kbe_database和用户kbe_user即可, 它会显示 : 12345678- Enter mysql ip-address:127.0.0.1- Enter mysql ip-port:3306- Enter mysql-account:kbe_user- Enter mysql-password:123456- Enter mysql-databaseName:kbe_database- mysql: yesModified: /home/b/kbengine-0.9.18//kbe/res/server/kbengine_defs.xmlKBEngine has been successfully installed! 是否安装成功 找到你的kbe根目录, 然后进入根目录, 比如你的kbe根目录是kbengine, 则1. 进入kbe根目录下的assets目录 : cd kbengine/assets 2. 运行启动脚本 : sh ./start_server.sh 用ps检查一下是否有以下进程再跑 : 12345678910b@b-VirtualBox:~/kbengine-0.9.18/assets$ ps -ef | grep -v grep | grep -i kbeb 15504 1372 0 04:28 pts/1 00:00:01 /home/b/kbengine-0.9.18/kbe/bin/server//machine --cid=2129652375332859700 --gus=1b 15505 1372 0 04:28 pts/1 00:00:05 /home/b/kbengine-0.9.18/kbe/bin/server//logger --cid=1129653375331859700 --gus=2b 15506 1372 0 04:28 pts/1 00:00:02 /home/b/kbengine-0.9.18/kbe/bin/server//interfaces --cid=1129652375332859700 --gus=3b 15507 1372 0 04:28 pts/1 00:00:06 /home/b/kbengine-0.9.18/kbe/bin/server//dbmgr --cid=3129652375332859700 --gus=4b 15508 1372 0 04:28 pts/1 00:00:07 /home/b/kbengine-0.9.18/kbe/bin/server//baseappmgr --cid=4129652375332859700 --gus=5b 15509 1372 0 04:28 pts/1 00:00:07 /home/b/kbengine-0.9.18/kbe/bin/server//cellappmgr --cid=5129652375332859700 --gus=6b 15510 1372 0 04:28 pts/1 00:00:03 /home/b/kbengine-0.9.18/kbe/bin/server//baseapp --cid=6129652375332859700 --gus=7b 15511 1372 0 04:28 pts/1 00:00:03 /home/b/kbengine-0.9.18/kbe/bin/server//cellapp --cid=7129652375332859700 --gus=8b 15512 1372 0 04:28 pts/1 00:00:06 /home/b/kbengine-0.9.18/kbe/bin/server//loginapp --cid=8129652375332859700 --gus=9 检查我们mysql中的kbe_database数据库里是否多了几个表 : 1234567891011mysql&gt; show tables;+---------------------------+| Tables_in_b_test_database |+---------------------------+| kbe_accountinfos || kbe_email_verification || kbe_entitylog || kbe_serverlog || tbl_Account |+---------------------------+5 rows in set (0.00 sec) 好, 如果都有基本安装完成!]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPC进程间通信]]></title>
    <url>%2F2017%2F01%2F27%2FIPC%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[IPC进程间通信 1.匿名管道( pipe )：匿名管道是一种半双工的通信方式，通常是在父子进程间使用。 2.命名管道 (named pipe) ：命名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 3.信号量( semophore ) ：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 4.消息队列( message queue ) ：消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 5.信号 ( sinal ) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 6.共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。 7.套接字( socket ) ：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同进程间的进程通信。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>IPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5分钟上手boost.asio]]></title>
    <url>%2F2017%2F01%2F12%2F5%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bboost.asio%2F</url>
    <content type="text"><![CDATA[Boost.Asio入门首先，让我们先来了解一下什么是Boost.Asio？怎么编译它？ linux下直接 : sudo apt-get install libboost-all-dev 什么是Boost.Asio简单来说，Boost.Asio是一个跨平台的、主要用于网络和其他一些底层输入/输出编程的C++库。 异步VS同步 首先，异步编程和同步编程是非常不同的。 在同步编程中，所有的操作都是顺序执行的，比如从socket中读取（请求），然后写入（回应）到socket中。 每一个操作都是阻塞的。 因为操作是阻塞的，所以为了不影响主程序，当在socket上读写时，通常会创建一个或多个线程来处理socket的输入/输出。 因此，同步的服务端/客户端通常是多线程的。 相反的，异步编程是事件驱动的。 虽然启动了一个操作，但是你不知道它何时会结束；它只是提供一个回调给你，当操作结束时，它会调用这个API，并返回操作结果。 对于有着丰富经验的QT（诺基亚用来创建跨平台图形用户界面应用程序的库）程序员来说，这就是他们的第二天性。 因此，在异步编程中，你只需要一个线程。 因为中途做改变会非常困难而且容易出错，所以你在项目初期（最好是一开始）就得决定用同步还是异步的方式实现网络通信。 不仅API有极大的不同，你程序的语意也会完全改变（异步网络通信通常比同步网络通信更加难以测试和调试）。 你需要考虑是采用阻塞调用和多线程的方式（同步，通常比较简单），或者是更少的线程和事件驱动（异步，通常更复杂）。 同步例子同步客户端下面是一个基础的同步客户端例子： 12345using boost::asio;io_service service;ip::tcp::endpoint ep( ip::address::from_string(&quot;127.0.0.1&quot;), 2001);ip::tcp::socket sock(service);sock.connect(ep); 首先，你的程序至少需要一个io_service实例。 Boost.Asio使用io_service同操作系统的输入/输出服务进行交互。 通常一个io_service的实例就足够了。 然后，创建你想要连接的地址和端口，再建立socket。 把socket连接到你创建的地址和端口。 同步服务端下面是一个简单的同步Boost.Asio的服务端：1234567891011121314151617typedef boost::shared_ptr&lt;ip::tcp::socket&gt; socket_ptr;io_service service;ip::tcp::endpoint ep( ip::tcp::v4(), 2001)); // listen on 2001ip::tcp::acceptor acc(service, ep);while ( true) &#123; socket_ptr sock(new ip::tcp::socket(service)); acc.accept(*sock); boost::thread( boost::bind(client_session, sock));&#125;void client_session(socket_ptr sock) &#123; while ( true) &#123; char data[512]; size_t len = sock-&gt;read_some(buffer(data)); if ( len &gt; 0) write(*sock, buffer(&quot;ok&quot;, 2)); &#125;&#125; 首先，同样是至少需要一个io_service实例。 然后你指定你想要监听的端口，再创建一个接收器——一个用来接收客户端连接的对象。 在接下来的循环中，你创建一个虚拟的socket来等待客户端的连接。 然后当一个连接被建立时，你创建一个线程来处理这个连接。 在client_session线程中来读取一个客户端的请求，进行解析，然后返回结果。 异步例子异步客户端而创建一个异步的客户端，你需要做如下的事情： 123456789using boost::asio;io_service service;ip::tcp::endpoint ep( ip::address::from_string(&quot;127.0.0.1&quot;), 2001);ip::tcp::socket sock(service);sock.async_connect(ep, connect_handler);service.run();void connect_handler(const boost::system::error_code &amp; ec) &#123; // 如果ec返回成功我们就可以知道连接成功了&#125; 在程序中你需要创建至少一个io_service实例。 你需要指定连接的地址以及创建socket。 当连接完成时（其完成处理程序）你就异步地连接到了指定的地址和端口，也就是说，connect_handler被调用了。 当connect_handler被调用时，检查错误代码（ec），如果成功，你就可以向服务端进行异步的写入。 注意：只要还有待处理的异步操作，servece.run()循环就会一直运行。 在上述例子中，只执行了一个这样的操作，就是socket的async_connect。 在这之后，service.run()就退出了。 每一个异步操作都有一个完成处理程序——一个操作完成之后被调用的函数。 异步服务端 下面的代码是一个基本的异步服务端 123456789101112131415161718using boost::asio;typedef boost::shared_ptr&lt;ip::tcp::socket&gt; socket_ptr;io_service service;ip::tcp::endpoint ep( ip::tcp::v4(), 2001)); // 监听端口2001ip::tcp::acceptor acc(service, ep);socket_ptr sock(new ip::tcp::socket(service));start_accept(sock);service.run();void start_accept(socket_ptr sock) &#123; acc.async_accept(*sock, boost::bind( handle_accept, sock, _1) );&#125;void handle_accept(socket_ptr sock, const boost::system::error_code &amp;err) &#123; if ( err) return; // 从这里开始, 你可以从socket读取或者写入 socket_ptr sock(new ip::tcp::socket(service)); start_accept(sock);&#125; 在上述代码片段中，首先，你创建一个io_service实例，指定监听的端口。 然后，你创建接收器acc——一个接受客户端连接，创建虚拟的socket，异步等待客户端连接的对象。 最后，运行异步service.run()循环。 当接收到客户端连接时，handle_accept被调用（调用async_accept的完成处理程序）。 如果没有错误，这个socket就可以用来做读写操作。 在使用这个socket之后，你创建了一个新的socket，然后再次调用start_accept()，用来创建另外一个“等待客户端连接”的异步操作，从而使service.run()循环一直保持忙碌状态。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>boost</tag>
        <tag>asio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式具体实现重要组件之RPC]]></title>
    <url>%2F2017%2F01%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6%E4%B9%8BRPC%2F</url>
    <content type="text"><![CDATA[RPC 是什么？RPC 的全称是 Remote Procedure Call 是一种进程间通信方式。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的，本质上编写的调用代码基本相同。 像腾讯的phxrpc框架是使用Protobuf作为IDL用于描述RPC接口以及通信数据结构 引用一个图 : c++ RPC的实现 1、一套完善的序列化框架；在不同的进程间传输数据，序列化是第一步，如何可靠且方便地将对象转化为二进制（或者其他格式），在对端则是如何正确且安全地将其从二进制恢复为对象。 2、完善的底层通信协议；其需要提供合适的语义抽象：服务端支持怎样的并发，是单客户单访问，还是多访问；而客户端的并发模型由服务端决定。当然，还需要健壮且足够的接口抽象，毕竟分布式环境，“一切皆有可能”，需要应对各种问题。 3、一个可用的反射系统。是的，需要在C++环境下建立一个反射系统。这一步是最为关键的，其由C++11支持。因为，我们需要注册一个类的各种信息，以供RPC调用。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速编译技巧]]></title>
    <url>%2F2016%2F11%2F01%2F%E5%BF%AB%E9%80%9F%E7%BC%96%E8%AF%91%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[项目越来越大，每次需要重新编译整个项目都是一件很浪费时间的事情。Research了一下，找到以下可以帮助提高速度的方法，总结一下。 tmpfs 有人说在Windows下用了RAMDisk把一个项目编译时间从4. 5小时减少到了5分钟，也许这个数字是有点夸张了，不过粗想想，把文件放到内存上做编译应该是比在磁盘 上快多了吧，尤其如果编译器需要生成很多临时文件的话。 这个做法的实现成本最低，在Linux中，直接mount一个tmpfs就可以了。而且对所编译的工程没有任何要求，也不用改动编译环境。 mount -t tmpfs tmpfs ~/build -o size=1G 用2.6.32.2的Linux Kernel来测试一下编译速度： 用物理磁盘：40分16秒 用tmpfs：39分56秒 呃……没什么变化。看来编译慢很大程度上瓶颈并不在IO上面。但对于一个实际项目来说， 编译过程中可能还会有打包等IO密集的操作，所以只要可能，用tmpfs是有 益无害的。 当然对于大项目来说，你需要有足够的内存才能负担得起这个tmpfs的开销。 make -j 既然IO不是瓶颈，那CPU就应该是一个影响编译速度的重要因素了。 用make -j带一个参数，可以把项目在进行并行编译，比如在一台双核的机器上，完全可以用make -j4，让make最多允许4个编译命令同时执行，这样可以更有效的利用CPU资源。 还是用Kernel来测试： 用make： 40分16秒 用make -j4：23分16秒 用make -j8：22分59秒 由此看来，在多核CPU上，适当的进行并行编译还是可以明显提高编译速度的。但并行的任务不宜太多，一般是以CPU的核心数目的两倍为宜。 不过这个方案不是完全没有cost的，如果项目的Makefile不规范，没有正确的设置好依赖关系，并行编译的结果就是编译不能正常进行。如果依赖关系设置过于保守，则可能本身编译的可并行度就下降了，也不能取得最佳的效果。 ccache ccache用于把编译的中间结果进行缓存，以便在再次编译的时候可以节省时间。这对于玩Kernel来说实在是再好不过了，因为经常需要修改一些Kernel的代码，然后再重新编译，而这两次编译大部分东西可能都没有发生变化。对于平时开发项目来说，也是一样。为什么不是直接用make所支持的增量编译呢？还是因为现实中，因为Makefile的不规范，很可能这种“聪明”的方案根本不能正常工作，只有每次make clean再make才行。 安装完ccache后，可以在/usr/local/bin下建立gcc，g++，c++，cc的symboliclink，链到/usr/bin/ccache上。总之确认系统在调用gcc等命令时会调用到ccache就可以了（通常情况下/usr/local/bin会在PATH中排在/usr/bin前面）。 继续测试： 用ccache的第一次编译(make -j4)：23分38秒 用ccache的第二次编译(make -j4)：8分48秒 用ccache的第三次编译(修改若干配置，make -j4)：23分48秒 看来修改配置（我改了CPU类型…）对ccache的影响是很大的，因为基本头文件发生变化后，就导致所有缓存数据都无效了，必须重头来做。但如果只是修改一些.c文件的代码，ccache的效果还是相当明显的。而且使用ccache对项目没有特别的依赖，布署成本很低，这在日常工作中很实用。 可以用ccache -s来查看cache的使用和命中情况： cache directory /home/lifanxi/.ccache cache hit 7165 cache miss 14283 called for link 71 not a C/C++ file 120 no input file 3045 files in cache 28566 cache size 81.7 Mbytes max cache size 976.6 Mbytes 可以看到，显然只有第二编次译时cache命中了，cache miss是第一次和第三次编译带来的。两次cache占用了81.7M的磁盘，还是完全可以接受的。 distcc 一台机器的能力有限，可以联合多台电脑一起来编译。这在公司的日常开发中也是可行的，因为可能每个开发人员都有自己的开发编译环境，它们的编译器版本一般是一致的，公司的网络也通常具有较好的性能。这时就是distcc大显身手的时候了。 使用distcc，并不像想象中那样要求每台电脑都具有完全一致的环境，它只要求源代码可以用make -j并行编译，并且参与分布式编译的电脑系统中具有相同的编译器。因为它的原理只是把预处理好的源文件分发到多台计算机上，预处理、编译后的目标文件的链接和其它除编译以外的工作仍然是在发起编译的主控电脑上完成，所以只要求发起编译的那台机器具备一套完整的编译环境就可以了。 distcc安装后，可以启动一下它的服务： /usr/bin/distccd –daemon –allow 10.64.0.0/16 默认的3632端口允许来自同一个网络的distcc连接。 然后设置一下DISTCC_HOSTS环境变量，设置可以参与编译的机器列表。 通常localhost也参与编译，但如果可以参与编译的机器很多，则可以把localhost从这个列表 中去掉，这样本机就完全只是进行预处理、分发和链接了，编译都在别的机器上完成。 因为机器很多时，localhost的处理负担很重，所以它就不再“兼职”编译了。 export DISTCC_HOSTS=&quot;localhost 10.64.25.1 10.64.25.2 10.64.25.3&quot; 然后与ccache类似把g++，gcc等常用的命令链接到/usr/bin/distcc上就可以了。 在make的时候，也必须用-j参数，一般是参数可以用所有参用编译的计算机CPU内核总数的两倍做为并行的任务数。 同样测试一下： 一台双核计算机，make -j4：23分16秒 两台双核计算机，make -j4：16分40秒 两台双核计算机，make -j8：15分49秒 跟最开始用一台双核时的23分钟相比，还是快了不少的。如果有更多的计算机加入，也可以得到更好的效果。 在编译过程中可以用distccmon-text来查看编译任务的分配情况。distcc也可以与ccache同时使用，通过设置一个环境变量就可以做到，非常方便。 总结 tmpfs： 解决IO瓶颈，充分利用本机内存资源 make -j： 充分利用本机计算资源 distcc： 利用多台计算机资源 ccache： 减少重复编译相同代码的时间 这些工具的好处都在于布署的成本相对较低，综合利用这些工具，就可以轻轻松松的节省相当可观的时间。 上面介绍的都是这些工具最基本的用法，更多的用法可以参考它们各自的man page。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>编译</tag>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个群聚(鱼群)AI插件基于虚幻4(有现成打包好的试玩demo, 源码在GitHub)]]></title>
    <url>%2F2016%2F10%2F18%2F%E4%B8%80%E4%B8%AA%E7%BE%A4%E8%81%9A(%E9%B1%BC%E7%BE%A4)AI%E6%8F%92%E4%BB%B6%E5%9F%BA%E4%BA%8E%E8%99%9A%E5%B9%BB4(%E6%9C%89%E7%8E%B0%E6%88%90%E6%89%93%E5%8C%85%E5%A5%BD%E7%9A%84%E8%AF%95%E7%8E%A9demo%2C%20%E6%BA%90%E7%A0%81%E5%9C%A8GitHub)%2F</url>
    <content type="text"><![CDATA[fishA fish flock AI Plugin for Unreal Engine 4 一个基于虚幻4的鱼群 AI 插件 this Plugin version can Run 2000+ fishes at the same time 这个插件版本可以同时运行 2000+ 条鱼儿 Video Preview Watch the Video Preview 查看 视频演示 Download &amp; PlayDownload Download MyFish.exe (Win64) (This is packaged by an unoptimized version( check out branch old_demo)) 下载 MyFish.exe (Win64) 玩玩 这个包是没有经过优化过的版本打包出来的(是用old_demo分支的版本打包的) How to play VR : (My Device is HTC Vive) Motion Controller FaceButton1 =&gt; Move forward 手柄圆盘上键 =&gt; 往前移动 PC’s KeyBoard Arrow UP and Down =&gt; Move faster or slower 电脑键盘的上下箭头键 =&gt; 调整移动速度 Hold Motion Controller Trigger Down =&gt; Attract fishes 按住手柄扳机键 =&gt; 吸引鱼群 PC : EQ =&gt; Up &amp; Down EQ 键 =&gt; 上下 WASD =&gt; Basic movement WASD 键 =&gt; 基本的移动指令(前后左右) Hold Left Mouse Button Down =&gt; Attract fishes 按住鼠标左键 =&gt; 吸引鱼群 Arrow UP and Down =&gt; Move faster or slower 上下箭头键 =&gt; 调整移动速度 How to useplace Plugins folder in your project root directory, then just like 把Plugins文件夹放在你项目的根目录, 接下来如图 About This Unreal Engine Version 4.15 Read Craig Reynolds’s thesis 查看 Craig Reynolds的论文 This project implements a new flocking Ai algorithm, with 3 components : 算法简要 Separation : every fish will try to steer away from their neighbors 分离性 ：每条鱼都会与周围的鱼保持距离 Following the leader : every fish will try to follow its leader 跟随一个领头者 ： 每条鱼都会跟随一个领头者 Avoiding enemies. 躲避敌人]]></content>
      <categories>
        <category>UE4</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>UE4</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XXTEA的python实现]]></title>
    <url>%2F2016%2F09%2F13%2FXXTEA%E7%9A%84python%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在数据的加解密领域，算法分为对称密钥与非对称密钥两种。 对称密钥与非对称密钥由于各自的特点，所应用的领域是不尽相同的。 对称密钥加密算法由于其速度快，一般用于整体数据的加密，而非对称密钥加密算法的安全性能佳，在数字签名领域得到广泛的应用。 微型加密算法（TEA）及其相关变种（XTEA，Block TEA，XXTEA） 都是分组加密算法，它们很容易被描述，实现也很简单（典型的几行代码）。 TEA是Tiny Encryption Algorithm的缩写，以加密解密速度快，实现简单著称。 TEA 算法最初是由剑桥计算机实验室的 David Wheeler 和 Roger Needham 在 1994 年设计的。 该算法使用 128 位的密钥为 64 位的信息块进行加密，它需要进行 64 轮迭代，尽管作者认为 32 轮已经足够了。 该算法使用了一个神秘常数δ作为倍数，它来源于黄金比率，以保证每一轮加密都不相同。 但δ的精确值似乎并不重要，这里 TEA 把它定义为 δ=「(√5 - 1)231」（也就是程序中的 0×9E3779B9）。 之后 TEA 算法被发现存在缺陷，作为回应，设计者提出了一个 TEA 的升级版本——XTEA（有时也被称为“tean”）。 XTEA 跟 TEA 使用了相同的简单运算，但它采用了截然不同的顺序，为了阻止密钥表攻击，四个子密钥（在加密过程中，原 128 位的密钥被拆分为 4 个 32 位的子密钥）采用了一种不太正规的方式进行混合，但速度更慢了。 在跟描述 XTEA 算法的同一份报告中，还介绍了另外一种被称为 Block TEA 算法的变种，它可以对 32 位大小任意倍数的变量块进行操作。 该算法将 XTEA 轮循函数依次应用于块中的每个字，并且将它附加于它的邻字。 该操作重复多少轮依赖于块的大小，但至少需要 6 轮。 该方法的优势在于它无需操作模式（CBC，OFB，CFB 等），密钥可直接用于信息。 对于长的信息它可能比 XTEA 更有效率。 在 1998 年，Markku-Juhani Saarinen 给出了一个可有效攻击 Block TEA 算法的代码，但之后很快 David J. Wheeler 和 Roger M. Needham 就给出了 Block TEA 算法的修订版，这个算法被称为 XXTEA。 XXTEA 使用跟 Block TEA 相似的结构，但在处理块中每个字时利用了相邻字。 它利用一个更复杂的 MX 函数代替了 XTEA 轮循函数，MX 使用 2 个输入量。 XXTEA 算法很安全，而且非常快速，非常适合应用于 Web 开发中。 TEA算法是由剑桥大学计算机实验室的David Wheeler和Roger Needham于1994年发明， TEA是Tiny Encryption Algorithm的缩写，以加密解密速度快，实现简单著称。 TEA算法每一次可以操作64bit(8byte)，采用128bit(16byte)作为key，算法采用迭代的形式，推荐的迭代轮数是64轮，最少32轮。 为解决TEA算法密钥表攻击的问题，TEA算法先后经历了几次改进，从XTEA到BLOCK TEA，直至最新的XXTEA。 XTEA也称做TEAN，它使用与TEA相同的简单运算，但四个子密钥采取不正规的方式进行混合以阻止密钥表攻击。 Block TEA算法可以对32位的任意整数倍长度的变量块进行加解密的操作，该算法将XTEA轮循函数依次应用于块中的每个字，并且将它附加于被应用字的邻字。 XXTEA使用跟Block TEA相似的结构，但在处理块中每个字时利用了相邻字，且用拥有两个输入量的MX函数代替了XTEA轮循函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import struct _DELTA = 0x9E3779B9 def _long2str(v, w): n = (len(v) - 1) &lt;&lt; 2 if w: m = v[-1] if (m &lt; n - 3) or (m &gt; n): return &apos;&apos; n = m s = struct.pack(&apos;&lt;%iL&apos; % len(v), *v) return s[0:n] if w else s def _str2long(s, w): n = len(s) m = (4 - (n &amp; 3) &amp; 3) + n s = s.ljust(m, &quot;\0&quot;) v = list(struct.unpack(&apos;&lt;%iL&apos; % (m &gt;&gt; 2), s)) if w: v.append(n) return v def encrypt(str, key): if str == &apos;&apos;: return str v = _str2long(str, True) k = _str2long(key.ljust(16, &quot;\0&quot;), False) n = len(v) - 1 z = v[n] y = v[0] sum = 0 q = 6 + 52 // (n + 1) while q &gt; 0: sum = (sum + _DELTA) &amp; 0xffffffff e = sum &gt;&gt; 2 &amp; 3 for p in xrange(n): y = v[p + 1] v[p] = (v[p] + ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[p &amp; 3 ^ e] ^ z))) &amp; 0xffffffff z = v[p] y = v[0] v[n] = (v[n] + ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[n &amp; 3 ^ e] ^ z))) &amp; 0xffffffff z = v[n] q -= 1 return _long2str(v, False) def decrypt(str, key): if str == &apos;&apos;: return str v = _str2long(str, False) k = _str2long(key.ljust(16, &quot;\0&quot;), False) n = len(v) - 1 z = v[n] y = v[0] q = 6 + 52 // (n + 1) sum = (q * _DELTA) &amp; 0xffffffff while (sum != 0): e = sum &gt;&gt; 2 &amp; 3 for p in xrange(n, 0, -1): z = v[p - 1] v[p] = (v[p] - ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[p &amp; 3 ^ e] ^ z))) &amp; 0xffffffff y = v[p] z = v[n] v[0] = (v[0] - ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[0 &amp; 3 ^ e] ^ z))) &amp; 0xffffffff y = v[0] sum = (sum - _DELTA) &amp; 0xffffffff return _long2str(v, True) if __name__ == &quot;__main__&quot;: print decrypt(encrypt(&apos;Hello XXTEA!&apos;, &apos;16bytelongstring&apos;), &apos;16bytelongstring&apos;)]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>xxtea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内零头和外零头]]></title>
    <url>%2F2016%2F09%2F12%2F%E5%86%85%E9%9B%B6%E5%A4%B4%E5%92%8C%E5%A4%96%E9%9B%B6%E5%A4%B4%2F</url>
    <content type="text"><![CDATA[问题:在内存管理中，“内零头”和“外零头”个指的是什么？在固定式分区分配、可变式分区分配、页式虚拟存储系统、段式虚拟存储系统中，各会存在何种零头？为什么？ 解答： 在存储管理中， 内零头是指分配给作业的存储空间中未被利用的部分， 外零头是指系统中无法利用的小存储块。 在固定式分区分配中，为将一个用户作业装入内存，内存分配程序从系统分区表中找出一个能满足作业要求的空闲分区分配给作业，由于一个作业的大小并不一定与分区大小相等，因此，分区中有一部分存储空间浪费掉了。 由此可知，固定式分区分配中存在内零头。 在可变式分区分配中，为把一个作业装入内存，应按照一定的分配算法从系统中找出一个能满足作业需求的空闲分区分配给作业，如果这个空闲分区的容量比作业申 请的空间容量要大，则将该分区一分为二，一部分分配给作业，剩下的部分仍然留作系统的空闲分区。 由此可知，可变式分区分配中存在外零头。 在页式虚拟存储系统中，用户作业的地址空间被划分成若干大小相等的页面，存储空间也分成也页大小相等的物理块，但一般情况下，作业的大小不可能都是物理块大小的整数倍，因此作业的最后一页中仍有部分空间被浪费掉了。 由此可知，页式虚拟存储系统中存在内零头。 在段式虚拟存储系统中，作业的地址空间由若干个逻辑分段组成，每段分配一个连续的内存区，但各段之间不要求连续，其内存的分配方式类似于动态分区分配。 由此可知，段式虚拟存储系统中存在外零头。 详细解释 操作系统在分配内存时，有时候会产生一些空闲但是无法被正常使用的内存区域，这些就是内存碎片，或者称为内存零头，这些内存零头一共分为两类：内零头和外零头。 内零头是指进程在向操作系统请求内存分配时，系统满足了进程所需要的内存需求后，还额外还多分了一些内存给该进程，也就是说额外多出来的这部分内存归该进程所有，其他进程是无法访问的。 外零头是指内存中存在着一些空闲的内存区域，这些内存区域虽然不归任何进程所有，但是因为内存区域太小，无法满足其他进程所申请的内存大小而形成的内存零头。 页式存储管理的情况页式存储管理是以页为单位（页面的大小由系统确定，且大小是固定的）向进程分配内存的， 例如：假设内存总共有100K,分为10页，每页大小为10K。现在进程A提出申请56K内存，因为页式存储管理是以页为单位进程内存分配的，所以系统会向进程A提供6个页面，也就是60K的内存空间，那么在最后一页中进程只使用了6K，从而多出了4K的内存碎片，但是这4K的内存碎片系统已经分配给进程A了，其他进程是无法再访问这些内存区域的， 这种内存碎片就是内零头。 段式存储管理的情况段式存储管理是段（段的大小是程序逻辑确定，且大小不是固定的）为单位向进程进行内存分配的，进程申请多少内存，系统就给进程分配多少内存，这样就不会产生内零头，但是段式分配会产生外零头。 例如：假设内存总的大小为100K，现在进程A向系统申请60K的内存，系统在满足了进程A的内存申请要求后，还剩下40K的空闲内存区域；这时如果进程B向系统申请50K的内存区域，而系统只剩下了40K的内存区域，虽然这40K的内存区域不归任何进程所有，但是因为大小无法满足进程B的要求，所以也无法分配给进程B，这样就产生了外零头。 请求段式存储管理是在段式存储管理的基础上增加了请求调段功能和段置换功能。所以段式和请求段式存储管理会产生外零头 练习题下面的内存管理模式中，会产生外零头的是(正确答案B, D) A、页式B、段式C、请求页式D、请求段式]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>内零头</tag>
        <tag>外零头</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的魔术]]></title>
    <url>%2F2016%2F09%2F01%2FPHP%E7%9A%84%E9%AD%94%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[PHP 将所有以 （两个下划线）开头的类方法保留为魔术方法。所以在定义类方法时，除了上述魔术方法，建议不要以 为前缀。 PHP魔幻（术）变量1234567- __LINE__ 文件中的当前行号。- __FILE__ 文件的完整路径和文件名。如果用在被包含文件中，则返回被包含的文件名。- __DIR__ 文件所在的目录。如果用在被包括文件中，则返回被包括的文件所在的目录。 它等价于 dirname(__FILE__)。- __FUNCTION__ 本常量返回该函数被定义时的名字（区分大小写）- __CLASS__ 本常量返回该类被定义时的名字（区分大小写） PHP魔幻（术）方法 __construct() 实例化类时自动调用。 __destruct() 类对象使用结束时自动调用。 __set() 在给未定义的属性赋值的时候调用。 __get() 调用未定义的属性时候调用。 __isset() 使用isset()或empty()函数时候会调用。 __unset() 使用unset()时候会调用。 __sleep() 使用serialize序列化时候调用。 __wakeup() 使用unserialize反序列化的时候调用。 __call() 调用一个不存在的方法的时候调用。 __callStatic()调用一个不存在的静态方法是调用。 __toString() 把对象转换成字符串的时候会调用。比如 echo。 __invoke() 当尝试把对象当方法调用时调用。 __set_state() 当使用var_export()函数时候调用。接受一个数组参数。 __clone() 当使用clone复制一个对象时候调用。]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建一台简易linux服务器(三)]]></title>
    <url>%2F2016%2F08%2F27%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0%E7%AE%80%E6%98%93linux%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[安装MySQL执行命令安装MySQL：sudo apt-get install mysql-server安装的时候会提示填入一个root的初始密码，先输入个8做初始密码吧 #导入客户数据库base_accountmysql -uroot -p &lt; *.sql(某个sql文件) 安装svn并checkout一个svn服务器上的目录 进入 /data/www目录下 ：cd /data/www 执行命令安装：sudo apt-get install subversion checkout一个目录（比如svn://112.124.26.188/myapp/td/01CServer_PHP/errorMsg），执行命令：svn checkout svn://112.124.26.188/myapp/td/01CServer_PHP/errorMsg （或者 svn co svn://112.124.26.188/myapp/td/01CServer_PHP/errorMsg） 测试是否可以访问并将相应数据传入数据库中访问 localhost/errorMsg/ErrorMsg.php?data=3_2&amp;error_msg=zhangnimashuai然后查看数据库相应表里是否增加了数据 ##证书登陆 (可选)#对dev 将id_rsa私钥和id_rsa.pub公钥以及authorized_keys授权文件拷贝至~dev/.ssh/目录chmod 600 id_rsa; chmod 644 id_rsa.pub; chmod 644 authorized_keys #SSH 证书登陆配置sudo vi /etc/ssh/sshd_config取消注释 : #AuthorizedKeysFile .ssh/authorized_keys修改yes-&gt;no : PasswordAuthentication nosudo service ssh restart #重启服务 测试登陆sudo service nginx restartsudo service php5-fpm restart #测试成功后去除dev用户的sudo权限 （可选）sudo visudo 删除：dev ALL=(ALL:ALL) ALL]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建一台简易linux服务器(二)]]></title>
    <url>%2F2016%2F08%2F25%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0%E7%AE%80%E6%98%93linux%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[安装nginx(如若有有不明白，还可以前往参考 wiki.ubuntu.org.cn/Nginx )执行命令安装nginx：sudo apt-get install nginx测试是否安装成功：在本机的浏览器里访问 localhost ;如果现实”Welcome to nginx!”，表明你的 Nginx 服务器安装成功！启动 Nginx：sudo /etc/init.d/nginx start关闭 Nginx：sudo /etc/init.d/nginx stop重启 nginx：sudo /etc/init.d/nginx restart 或者 sudo service nginx restartsudo service apache2 stop (如果之前装了apache2则需要sudo apt-get remove apache2 卸载掉apache2然后执行这个stop命令) 修改nginx的server配置文件 执行命令：sudo vi /etc/nginx/sites-available/default 然后将default文件里的内容全部删除，把下面的内容粘贴进去：server {listen 80 default_server; root /data/www; #这里表示nginx根目录index index.php index.html index.htm; server_name localhost;chunked_transfer_encoding off; location / {try_files $uri $uri/ =404;} error_page 404 /index.html; location ~ .php$ { #加上这个代码块就可以用php访问了，这个代码块还有fastcgi的相关内容try_files $uri =404;fastcgi_split_path_info ^(.+.php)(/.+)$;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fastcgi_params;}} 安装以及启动fastcgi 执行命令安装：sudo apt-get install spawn-fcgi 启动fastcgi ：spawn-fcgi -a 127.0.0.1 -p 9000 -C 10 -u www-data -f /usr/bin/php-cgi 为了让php-cgi开机自启动： Ubuntu开机之后会执行/etc/rc.local文件中的脚本 所以我们可以直接在/etc/rc.local中添加启动脚本。 将 spawn-fcgi -a 127.0.0.1 -p 9000 -C 10 -u www-data -f /usr/bin/php-cgi 添加到语句：exit 0 前面才行 安装PHP执行命令安装PHP：sudo apt-get install php5-cli php5-cgi php5-fpm php5-mcrypt php5-mysql php设置sudo vi /etc/php5/fpm/php.ini #设置cgi.fix_pathinfo=0sudo service php5-fpm restart sudo vi /etc/php5/fpm/pool.d/www.conflisten.owner = www-datalisten.group = www-datalisten.mode = 0660 （去掉原www.conf里“listen.mode = 0660”前的分号，那个分号是注释的意思）sudo service php5-fpm restart 测试是否可以访问 在nginx根目录也就是 上面server配置文件里的 /data/www(若没有这个目录就建一个，并改变权限，执行sudo chown dev:dev data/)文件夹里新建index.html（不建此文件将不能在本机访问localhost） 将下面的内容粘贴到index.html文件里 Welcome to nginx!Welcome to nginx! 第1步完成后将可以在浏览器访问 http://localhost 再在 /data/www文件夹里新建test.php将下面的内容粘贴到test.php文件里&lt;?php phpinfo(); ?&gt; 第3步完成后将可以在浏览器访问 http://localhost/test.php（注：如果没有启动fastcgi，访问之后将会下载此php文件。若启动了fastcgi，则访问phpinfo的网页;如果出现No input file specified就在上面的server配置文件里的下述地方加入这条语句：fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;如下：location ~ .php$ {try_files $uri =404;fastcgi_split_path_info ^(.+.php)(/.+)$;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;include fastcgi_params;} ）]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建一台简易linux服务器(一)]]></title>
    <url>%2F2016%2F08%2F23%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0%E7%AE%80%E6%98%93linux%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[#virtualBox网络设置在virtualBox的你的那个虚拟机里的网络设置里添加两张网卡：1.“网络地址转换（NAT）”， 不是那个“NAT网络”噢， 这张网卡是用来访问宿主机和外网的， 但是仅仅有这张网卡宿主机是不能访问你的这个虚拟机的， 所以还需要下面这第2张2.“仅主机（Host-Olny）网络”， 这张网卡是用来让宿主机是访问你的这个虚拟机的， 这样就能用ssh工具从宿主机连到你的这个虚拟机了 #创建dev用户sudo adduser dev #增加dev权限sudo visudo 添加：dev ALL=(ALL:ALL) ALL 关于Ubuntu的root密码Ubuntu的默认root密码是随机的，即每次开机都有一个新的root密码。我们可以在终端输入命令 sudo passwd，然后输入当前用户的密码，enter，终端会提示我们输入新的密码并确认，此时的密码就是root新密码。修改成功后，输入命令 su root，再输入新的密码就ok了。 安装ssh服务端先更换源， 然后执行sudo apt-get update执行命令：sudo apt-get install openssh-server测试是否安装成功：ssh localhost]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[boost之program_options]]></title>
    <url>%2F2016%2F08%2F15%2Fboost%E4%B9%8Bprogram_options%2F</url>
    <content type="text"><![CDATA[介绍命令行接口是普遍,基础的人机交互接口，从命令行提取程序的运行时选项的方法有很多。 你可以自己编写相对应的完整的解析函数，或许你有丰富的C语言编程经验，熟知getopt()函数的用法，又或许使用Python的你已经在使用optparse库来简化这一工作。 大家在平时不断地谈及到“不要重复造轮子”，那就需要掌握一些顺手的库，这里介绍一种C++方式来解析命令行选项的方法，就是使用Boost.Program_options库。 program_options提供程序员一种方便的命令行和配置文件进行程序选项设置的方法。 使用program_options库而不是你自己动手写相关的解析代码，因为它更简单，声明程序选项的语法简洁，并且库自身也非常小。 将选项值转换为适合的类型值的工作也都能自动完成。 库有着完备的错误检查机制，如果自己手写解析代码时，就可能会错过对一些出错情况的检查了。 最后，选项值不仅能从命令行获取，也能从配置文件，甚至于环境变量中提取，而这些选择不会增加明显的工作量。 示例说明以下面简单的hello程序进行说明，默认打印hello world,如果传入-p选项，就会打印出人的姓名，另外通过传入-h选项，可以打印出帮助选项。 略微看一眼代码文件和相应的屏幕输入输出，然后我们再一起来看看这些是如何发生的。 123456789101112131415161718192021222324252627//hello.cpp #include &lt;iostream&gt;#include &lt;string&gt;#include &lt;boost/program_options.hpp&gt;using namespace std;int main(int argc, char* argv[])&#123; using namespace boost::program_options; //声明需要的选项 options_description desc(&quot;Allowed options&quot;); desc.add_options() (&quot;help,h&quot;, &quot;produce help message&quot;) (&quot;person,p&quot;, value&lt;string&gt;()-&gt;default_value(&quot;world&quot;), &quot;who&quot;) ; variables_map vm; store(parse_command_line(argc, argv, desc), vm); notify(vm); if (vm.count(&quot;help&quot;)) &#123; cout &lt;&lt; desc; return 0; &#125; cout &lt;&lt; &quot;Hello &quot; &lt;&lt; vm[&quot;person&quot;].as&lt;string&gt;() &lt;&lt; endl; return 0;&#125; 下面是在Windows命令提示符窗口上的输入输出结果，其中”&gt;”表示提示符。 1234567891011&gt;hello Hello world&gt;hello -hAllowed options: -h [ --help ] produce help message -p [ --person ] arg (=world) who&gt;hello --person lenHello len 首先通过options_description类声明了需要的选项，add_options返回了定义了operator()的特殊的代理对象。 这个调用看起来有点奇怪，其参数依次为选项名，选项值，以及选项的描述。 注意到示例中的选项名为”help,h”，是因为声明了具有短选项名和长选项名的选项，这跟gnu程序的命令行具有一致性。 当然你可以省略短选项名，但是这样就不能用命令选项简写了。 第二个选项的声明，定义了选项值为string类型，其默认值为world. 接下来,声明了variables_map类的对象，它主要用来存储选项值，并且能储存任意类型的值。 然后，store,parse_command_line和notify函数使vm能存储在命令行中发现的选项。 最后我们就自由地使用这些选项了，variables_map类的使用就像使用std::map一样，除了它必须用as方法去获取值。 如果as方法调用的指定类型与实际存储的类型不同，就会有异常抛出。 具有编程的你可能有这样的经验，使用cl或gcc对源文件进行编译时，可直接将源文件名放置在命令行中，而无需什么选项字母，如gcc a.c之类的。 prgram_options也能处理这种情况，在库中被称为”positional options”(位置选项),但这需要程序员的一点儿帮助才能完成。 看下面的经过对应修改的代码，我们无需传入”-p”选项，就能可指定”person”选项值 123positional_options_description p;p.add(&quot;person&quot;, -1);store(command_line_parser(argc, argv).options(desc).positional(p).run(), vm); 12&gt;hello lenHello len 前面新增的两行是为了说明所有的位置选项都应被解释成”person”选项，这里还采用了command_line_parser类来解析命令行，而不是用parse_command_line函数。 后者只是对前者类的简单封装，但是现在我们需要传入一些额外的信息，所以要使用类本身。 选项复合来源一般来说，在命令行上指定所有选项，对用户来说是非常烦人的。 如果有些选项要应用于每次运行，那该怎么办呢。 我们当然希望能创建出带有些常用设置的选项文件，跟命令行一起应用于程序中。 当然这一切需要将命令行与配置文件中的值结合起来。 比如，在命令行中指定的某些选项值应该能覆盖配置文件中的对应值，或者将这些值组合起来。 下面的代码段将选项通过文件读取，这文件是文本格式，可用”#”表示注释，格式如命令行中的参数一样，选项=值 123ifstream ifs(&quot;config.cfg&quot;);store(parse_config_file(ifs,config),vm);notify(vm); 参考Boost.prgram_options库文档]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>boost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于UNP与APUE与TLPI三本大部头的阅读建议(着重讲UNP)]]></title>
    <url>%2F2016%2F08%2F11%2F%E5%85%B3%E4%BA%8EUNP%E4%B8%8EAPUE%E4%B8%8ETLPI%E4%B8%89%E6%9C%AC%E5%A4%A7%E9%83%A8%E5%A4%B4%E7%9A%84%E9%98%85%E8%AF%BB%E5%BB%BA%E8%AE%AE(%E7%9D%80%E9%87%8D%E8%AE%B2UNP)%2F</url>
    <content type="text"><![CDATA[这本书不能一次性所有都想看完。 要有目的性的看，因为这本书类似于百科全书所有都讲， 不分轻重， 如果都看，硬啃，只会迷失了自己，反而不知道看了什么 这本书不能单独看。 这本书必须配合TCP/IP详解和UNIX环境高级编程（简称APUE）以及The Linux Programming Interface（不知道这本书的译名是什么， 简称TLPI）来看 个人看的是卷一第三版，因当前工作经验范围和阅历受限，对于IT码农，IPv6的和SCTP的章节暂且略过，所以目前大概划出的必看章节（其他可挑选）是 1 2 3 4 5 6 7 8 11 13 16 22 26 30 书中的源码在linux环境下不一定能一次性编译过。 有些地方得自己修改 建议阅读电子版。 使用可以搜索书签的pdf阅读器（比较推荐福昕）， 并且多开几个此书的副本，因为经常会源码和源码讲解对照着看，如果有双屏效率会极大的提高]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reactor模式和Proactor]]></title>
    <url>%2F2016%2F08%2F07%2FReactor%E5%92%8CProactor%2F</url>
    <content type="text"><![CDATA[在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。 在比较这两个模式之前，我们首先的搞明白几个概念，什么是阻塞和非阻塞，什么是同步和异步, 同步和异步是针对应用程序和内核的交互而言的， 同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪， 异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。 而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式， 说白了是一种读取或者写入操作函数的实现方式， 阻塞方式下读取或者写入函数将一直等待， 非阻塞方式下，读取或者写入函数会立即返回一个状态值。 同步 vs 异步一般来说I/O模型可以分为： 同步阻塞， 同步非阻塞， 异步阻塞， 异步非阻塞IO 同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。 JAVA传统的IO模型属于此种方式！ 同步非阻塞IO:在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪， 这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。 其中目前JAVA的NIO就属于同步非阻塞IO。 异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！ 异步非阻塞IO:在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。 目前Java中还没有支持此种IO模型。 Reactor vs Proactor搞清楚了以上概念以后，我们再回过头来看看，Reactor模式和Proactor模式。 Reactor首先来看看Reactor模式，Reactor模式应用于同步I/O的场景。 我们分别以读操作和写操作为例来看看Reactor中的具体步骤： 读取操作： 应用程序注册读就需事件和相关联的事件处理器 事件分离器等待事件的发生 当发生读就需事件的时候，事件分离器调用第一步注册的事件处理器 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理 写入操作:类似于读取操作，只不过第一步注册的是写就绪事件。 Proactor下面我们来看看Proactor模式中读取操作和写入操作的过程： 读取操作： 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。 事件分离器等待读取操作完成事件 在事件分离器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。 这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。 事件分离器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。 写入操作:Proactor中写入操作和读取操作类似，只不过感兴趣的事件是写入完成事件。 小结从上面可以看出，Reactor和Proactor模式的主要区别就是真正的读取和写入操作是有谁来完成的， Reactor中需要应用程序自己读取或者写入数据，而Proactor模式中，应用程序不需要进行实际的读写过程， 它只需要从缓存区读取或者写入即可，操作系统会读取缓存区或者写入缓存区到真正的IO设备. 总结综上所述，同步和异步是相对于应用和内核的交互方式而言的，同步 需要主动去询问， 而异步的时候内核在IO事件发生的时候通知应用程序， 而阻塞和非阻塞仅仅是系统在调用系统调用的时候函数的实现方式而已。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>proactor</tag>
        <tag>reactor</tag>
        <tag>同步</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新看unix网络编程的一些心得]]></title>
    <url>%2F2016%2F08%2F02%2F%E9%87%8D%E6%96%B0%E7%9C%8Bunix%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[老书新看, 有了许多不同的见解, 也准备拿出以前自己私人的老笔记做修正放到博客里, 加深理解. 在这个浮躁人人都能写书的时代基本要看一本书需要挑很久, 谁写的, 写得怎么样, 是否是业界经典, 都要需要一一斟酌各种查证方可, 不然看一本烂书事半功倍, 浪费生命,影响效率, 被误导跑偏, 能让人静下心来的书籍不多, 能让人看好几遍仍回味无穷的经典就更少了 陈硕说过, 学东西不要只是从网上看点大牛的博客总结就行了, 总要完整地看些相关领域的经典著作的, 系统的知识结构打下坚实的基础才能继续看有关优化效率方面的书籍, 深以为然 孟岩说, 最近不止一次听到当一个人拥有相关领域的知识基础之后就可以找一本effective*的书来研读了, 颇有道理 看书的顺序忌胶柱鼓瑟, 并不是他的目录结构怎么编排你就该怎么看的, 大多数经典书籍基本都是面面俱到, 如果直接跟着这种面向知识体系本身的编排思路去看, 容易迷失乏味而无法继续, 应该找到属于自己看书顺序 个人总结的看书顺序是先翻阅自己感兴趣的,接着仔细观察他的目录来确定他的编排思路, 然后花一到两天的时间通览全书以获得大体知识体系构架, 之后找到实战性最强的章节来实操并逐个突破实战过程中的各个知识点]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈当前流行的pomelo和skynet和kbengine]]></title>
    <url>%2F2016%2F08%2F01%2F%E6%B5%85%E8%B0%88%E5%BD%93%E5%89%8D%E6%B5%81%E8%A1%8C%E7%9A%84pomelo%E5%92%8Cskynet%E5%92%8Ckbengine%2F</url>
    <content type="text"><![CDATA[根据之前的博文&lt;&lt;服务端常用架构&gt;&gt;来看 网易pomelo属于第二代游戏服务端五型的架构，即图7的架构。 skynet因为是一个服务端框架，官方只是提供了login server 和 gate server的参考实现，其他的需要自己来实现，编程的自由度变大了，架构完全取决于程序员自己的选择，程序员可以自己尝试去实现第二代的架构，也可以实现第三代的架构。注意: skynet仅仅是框架，其他属于完整解决方案。 Kbengine属于第三代服务端框架，可能类似于图10。（这个理解不确定）Kbengine引擎应该是对图10中的Gate服务器和NODE和OBJ进行了细分。在功能上大体划分为与位置有关（在Kbengine中称为Cellapp）和与位置无关（在Kbengine中称为Baseapp）。类似于下面的示图架构。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>skynet</tag>
        <tag>pomelo</tag>
        <tag>kbengine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速完成一个slg游戏思路(二)]]></title>
    <url>%2F2016%2F07%2F30%2F%E5%BF%AB%E9%80%9F%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AAslg%E6%B8%B8%E6%88%8F%E6%80%9D%E8%B7%AF(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[ChatServer 从登录成功就开始连接, 注册一个Chat_ID, player_ID 和 Chat_ID相互对应, 会注册相应的房间频道, 并为每位Player存了一份黑名单, 在客户端做了本地黑名单, 聊天服务器也做了黑名单二次验证处理. 世界频道 : 则用MsgServer的非实时推送思路 私密聊天 : 则选择 workerman 的tcp, MsgServer 实时推送 : workerman 的tcp 非实时推送 : 客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒， deployToolCapistrano是一个开源的部署工具, 用ruby来写, 语法超简洁的 优点 实时则走 workerman 非实时则跑 yii 访问一下，请求一下关卡数据，玩完了又提交一下， 验算一下是否合法，获得什么奖励， 数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余， 这类游戏因为逻辑简单，玩家之间交互不强， 使用HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>yii</tag>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>http</tag>
        <tag>udp</tag>
        <tag>workerman</tag>
        <tag>Capistrano</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速完成一个slg游戏思路(一)]]></title>
    <url>%2F2016%2F07%2F30%2F%E5%BF%AB%E9%80%9F%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AAslg%E6%B8%B8%E6%88%8F%E6%80%9D%E8%B7%AF(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[LoginServer(GateWay)当完成渠道sdk回调验证之后, 验证完玩家信息, 用了nginx的负载均衡给每位玩家分配一台不繁忙的游戏服务器, 在redis中存了一份玩家在线有效时间key,超时则掉线, 这个key也可以用来完成封号操作 MainServer 因为弱交互/短连接的关系, 大多数情况玩家和玩家之间不需要实时面对面PK， 打一下对方的离线数据， 计算下排行榜，排行榜是实时计算的, 存在redis里, 做了分页处理 买卖下道具即可 所以 MainServer 选择了: yii redis mysql nginx pvpServeer而 pvpServer 则选择 workerman 的tcp模式, 实时交互数据, MainServer 和 pvpServer之间通信并接同一个数据库. 其实这里可以不选择用tcp, 而自撸一个可靠udp来提高效率]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>yii</tag>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>http</tag>
        <tag>udp</tag>
        <tag>workerman</tag>
        <tag>Capistrano</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务端常用架构(三)]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[休闲游戏服务器休闲游戏同战网服务器类似，都是全区架构，不同的是有房间服务器，还有具体的游戏服务器，游戏主体不再以玩家 P2P进行，而是连接到专门的游戏服务器处理： 和战网一样的全区架构，用户数据不能象分区的 RPG那样一次性load到内存，然后在内存里面直接修改。全区架构下，为了应对一个用户同时玩几个游戏，用户数据需要区分基本数据和不同的游戏数据，而游戏数据又需要区分积分数据、和文档数据。胜平负之类的积分可以直接提交增量修改，而更为普遍的文档类数据则需要提供读写令牌，写令牌只有一块，读令牌有很多块。同帐号同一个游戏同时在两台电脑上玩时，最先开始的那个游戏获得写令牌，可以操作任意的用户数据。而后开始的那个游戏除了可以提交胜平负积分的增量改变外，对用户数据采用只读的方式，保证游戏能运行下去，但是会提示用户，游戏数据锁定。 现代动作类网游从早期的韩国动作游戏开始，传统的战网动作类游戏和 RPG游戏开始尝试融合。单纯的动作游戏玩家容易疲倦，留存也没有 RPG那么高；而单纯 RPG战斗却又慢节奏的乏味，无法满足很多玩家激烈对抗的期望，于是二者开始融合成为新一代的：动作 + 城镇模式。玩家在城镇中聚集，然后以开副本的方式几个人出去以动作游戏的玩法来完成各种 RPG任务。本质就是一套 RPG服务端+副本服务端。由于每次副本时人物可以控制在8人以内，因此可以获得更为实时的游戏体验，让玩家玩的更加爽快。 说了那么多的游戏服务器类型，其实也差不多了，剩下的类型大家拼凑一下其实也就是这个样子而已。游戏服务端经历了那么多结构上的变迁，内部开发模式是否依然不变？究竟是继续延续传统的开发方式？还是有了更多突破性的方法？经历那么多次架构变迁，后面是否有共通的逻辑？未来的发展还会存在哪些困难？游戏服务端开发如何达到最终的彼岸？请看下节：技术的演进。]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务端常用架构(二)]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[第三代游戏服务器 2007从魔兽世界开始无缝世界地图已经深入人心，比较以往游戏玩家走个几步还需要切换场景，每次切换就要等待 LOADING个几十秒是一件十分破坏游戏体验的事情。于是对于 2005年以后的大型 MMORPG来说，无缝地图已成为一个标准配置。比较以往按照地图来切割游戏而言，无缝世界并不存在一块地图上面的人有且只由一台服务器处理了： 每台 Node服务器用来管理一块地图区域，由 NodeMaster（NM）来为他们提供总体管理。更高层次的 World则提供大陆级别的管理服务。这里省略若干细节服务器，比如传统数据库前端，登录服务器，日志和监控等，统统用 ADMIN概括。在这样的结构下，玩家从一块区域走向另外一块区域需要简单处理一下： 玩家1完全由节点A控制，玩家3完全由节点B控制。而处在两个节点边缘的2号玩家，则同时由A和B提供服务。玩家2从A移动到B的过程中，会同时向A请求左边的情况，并向B请求右边的情况。但是此时玩家2还是属于A管理。直到玩家2彻底离开AB边界很远，才彻底交由B管理。按照这样的逻辑将世界地图分割为一块一块的区域，交由不同的 Node去管理。 对于一个 Node所负责的区域，地理上没必要连接在一起，比如大陆的四周边缘部分和高山部分的区块人比较少，可以统一交给一个Node去管理，而这些区块在地理上并没有联系在一起的必要性。一个 Node到底管理哪些区块，可以根据游戏实时运行的负载情况，定时维护的时候进行更改 NodeMaster 上面的配置。 于是碰到第一个问题是很多 Node服务器需要和玩家进行通信，需要问管理服务器特定UID为多少的玩家到底在哪台 Gate上，以前按场景切割的服务器这个问题不大，问了一次以后就可以缓存起来了，但是现在服务器种类增加不少，玩家又会飘来飘去，按UID查找玩家比较麻烦；另外一方面 GATE需要动态根据坐标计算和哪些 Node通信，导致逻辑越来越厚，于是把：“用户对象”从负责连接管理的 GATE中切割出来势在必行于是有了下面的模型： 网关服务器再次退回到精简的网络转发功能，而用户逻辑则由按照 UID划分的 OBJ服务器来承担，GATE是按照网络接入时的负载来分布，而 OBJ则是按照资源的编号（UID）来分布，这样和一个用户通信直接根据 UID计算出 OBJ服务器编号发送数据即可。而新独立出来的 OBJ则提供了更多高层次的服务： • 对象移动：管理具体玩家在不同的 Node所管辖的区域之间的移动，并同需要的 Node进行沟通。• 数据广播：Node可以给每个用户设置若干 TAG，然后通知 Object Master 按照TAG广播。• 对象消息：通用消息推送，给某个用户发送数据，直接告诉 OBJ，不需要直接和 GATE打交道。• 好友聊天：角色之间聊天直接走 OBJ/OBJ MASTER。整个服务器主体分为三层以后，NODE专注场景，OBJ专注玩家对象，GATE专注网络。这样的模型在无缝场景服务器中得到广泛的应用。但是随着时间的推移，负载问题也越来越明显，做个活动，远来不活跃的区域变得十分活跃，靠每周维护来调整还是比较笨重的，于是有了动态负载均衡。 动态负载均衡有两种方法，第一种是按照负载，由 Node Master 定时动态移动修改一下各个 Node的边界，而不同的玩家对象按照先前的方法从一台 Node上迁移到另外一台 Node上： 图11 动态负载均衡 这样 Node Master定时查找地图上的热点区域，计算新的场景切割方式，然后告诉其他服务器开始调整，具体处理方式还是和上面对象跨越边界移动的方法一样。 但是上面这种方式实现相对复杂一些，于是人们设计出了更为简单直接的一种新方法： 图12 基于网格的动态负载均衡 还是将地图按照标准尺寸均匀切割成静态的网格，每个格子由一个具体的Node负责，但是根据负载情况，能够实时的迁移到其他 Node上。在迁移分为三个阶段：准备，切换，完成。三个状态由Node Master负责维护。准备阶段新的 Node开始同步老 Node上面该网格的数据，完成后告诉NM；NM确认OK后同时通知新旧 Node完成切换。完成切换后，如果 Obj服务器还在和老的 Node进行通信，老的 Node将会对它进行纠正，得到纠正的 OBJ将修正自己的状态，和新的 Node进行通信。 很多无缝动态负载均衡的服务端宣称自己支持无限的人数，但不意味着 MMORPG游戏的人数上限真的可以无限扩充，因为这样的体系会受制于网络带宽和客户端性能。带宽决定了同一个区域最大广播上限，而客户端性能决定了同一个屏幕到底可以绘制多少个角色。 从无缝地图引入了分布式对象模型开始，已经完全脱离 MUDOS体系，成为一种新的服务端模型。又由于动态负载均衡的引入，让无缝服务器如虎添翼，容纳着超过上一代游戏服务器数倍的人数上限，并提供了更好的游戏体验，我们称其为第三代游戏服务端架构。网游以大型多人角色扮演为开端，RPG网游在相当长的时间里一度占据90%以上，使得基于 MMORPG的服务端架构得到了蓬勃的发展，然而随着玩家对RPG的疲惫，各种非MMORPG游戏如雨后春笋般的出现在人们眼前，受到市场的欢迎。 战网游戏服务器经典战网服务端和 RPG游戏有两个区别：RPG是分区分服的，北京区的用户和广州区的用户老死不相往来。而战网，虽然每局游戏一般都是 8人以内，但全国只有一套服务器，所有的玩家都可以在一起游戏，而玩家和玩家之使用 P2P的方式连接在一起，组成一局游戏： 玩家通过 Match Making 服务器使用：创建、加入、自动匹配、邀请等方式组成一局游戏。服务器会选择一个人做 Host，其他人 P2P连接到做主的玩家上来。STUN是帮助玩家之间建立 P2P的牵引服务器，而由于 P2P联通情况大概只有 75%，实在联不通的玩家会通过 Forward进行转发。 大量的连接对战，体育竞技游戏采用类似的结构。P2P有网状模型（所有玩家互相连接），和星状模型（所有玩家连接一个主玩家）。复杂的游戏状态在网状模型下难以形成一致，因此星状P2P模型经受住了历史的考验。除去游戏数据，支持语音的战网系统也会将所有人的语音数据发送到做主的那个玩家机器上，通过混音去重再编码的方式返回给所有用户。 战网类游戏，以竞技、体育、动作等类型的游戏为主，较慢节奏的 RPG（包括ARPG）有本质上的区别，而激烈的游戏过程必然带来到较 RPG复杂的多的同步策略，这样的同步机制往往带来的是很多游戏结果由客户端直接计算得出，那在到处都是破解的今天，如何保证游戏结果的公正呢？ 主要方法就是投票法，所有客户端都会独立计算，然后传递给服务器。如果结果相同就更新记录，如果结果不一致，会采取类似投票的方式确定最终结果。同时记录本剧游戏的所有输入，在可能的情况下，找另外闲散的游戏客户端验算整局游戏是否为该结果。并且记录经常有作弊嫌疑的用户，供运营人员封号时参考。]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务端常用架构(一)]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[卡牌、跑酷等弱交互服务端卡牌跑酷类因为交互弱，玩家和玩家之间不需要实时面对面PK，打一下对方的离线数据，计算下排行榜，买卖下道具即可，所以实现往往使用简单的 HTTP服务器： 登录时可以使用非对称加密（RSA, DH），服务器根据客户端uid，当前时间戳还有服务端私钥，计算哈希得到的加密 key 并发送给客户端。之后双方都用 HTTP通信，并用那个key进行RC4加密。客户端收到key和时间戳后保存在内存，用于之后通信，服务端不需要保存 key，因为每次都可以根据客户端传上来的 uid 和时间戳以及服务端自己的私钥计算得到。用模仿 TLS的行为，来保证多次 HTTP请求间的客户端身份，并通过时间戳保证同一人两次登录密钥不同。 每局开始时，访问一下，请求一下关卡数据，玩完了又提交一下，验算一下是否合法，获得什么奖励，数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存（可选）。如果要实现通知，那么让客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒，即便两人聊天，延迟也能自适应。 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余，这类游戏因为逻辑简单，玩家之间交互不强，使用 HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了。 第一代游戏服务器 19781978年，英国著名的财经学校University of Essex的学生 Roy Trubshaw编写了世界上第一个MUD程序《MUD1》，在University of Essex于1980年接入 ARPANET之后加入了不少外部的玩家，甚至包括国外的玩家。《MUD1》程序的源代码在 ARPANET共享之后出现了众多的改编版本，至此MUD才在全世界广泛流行起来。不断完善的 MUD1的基础上产生了开源的 MudOS（1991），成为众多网游的鼻祖： MUDOS采用 C语言开发，因为玩家和玩家之间有比较强的交互（聊天，交易，PK），MUDOS使用单线程无阻塞套接字来服务所有玩家，所有玩家的请求都发到同一个线程去处理，主线程每隔1秒钟更新一次所有对象（网络收发，更新对象状态机，处理超时，刷新地图，刷新NPC）。 游戏世界采用房间的形式组织起来，每个房间有东南西北四个方向可以移动到下一个房间，由于欧美最早的网游都是地牢迷宫形式的，因此场景的基本单位被成为 “房间”。MUDOS使用一门称为LPC的脚本语言来描述整个世界（包括房间拓扑，配置，NPC，以及各种剧情）。游戏里面的高级玩家（巫师），可以不断的通过修改脚本来为游戏添加房间以及增加剧情。早年 MUD1上线时只有17个房间，Roy Trubshaw毕业以后交给他的师弟 Richard Battle，在 Richard Battle手上，不断的添加各种玩法到一百多个房间，终于让 MUD发扬光大。 用户使用 Telnet之类的客户端用 Tcp协议连接到 MUDOS上，使用纯文字进行游戏，每条指令用回车进行分割。比如 1995年国内第一款 MUD游戏《侠客行》，你敲入：”go east”，游戏就会提示你：“后花园 - 这里是归云庄的后花园，种满了花草，几个庄丁正在浇花。此地乃是含羞草生长之地。这里唯一的出口是 north。这里有：花待阿牧（A mu），还有二位庄丁（Zhuang Ding）”，然后你继续用文字操作，查看阿牧的信息：“look a mu”，系统提示：“花待阿牧（A mu）他是陆乘风的弟子，受命在此看管含羞草。他看起来三十多岁，生得眉清目秀，端正大方，一表人才。他的武艺看上去【不是很高】，出手似乎【极轻】”。然后你可以选择击败他获得含羞草，但是你吃了含羞草却又可能会中毒死亡。在早期网上资源贫乏的时候，这样的游戏有很强的代入感。 用户数据保存在文件中，每个用户登录时，从文本文件里把用户的数据全部加载进来，操作全部在内存里面进行，无需马上刷回磁盘。用户退出了，或者每隔5分钟检查到数据改动了，都会保存会磁盘。这样的系统在当时每台服务器承载个4000人同时游戏，不是特别大的问题。从1991年的 MUDOS发布后，全球各地都在为他改进，扩充，退出新版本，随着 Windows图形机能的增强。1997游戏《UO》在 MUDOS的基础上为角色增加的x,y坐标，为每个房间增加了地图，并且为每个角色增加了动画，形成了第一代的图形网络游戏。 因为游戏内容基本可以通过 LPC脚本进行定制，所以MUDOS也成为名副其实的第一款服务端引擎，引擎一次性开发出来，然后制作不同游戏内容。后续国内的《万王之王》等游戏，很多都是跟《UO》一样，直接在 MUDOS上进行二次开发，加入房间的地图还有角色的坐标等要素，该架构一直为国内的第一代 MMORPG提供了稳固的支持，直到 2003年，还有游戏基于 MUDOS开发。 虽然后面图形化增加了很多东西，但是这些MMORPG后端的本质还是 MUDOS。随着游戏内容的越来越复杂，架构变得越来越吃不消了，各种负载问题慢慢浮上水面，于是有了我们的第二代游戏服务器。 类型3：第二代游戏服务器 2003 2000年后，网游已经脱离最初的文字MUD，进入全面图形化年代。最先承受不住的其实是很多小文件，用户上下线，频繁的读取写入用户数据，导致负载越来越大。随着在线人数的增加和游戏数据的增加，服务器变得不抗重负。同时早期 EXT磁盘分区比较脆弱，稍微停电，容易发生大面积数据丢失。因此第一步就是拆分文件存储到数据库去。 此时游戏服务端已经脱离陈旧的 MUDOS体系，各个公司在参考 MUDOS结构的情况下，开始自己用 C在重新开发自己的游戏服务端。并且脚本也抛弃了 LPC，采用扩展性更好的 Python或者 Lua来代替。由于主逻辑使用单线程模型，随着游戏内容的增加，传统单服务器的结构进一步成为瓶颈。于是有人开始拆分游戏世界，变为下面的模型： 游戏服务器压力拆分后得意缓解，但是两台游戏服务器同时访问数据库，大量重复访问，大量数据交换，使得数据库成为下一个瓶颈。于是形成了数据库前端代理（DB Proxy），游戏服务器不直接访问数据库而是访问代理，再有代理访问数据库，同时提供内存级别的cache。早年 MySQL4之前没有提供存储过程，这个前端代理一般和 MySQL跑在同一台上，它转化游戏服务器发过来的高级数据操作指令，拆分成具体的数据库操作，一定程度上代替了存储过程： 但是这样的结构并没有持续太长时间，因为玩家切换场景经常要切换连接，中间的状态容易错乱。而且游戏服务器多了以后，相互之间数据交互又会变得比较麻烦，于是人们拆分了网络功能，独立出一个网关服务 Gate（有的地方叫 Session，有的地方叫 LinkSvr之类的，名字不同而已）： 把网络功能单独提取出来，让用户统一去连接一个网关服务器，再有网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网管进行交换。这样类型的服务器基本能稳定的为玩家提供游戏服务，一台网关服务1-2万人，后面的游戏服务器每台服务5k-1w，依游戏类型和复杂度不同而已，图中隐藏了很多不重要的服务器，如登录和管理。这是目前应用最广的一个模型，到今天任然很多新项目会才用这样的结构来搭建。 人都是有惯性的，按照先前的经验，似乎把 MUDOS拆分的越开性能越好。于是大家继续想，网关可以拆分呀，基础服务如聊天交易，可以拆分呀，还可以提供web接口，数据库可以拆分呀，于是有了下面的模型： 这样的模型好用么？确实有成功游戏使用类似这样的架构，并且发挥了它的性能优势，比如一些大型 MMORPG。但是有两个挑战：每增加一级服务器，状态机复杂度可能会翻倍，导致研发和找bug的成本上升；并且对开发组挑战比较大，一旦项目时间吃紧，开发人员经验不足，很容易弄挂。 比如我见过某上海一线游戏公司的一个 RPG上来就要上这样的架构，我看了下他们团队成员的经验，问了下他们的上线日期，劝他们用前面稍微简单一点的模型。人家自信得很，认为有成功项目是这么做的，他们也要这么做，自己很想实现一套。于是他们义无反顾的开始编码，项目做了一年多，然后，就没有然后了。 现今在游戏成功率不高的情况下，一开始上一套比较复杂的架构需要考虑投资回报率，比如你的游戏上线半年内 PCU会去到多少？如果一个 APRG游戏，每组服务器5千人都到不了的话，那么选择一套更为贴近实际情况的结构更为经济。即使后面你的项目真的超过5千人朝着1万人目标奔的话，相信那个时候你的项目已经挣大钱了，你数着钱加着班去逐步迭代，一次次拆分它，相信心里也是乐开花的。 上面这些类型基本都是从拆分 MUDOS开始，将 MUDOS中的各个部件从单机一步步拆成分布式。虽然今天任然很多新项目在用上面某一种类似的结构，或者自己又做了其他热点模块的拆分。因为他们本质上都是对 MUDOS的分解，故将他们归纳为第二代游戏服务器。]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux编程须知(阅读开源服务器源码基础)]]></title>
    <url>%2F2016%2F07%2F04%2Flinux%E7%BC%96%E7%A8%8B%E9%A1%BB%E7%9F%A5(%E9%98%85%E8%AF%BB%E5%BC%80%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%BA%90%E7%A0%81%E5%9F%BA%E7%A1%80)%2F</url>
    <content type="text"><![CDATA[当阅读一些开源服务器源码的时候, 如果不知道以下知识, 就会有知识盲点, 导致不知所云.这篇博客会讲述一些相关的编程知识点, 把之前的笔记总结一下.还是那句老话, 带着问题阅读是最容易让人类迅速进入状态的. 进程的内存布局是什么样的? 线程的同步机制有哪些? 互斥量 条件变量 自旋锁 读写锁 屏障 如何避免死锁 顺序加锁(例如，线程2和线程3只有在获取了锁A之后才能尝试获取锁C(译者注：获取锁A是获取锁C的必要条件)。因为线程1已经拥有了锁A，所以线程2和3需要一直等到锁A被释放。然后在它们尝试对B或C加锁之前，必须成功地对A加了锁。 加锁时限(另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。) 进程间的同步机制(也就是进程间通信, 能通信就能同步了嘛)有哪些? 管道 FIFO 消息队列 信号量 共享内存 套接字 linux的任务调度机制是什么？Linux 分实时进程和普通进程，实时进程应该先于普通进程而运行。而实时进程的调度机制为： FIFO(先入先出服务调度) RR（时间片轮转调度）。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB能取代MySQL或者Redis能取代memcached么]]></title>
    <url>%2F2016%2F06%2F30%2FMongoDB%E8%83%BD%E5%8F%96%E4%BB%A3MySQL%E6%88%96%E8%80%85Redis%E8%83%BD%E5%8F%96%E4%BB%A3memcached%E4%B9%88%2F</url>
    <content type="text"><![CDATA[mongodb和memcached不是一个范畴内的东西。 mongodb是文档型的非关系型数据库，其优势在于查询功能比较强大，能存储海量数据。 mongodb和memcached不存在谁替换谁的问题。和memcached更为接近的是redis。 它们都是内存型数据库，数据保存在内存中，通过tcp直接存取，优势是速度快，并发高，缺点是数据&gt; 类型有限，查询功能不强，一般用作缓存。 一般现在的项目中，用redis来替代memcached。 Redis相比memcached： redis具有持久化机制，可以定期将内存中的数据持久化到硬盘上。 redis具备binlog功能，可以将所有操作写入日志，当redis出现故障，可依照binlog进行数据恢复。 redis支持virtual memory，可以限定内存使用大小，当数据超过阈值，则通过类似LRU的算法把内存中的最不常用数据保存到硬盘的页面文件中。 redis原生支持的数据类型更多，使用的想象空间更大。 mongodb 是文档数据库，用于方便懒人替代mysql等关系数据库的。不过mongodb在内存足够的情况下读写性能不错，大部分应用可以省去cache这一层了。 根据业务场景, 懒人可以使用MongoDB来取代MySQL+memcached,.]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
        <tag>redis</tag>
        <tag>mysql</tag>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAT穿越基础]]></title>
    <url>%2F2016%2F06%2F21%2FNAT%E7%A9%BF%E8%B6%8A%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[NAT有哪些类型及其穿透原理是什么? NAT类型 : 锥NAT 全锥NAT ：全锥NAT 把所有来自相同内部IP 地址和端口的请求映射到相同的外部IP 地址和端口。任何一个外部主机均可通过该映射发送数据包到该内部主机。 限制性锥NAT ：限制性锥NAT 把所有来自相同内部IP 地址和端口的请求映射到相同的外部IP 地址和端口。但是, 和全锥NAT 不同的是：只有当内部主机先给外部主机发送数据包, 该外部主机才能向该内部主机发送数据包。 端口限制性锥NAT ：端口限制性锥NAT 与限制性锥NAT 类似, 只是多了端口号的限制, 即只有内部主机先向外部地址：端口号对发送数据包, 该外部主机才能使用特定的端口号向内部主机发送数据包。 对称NAT ：对称NAT 与上述3 种类型都不同, 不管是全锥NAT ，限制性锥NAT 还是端口限制性锥NAT ，它们都属于锥NAT （Cone NAT ）。当同一内部主机使用相同的端口与不同地址的外部主机进行通信时, 对称NAT 会重新建立一个Session ，为这个Session 分配不同的端口号，或许还会改变IP 地址。 穿透原理 : 查看这篇博客]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL进阶(二)]]></title>
    <url>%2F2016%2F06%2F16%2FMySQL%E8%BF%9B%E9%98%B6(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[事务 MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 ACID 一般来说，事务是必须满足4个条件（ACID）： Atomicity（原子性）、Consistency（一致性或稳定性）、Isolation（隔离性）、Durability（持久性） 事务的原子性：一组事务，要么成功；要么撤回。 稳定性 ：有非法数据（外键约束之类），事务撤回。 隔离性：事务独立运行。一个事务处理后的结果，影响了其他事务，那么其他事务会撤回。事务的100%隔离，需要牺牲速度。 持久性：软、硬件崩溃后，InnoDB数据表驱动会利用日志文件重构修改。可靠性和高速度不可兼得. 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 事物控制语句： BEGIN或START TRANSACTION；显式地开启一个事务； COMMIT；也可以使用COMMIT WORK，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的； ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT； RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier；把事务回滚到标记点； SET TRANSACTION；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。 MYSQL 事务处理主要有两种方法： 用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 事务的4个隔离级别 具体例子参考这篇博客 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 相关术语 脏读 :脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读 :是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻读 :第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 临时表临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。 防SQL注入 防止SQL注入，我们需要注意以下几个要点： 永远不要信任用户的输入。对用户的输入进行校验，可以通过正则表达式，或限制长度；对单引号和 双”-“进行转换等。 永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用存储过程进行数据查询存取。 永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。 不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。 应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装 sql注入的检测方法一般采取辅助软件或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思网站安全平台检测工具。MDCSOFT SCAN等。采用MDCSOFT-IPS可以有效的防御SQL注入，XSS攻击等。 可以总结为 : 连接权限 包装提示 校验输入]]></content>
      <categories>
        <category>DB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL进阶(一)]]></title>
    <url>%2F2016%2F06%2F14%2FMySQL%E8%BF%9B%E9%98%B6(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[引擎 MySQL是有多个引擎的, 不同的场景情况用不同的引擎以提升性能和灵活性. 三大最常用的引擎 : InnoDB : 可靠的事务处理引擎 ,不支持全文搜索 MyISAM : 支持全文搜索, 不支持事务处理 MEMORY : 功能等同于MyISAM, 但数据存储在内存而不是磁盘, 所以速度非常快, 特别适用于临时表(temporary table) 索引 索引是用来改善搜索性能的, 不要滥用索引, 索引会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 索引有三种 : 普通索引normal 唯一索引unique : 它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 全文索引fulltext : 表示 全文搜索的索引。 FULLTEXT 用于搜索很长一篇文章的时候，效果最好。用在比较短的文本，如果就一两行字的，普通的 INDEX 也可以。 建立索引需要遵守的规则 : 选择唯一性索引 为经常需要排序、分组和联合操作的字段建立索引 为常作为查询条件的字段建立索引 限制索引的数目 尽量使用数据量少的索引 尽量使用前缀来索引 删除不再使用或者很少使用的索引 一些优化建议 like和fulltext like没有fulltext快, 但需要大内容的全文本搜索的时候来一发fulltext吧 选择正确数据类型 比如 : 定长的数据类型比可变长度的数据类型性能要高 正确使用索引 勿滥用select *语句 关闭自动提交]]></content>
      <categories>
        <category>DB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[UE4旋转笔记]]></title>
    <url>%2F2016%2F05%2F31%2FUE4%E6%97%8B%E8%BD%AC%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[最近想将一个vector转化为rotator，转而需要考虑UE4到底是怎么旋转的。下面我们做个实验： 我们先将两个staticMesh放入场景，并将它们的rotation调成一样，如上图。上面那个为renti_a_gear，下面那个为renti_a_gear2. 第一种情况： 绕自身坐标系来旋转 如上图，两个staticMesh旋转之后rotation是一样的，可以证明，绕自身坐标系旋转的顺序是Z-&gt;Y-&gt;X 第二种情况： 绕世界坐标系来旋转 如上图，两个staticMesh旋转之后rotation是一样的，可以证明，绕世界坐标系旋转的顺序跟第一种情况刚好反过来， 是X-&gt;Y-&gt;Z]]></content>
      <categories>
        <category>UE4</category>
      </categories>
      <tags>
        <tag>UE4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http报文笔记整理]]></title>
    <url>%2F2016%2F05%2F24%2Fhttp%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B9%8B%E6%8A%A5%E6%96%87%2F</url>
    <content type="text"><![CDATA[看了书和各种网上资料, 学东西嘛, 要做总结, 这些老笔记整理一下, 供以后方便查阅也加强印象和理解. 报文的组成 起始行(start line) 首部(header) 主体(body) 可细分为 : 方法 :如GET, HEAD, POST 关于HTTP请求GET和POST的区别 : 1.提交方式的区别: GET提交，请求的数据会附在URL之后（就是把数据放置在http起始行中），以?分割URL和传输数据，多个参数用&amp;连接;例如：login.action?name=hyddd&amp;password=idontknow&amp;verify=%E4%BD%A0 %E5%A5%BD。如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如： %E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。 POST提交：把提交的数据放置在是HTTP主体中。 因此，GET提交的数据会在地址栏中显示出来，而POST提交，地址栏不会改变 2.传输数据的大小：首先声明,HTTP协议没有对传输的数据大小进行限制，HTTP协议规范也没有对URL长度进行限制。 而在实际开发中存在的限制主要有： GET:特定浏览器和服务器对URL长度有限制，例如IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。 因此对于GET提交时，传输数据就会受到URL长度的限制。 POST:由于不是通过URL传值，理论上数据不受限。但实际各个WEB服务器会规定对post提交数据大小进行限制，Apache、IIS6都有各自的配置。 3.安全性：POST的安全性要比GET的安全性高。注意：这里所说的安全性和上面GET提到的“安全”不是同个概念。上面“安全”的含义仅仅是不作数据修改，而这里安全的含义是真正的Security的含义，比如：通过GET提交数据，用户名和密码将明文出现在URL上，因为 (1)登录页面有可能被浏览器缓存， (2)其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了， 请求URL URL是浏览器寻找信息时所需的资源位置 .URL分为三个部分 : URL文案 服务器位置 资源路径 版本号上图中的HTTP/1.0 200 OK, HTTP/1.0就是版本号 状态码 : 如最著名的404, 302, 如上图中的HTTP/1.0 200 OK中, 状态码就是200 原因短语 如上图中的HTTP/1.0 200 OK中, OK就是原因短语 首部 主体主体部分是可选的, 主体是http报文要传输的内容, 可以承载很多类型的数字数据 : 图片, 视频, 软件应用程序, 电子邮件等]]></content>
      <categories>
        <category>脚本</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[php与cgi]]></title>
    <url>%2F2016%2F05%2F22%2Fhttp%E7%AC%94%E8%AE%B0%E4%B9%8Bphp%E4%B8%8Ecgi%2F</url>
    <content type="text"><![CDATA[首先，CGI是干嘛的？CGI是为了保证web server传递过来的数据是标准格式的，方便CGI程序的编写者。 web server（比如说nginx）只是内容的分发者。比如，如果请求/index.html，那么web server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。好了，如果现在请求的是/index.php，根据配置文件，nginx知道这个不是静态文件，需要去找PHP解析器来处理，那么他会把这个请求简单处理后交给PHP解析器。Nginx会传哪些数据给PHP解析器呢？url要有吧，查询字符串也得有吧，POST数据也要有，HTTP header不能少吧，好的，CGI就是规定要传哪些数据、以什么样的格式传递给后方处理这个请求的协议。仔细想想，你在PHP代码中使用的用户从哪里来的。 当web server收到/index.php这个请求后，会启动对应的CGI程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程。web server再把结果返回给浏览器。 好了，CGI是个协议，跟进程什么的没关系。那fastcgi又是什么呢？Fastcgi是用来提高CGI程序性能的。 提高性能，那么CGI程序的性能问题在哪呢？”PHP解析器会解析php.ini文件，初始化执行环境”，就是这里了。标准的CGI对每个请求都会执行这些步骤（不闲累啊！启动进程很累的说！），所以处理每个时间的时间会比较长。这明显不合理嘛！那么Fastcgi是怎么做的呢？首先，Fastcgi会先启一个master，解析配置文件，初始化执行环境，然后再启动多个worker。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着；当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是fastcgi的对进程的管理。 那PHP-FPM又是什么呢？是一个实现了Fastcgi的程序，被PHP官方收了。 大家都知道，PHP的解释器是php-cgi。php-cgi只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理（皇上，臣妾真的做不到啊！）所以就出现了一些能够调度php-cgi进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。好了PHP-FPM也是这么个东东，在长时间的发展后，逐渐得到了大家的认可（要知道，前几年大家可是抱怨PHP-FPM稳定性太差的），也越来越流行。好了，最后来回来你的问题。 网上有的说，fastcgi是一个协议，php-fpm实现了这个协议 对。 有的说，php-fpm是fastcgi进程的管理器，用来管理fastcgi进程的 对。php-fpm的管理对象是php-cgi。但不能说php-fpm是fastcgi进程的管理器，因为前面说了fastcgi是个协议，似乎没有这么个进程存在，就算存在php-fpm也管理不了他（至少目前是）。 有的说，php-fpm是php内核的一个补丁 以前是对的。因为最开始的时候php-fpm没有包含在PHP内核里面，要使用这个功能，需要找到与源码版本相同的php-fpm对内核打补丁，然后再编译。后来PHP内核集成了PHP-FPM之后就方便多了，使用–enalbe-fpm这个编译参数即可。 有的说，修改了php.ini配置文件后，没办法平滑重启，所以就诞生了php-fpm 是的，修改php.ini之后，php-cgi进程的确是没办法平滑重启的。php-fpm对此的处理机制是新的worker用新的配置，已经存在的worker处理完手上的活就可以歇着了，通过这种机制来平滑过度。 还有的说PHP-CGI是PHP自带的FastCGI管理器，那这样的话干吗又弄个php-fpm出 不对。php-cgi只是解释PHP脚本的程序而已。 参考]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>cgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vector的内存分配与使用注意点]]></title>
    <url>%2F2016%2F05%2F17%2Fvector%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E7%82%B9%2F</url>
    <content type="text"><![CDATA[增长方式为了支持快速随机访问 ， vector 将元素连续存储一一每个元素紧挨着前一个元素存储 。 假定容器中元素是连续存储 的， 且容器的大小是可变的 ， 考虑 向 vector 或 string中添加元素会发生什么 : 如果没有空间容纳新元素，容器不可能简单地将它添加到内存中其他位置一一因为元素必须连续存储。 容器必须分配新的内存空间来保存己有元素和新元素 ， 将已有元素从 旧位置移动到新空 间中， 然后添加新元素，释放旧存储空间 。 如果我们每添加一个新元素， vector 就执行一次这样的内存分配和释放操作 ，性能会慢到不可接受 。 为了避免这种代价，标准库实现者采用了可以减少容器空间重新分配次数的策略。 当不得不在取新的内 存空间 时， vector 和 string 的实现通常会分配比新的空间需求更大的内存空间 。 容器预留这些空间作为备用 ， 可用来保存更多的新元素 。 这样，就不需要每次添加新元素都重新分配容器的内存空间了 。 这种分配策略比每次添加新元素时都重新分配容器内存空间的策略要高效得多 。 其实际性能也表现得足够好一一虽然 vector 在每次重新分配内存空间时都要移动所有元素，但使用 此策略后，其扩张操作通常比 list 和 deque 还要快 。 增长方式的具体实现STL提供了很多泛型容器，如vector，list和map。程序员在使用这些容器时只需关心何时往容器内塞对象，而不用关心如何管理内存，需要用多少内存，这些STL容器极大地方便了C++程序的编写。例如可以通过以下语句创建一个vector，它实际上是一个按需增长的动态数组，其每个元素的类型为int整型： stl::vector&lt;int&gt; array; 拥有这样一个动态数组后，用户只需要调用push_back方法往里面添加对象，而不需要考虑需要多少内存： 12array.push_back(10); array.push_back(2); vector会根据需要自动增长内存，在array退出其作用域时也会自动销毁占有的内存，这些对于用户来说是透明的，stl容器巧妙的避开了繁琐且易出错的内存管理工作。 隐藏在这些容器后的内存管理工作是通过STL提供的一个默认的allocator实现的。当然，用户也可以定制自己的allocator，只要实现allocator模板所定义的接口方法即可，然后通过将自定义的allocator作为模板参数传递给STL容器，创建一个使用自定义allocator的STL容器对象，如： stl::vector&lt;int, UserDefinedAllocator&gt; array; 大多数情况下，STL默认的allocator就已经足够了。这个allocator是一个由两级分配器构成的内存管理器，当申请的内存大小大于128byte时，就启动第一级分配器通过malloc直接向系统的堆空间分配，如果申请的内存大小小于128byte时，就启动第二级分配器，从一个预先分配好的内存池中取一块内存交付给用户，这个内存池由16个不同大小（8的倍数，8~128byte）的空闲列表组成，allocator会根据申请内存的大小（将这个大小round up成8的倍数）从对应的空闲块列表取表头块给用户。 这种做法有两个优点： 1）小对象的快速分配。小对象是从内存池分配的，这个内存池是系统调用一次malloc分配一块足够大的区域给程序备用，当内存池耗尽时再向系统申请一块新的区域，整个过程类似于批发和零售，起先是由allocator向总经商批发一定量的货物，然后零售给用户，与每次都总经商要一个货物再零售给用户的过程相比，显然是快捷了。当然，这里的一个问题时，内存池会带来一些内存的浪费，比如当只需分配一个小对象时，为了这个小对象可能要申请一大块的内存池，但这个浪费还是值得的，况且这种情况在实际应用中也并不多见。 2）避免了内存碎片的生成。程序中的小对象的分配极易造成内存碎片，给操作系统的内存管理带来了很大压力，系统中碎片的增多不但会影响内存分配的速度，而且会极大地降低内存的利用率。以内存池组织小对象的内存，从系统的角度看，只是一大块内存池，看不到小对象内存的分配和释放。 vector的内存释放由于vector的内存占用空间只增不减，比如你首先分配了10,000个字节， 然后erase掉后面9,999个，留下一个有效元素，但是内存占用仍为10,000个。 所有内存空间是在vector析构时候才能被系统回收。empty()用来检测容器是否为空的， clear()可以清空所有元素。但是即使clear()， vector所占用的内存空间依然如故，无法保证内存的回收。 如果需要空间动态缩小，可以考虑使用deque。如果vector，可以用swap()来帮助你释放内存。具体方法如下： vector&lt;Point&gt;().swap(pointVec); //或者pointVec.swap(vector&lt;Point&gt; ()) 迭代器失效看了上方的实现方式, 相信很容易能理解迭代器失效问题了啊 向容器中添加元素和从容器中删除元素 的操作可能(下面将会讨论为什么是可能)会使指向容器元素的指针、引用或法代器失效。 一个失效的指针、引用或法代器将不再表示任何元素 。 使用失效的指针、引用或迭代器是一种严重的程序设计错误，很可能引起与使用未初始化指针一样的问题 以下三种情况都是在ubuntu g++环境测试的, 不同平台不同编译器会有不同表现, 比如同样的代码有可能会在vs下崩溃所以 向容器中添加元素和从容器中删除元素 的操作都需要重置一下迭代器 : i = q.insert(i,22); i = q.erase(i); 删除元素123456789101112131415161718192021//erase操作#include&lt;vector&gt;#include&lt;iostream&gt;using namespace std;int main()&#123; vector&lt;int&gt;q&#123;1,2,3,4,5,6,7,8,9,10&#125;; int cnt = 0; int flag = 0; for(vector&lt;int&gt;::iterator i = q.begin(); i != q.end(); ++i)&#123; ++cnt; if(cnt &gt; 15)&#123; cout&lt;&lt;&quot;gg&quot;&lt;&lt;endl; break; &#125; if(*i == 3) //删除第三个 i = q.erase(i); cout &lt;&lt; *i &lt;&lt; endl; cout &lt;&lt; &amp;(*i) &lt;&lt; endl; &#125; return 0;&#125; output:12345678910111213141516171810xc7215820xc7215c40xc7216050xc7216460xc7216870xc7216c80xc7217090xc72174100xc72178 输出结果分析: 当删除第3个元素以后我们发现第四个元素是紧邻第二个元素的（刚好差一个int的内存） 也就是说vector执行erase（i）后会将迭代器i之后的元素逐个向前移动一个type单位, 所以其实这种c++实现迭代器没失效 但是其他的c++实现, 有可能所有元素全部移到另外一块内存, 比如这段代码放到vs是会崩溃的 添加元素时若预分配的内存足够迭代器就不会失效123456789101112131415161718192021222324252627282930//insert操作//内存充足情况#include&lt;vector&gt;#include&lt;iostream&gt;using namespace std;int main()&#123; vector&lt;int&gt;q&#123;1,2,3,4,5,6,7,8,9,10&#125;; q.push_back(11); cout&lt;&lt;&quot;初始vector分配的容量:&quot;&lt;&lt;q.capacity()&lt;&lt;endl; int cnt = 0; int flag = 0; //flag保证只插入一次 for(vector&lt;int&gt;::iterator i = q.begin(); i != q.end(); ++i)&#123; ++cnt; if(cnt &gt; 15)&#123; cout&lt;&lt; &quot;gg&quot; &lt;&lt;endl; break; &#125; if(*i == 3&amp;&amp;!flag)&#123; flag = 1; i = q.insert(i,22); cout&lt;&lt;&quot;插入元素后vector分配的容量:&quot; &lt;&lt;q.capacity() &lt;&lt;endl; &#125; cout &lt;&lt; *i &lt;&lt; endl; cout &lt;&lt; &amp;(*i) &lt;&lt; endl; &#125; return 0;&#125; 输出为:1234567891011121314151617181920212223242526初始vector分配的容量:20 1 0x1f2188 2 0x1f218c 插入元素后vector分配的容量:20 22 0x1f2190 3 0x1f2194 4 0x1f2198 5 0x1f219c 6 0x1f21a0 7 0x1f21a4 8 0x1f21a8 9 0x1f21ac 10 0x1f21b0 11 0x1f21b4 输出结果分析: 很显然当内存充足的情况下, 执行insert操作只会将迭代器i及i之后的的所有元素向后移动一个type单位.所以这种情况下即使没有使用返回值也不会发生迭代器失效 添加元素时若预分配的内存不足迭代器就会失效1234567891011121314151617181920212223242526272829303132333435//insert操作//内存不够情况#include&lt;vector&gt;#include&lt;iostream&gt;using namespace std;int main()&#123; vector&lt;int&gt;q&#123;1,2,3,4,5,6,7,8,9,10&#125;; // c++11列表初始化 vector&lt;int&gt;::iterator j = q.begin(); j++; cout&lt;&lt;&quot;第二个元素:&quot;&lt;&lt;*j&lt;&lt;endl; cout&lt;&lt;&quot;第二个元素地址:&quot;&lt;&lt;&amp;(*j)&lt;&lt;endl; cout&lt;&lt;&quot;初始vector分配的容量:&quot;&lt;&lt;q.capacity()&lt;&lt;endl; // 有多少元素即分配多少内存 int cnt = 0; int flag = 0; //flag保证只插入一次 for(vector&lt;int&gt;::iterator i = q.begin(); i != q.end(); ++i)&#123; ++cnt; if(cnt &gt; 15)&#123; cout&lt;&lt; &quot;gg&quot; &lt;&lt;endl; break; &#125; if(*i == 3&amp;&amp;!flag)&#123; flag = 1; i = q.insert(i,22); cout&lt;&lt;&quot;\n插入后第二个元素:&quot;&lt;&lt;*j&lt;&lt;endl; cout&lt;&lt;&quot;插入后第二个元素地址:&quot;&lt;&lt;&amp;(*j)&lt;&lt;endl; cout&lt;&lt;&quot;插入元素后vector分配的容量:&quot; &lt;&lt;q.capacity() &lt;&lt;endl; &#125; cout &lt;&lt; *i &lt;&lt; endl; cout &lt;&lt; &amp;(*i) &lt;&lt; endl; &#125; return 0;&#125; output:1234567891011121314151617181920212223242526272829第二个元素:2 第二个元素地址:0xe5215c 初始vector分配的容量:10 1 0xe52158 2 0xe5215c 插入后第二个元素:15007936 插入后第二个元素地址:0xe5215c 插入元素后vector分配的容量:20 22 0xe52190 3 0xe52194 4 0xe52198 5 0xe5219c 6 0xe521a0 7 0xe521a4 8 0xe521a8 9 0xe521ac 10 0xe521b0 输出结果分析: vector内存分配策略为 二倍扩容 , 每次当内存不够的情况下vector会将容量扩展为当前的两倍. 那这些新分配的会在原内存的后面吗？ 根据输出结果显然不是的。 上例代码在插入元素22 后, 新的3号元素内存位置距离上一个元素不是4byte(1个int单位), 也就是说 当vector扩容时, 会在另一个内存分配一段新的内存(原内存的二倍). 并把原内存中的元素全部拷贝到新内存中… 指向二号元素的迭代器在插入操作之后指向的值由2变成了15007936,也验证了上述结论. capacity &amp; size 理解 capacity 和 size 的区别非常重要。 容器的 size 是指它已经保存的元素的数目 ; 而 capacity 则是在不分配新的内存空间的前提下它最多可以保存多少元素。 函数 函数 表述 c.assign(beg,end) 将[beg; end)区间中的数据赋值给c。 c.assign(n,elem) 将n个elem的拷贝赋值给c。 c.at(idx) 传回索引idx所指的数据，如果idx越界，抛出out_of_range。 c.back() 传回最后一个数据，不检查这个数据是否存在。 c.begin() 传回迭代器重的可一个数据。 c.capacity() 返不分配新的内存空间的前提下它最多可以保存多少元素。 c.clear() 移除容器中所有数据。 c.empty() 判断容器是否为空。 c.end() 指向迭代器中的最后一个数据地址。 c.erase(iter) 删除pos位置的数据，传回下一个数据的位置。 c.erase(beg,end) 删除[beg,end)区间的数据，传回下一个数据的位置。 c.front() 传回第一个数据。 get_allocator 使用构造函数返回一个拷贝。 c.insert(iter,elem) 在pos位置插入一个elem拷贝，传回新数据位置。 c.insert(pos,n,elem) 在pos位置插入n个elem数据。无返回值。 c.insert(pos,beg,end) 在pos位置插入在[beg,end)区间的数据。无返回值。 c.max_size() 返回容器中最大数据的数量。 c.pop_back() 删除最后一个数据。 c.push_back(elem) 在尾部加入一个数据。 c.rbegin() 传回一个逆向队列的第一个数据。 c.rend() 传回一个逆向队列的最后一个数据的下一个位置。 c.resize(num) 重新指定队列的长度。 c.reserve() 保留适当的容量。 c.size() 返回容器中实际数据的个数。 c1.swap(c2) 将c1和c2元素互换。 swap(c1,c2) 同上操作。 构造 &amp; 销毁 写法 表述 vector c 创建一个空的vector。 vector c1(c2) 复制一个vector。 vector c(n) 创建一个vector，含有n个数据，数据均已缺省构造产生。 vector c(n, elem) 创建一个含有n个elem拷贝的vector。 vector c(beg,end) 创建一个以[beg;end)区间的vector。 c.~ vector () 销毁所有数据，释放内存。]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>stl</tag>
        <tag>vector</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stl关联容器的特性]]></title>
    <url>%2F2016%2F04%2F26%2Fstl%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8%E7%9A%84%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[概绍 关联容器和 顺序容器有着根本的不问 : 关联容器中的元素是按关键字来保在和访问的 。 与之相对，顺序容器中的元素是按它们在容器中的位置来顺序保存和访问的 。 关联容器支持高效的关键字查找和访问 。 两个主要的关联容器类型是 map set map 中 的元素是一些关键字一值 ( key-value )对 : 关键字起到索 引 的作用，值则表示与索引相关联的数据 。 set 中每个元素只包含一个关键字 : set 支持高效的关键字检查一个给定关键字是否在 set 中 。 例如，在某些文本处理过程中，可以用一个 set 来保存想要忽略的单词。字典则是一个很好的使用 map 的例子 : 可 以将单词作为关键字 ， 将单词释义作为值 。 map &amp; set 的实现因为需要快速定位到键值的关系, 以红黑树的结构实现，其自平衡特性可以让插入删除等操作都可以在O(log n)时间内完成 map的基本操作函数 函数 含义 begin() 返回指向map头部的迭代器 clear(） 删除所有元素 count() 返回指定元素出现的次数 empty() 如果map为空则返回true end() 返回指向map末尾的迭代器 equal_range() 返回特殊条目的迭代器对 erase() 删除一个元素 find() 查找一个元素 get_allocator() 返回map的配置器 insert() 插入元素 key_comp() 返回比较元素key的函数 lower_bound() 返回键值&gt;=给定元素的第一个位置 max_size() 返回可以容纳的最大元素个数 rbegin() 返回一个指向map尾部的逆向迭代器 rend() 返回一个指向map头部的逆向迭代器 size() 返回map中元素的个数 swap() 交换两个map upper_bound() 返回键值&gt;给定元素的第一个位置 value_comp() 返回比较元素value的函数 迭代器失效123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;map&gt;#include &lt;string&gt;#include &lt;iostream&gt;using namespace std;int main()&#123; map&lt;int, string&gt; map_student; map_student.insert(pair&lt;int, string&gt;(1, &quot;stu1&quot;)); map_student.insert(pair&lt;int, string&gt;(2, &quot;stu2&quot;)); map_student.insert(pair&lt;int, string&gt;(3, &quot;stu3&quot;)); map_student.insert(pair&lt;int, string&gt;(4, &quot;stu4&quot;)); map&lt;int, string&gt;::iterator iter; if (map_student.find(2) != map_student.end()) &#123; cout &lt;&lt; &quot;found&quot; &lt;&lt; endl; &#125; for (iter = map_student.begin(); iter != map_student.end(); iter++) &#123; if (iter-&gt;first == 2) &#123; map_student.erase(iter); // 移除元素会让迭代器失效, 所以上面这行应改为:iter = map_student.erase(iter); // map_student.insert(pair&lt;int, string&gt;(5, &quot;stu5&quot;)); // map增加元素并不会使迭代器失效, 因为map增加元素跟vector不一样, // vector要重新找一块内存把当前所有元素复制过去并释放原有元素所以会导致vector的迭代器失效, // 但是map只是直接在红黑树上增加一个结点而已, 并不会移动原有元素, 内存没动, // 自然map的迭代器不会失效了 &#125; cout &lt;&lt; iter-&gt;first &lt;&lt; &quot; : &quot; &lt;&lt; iter-&gt;second &lt;&lt; endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>stl</tag>
        <tag>map</tag>
        <tag>set</tag>
        <tag>pair</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5分钟学会git(二)]]></title>
    <url>%2F2016%2F04%2F13%2F5%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9Agit(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[贮藏stash 设想一个场景，假设我们正在一个新的分支做新的功能，这个时候突然有一个紧急的bug需要修复，而且修复完之后需要立即发布。当然你说我先把刚写的一点代码进行提交不就行了么？这样理论上当然是ok的，但是这会产品垃圾commit，原则上我们每次的commit都要有实际的意义，你的代码只是刚写了一半，还没有什么实际的意义是不建议就这样commit的，那么有没有一种比较好的办法，可以让我暂时切到别的分支，修复完bug再切回来，而且代码也能保留的呢？ 试试git stash吧 git stash : 把当前的文件改动贮藏起来 git stash list: 查看当前有哪些贮藏记录 git stash pop stash_list_id: 会帮你把代码还原，还自动帮你把这条 stash 记录删除 12345678910111213141516171819202122232425b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git checkout old_demo error: Your local changes to the following files would be overwritten by checkout: README.mdPlease, commit your changes or stash them before you can switch branches.Abortingb@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git stash Saved working directory and index state WIP on new_test_branch: b3ad5d2 modify mdHEAD is now at b3ad5d2 modify mdb@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git checkout old_demo Switched to branch &apos;old_demo&apos;Your branch is up-to-date with &apos;origin/old_demo&apos;.b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git checkout new_test_branch Switched to branch &apos;new_test_branch&apos;b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git stash liststash@&#123;0&#125;: WIP on new_test_branch: b3ad5d2 modify mdb@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git stash pop stash@&#123;0&#125;On branch new_test_branchChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)Dropped stash@&#123;0&#125; (88cd440c10c80bb6eaef9f4d86ab4a0be3d6dc00) 对比diff 比如查看当前还未git add的文件的不同 : git diff 比如查看当前已经add 没有commit 的改动 : git diff –cached 比如查看当前所有改动和HEAD的区别(当前还未git add的文件的改动和当前当前已经add 但没有commit 的改动), 也就是上面两条命令的合并 : git diff HEAD 比如查看 commit_id为a和commit_id为b的temp文件夹的差异 : git diff a b temp 处理冲突 假设这样一个场景，A和B两位同学各自开了两个分支来开发不同的功能，大部分情况下都会尽量互不干扰的，但是有一个需求A需要改动一个基础库中的一个类的方法，不巧B这个时候由于业务需要也改动了基础库的这个方法，因为这种情况比较特殊，A和B都认为不会对地方造成影响，等两人各自把功能做完了，需要合并的到主分支 master 的时候，我们假设先合并A的分支，这个时候没问题的，之后再继续合并B的分支，这个时候想想也知道就有冲突了，因为A和B两个人同时更改了同一个地方，Git 本身他没法判断你们两个谁更改的对，但是这个时候他会智能的提示有 conflicts 就像下面这种情况 :1234b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git merge plugin Auto-merging README.mdCONFLICT (content): Merge conflict in README.mdAutomatic merge failed; fix conflicts and then commit the result. 打开READ.md文件一看发现冲突的地方如下:12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADmmmp=======nani&gt;&gt;&gt;&gt;&gt;&gt;&gt; plugin 冲突的地方由 ==== 分出了上下两个部分，上部分一个叫 HEAD 的字样代表是我当前所在分支的代码，下半部分是一个叫 plugin 分支的代码，可以看到 HEAD 是那里加了一行mmmp，而plugin分支则加了一句nani, 所以我们得跟团队的其他人商量一下看看要改成什么样，而且同时也要把那些 «&lt; HEAD、==== 以及 »»»plugin 这些标记符号也一并删除，最后进行一次 commit 就ok了。 标签tag 主要介绍附注标签( annotated tag) 创建附注标签git tag -a v0.1.2 -m “0.1.2版本” 创建轻量标签不需要传递参数，直接指定标签名称即可。创建附注标签时，参数a即annotated的缩写，指定标签类型，后附标签名。参数m指定标签说明，说明信息会保存在标签对象中。 切换到标签与切换分支命令相同，用git checkout [tagname] 查看标签信息用git show命令可以查看标签的版本信息：git show v0.1.2 删除标签误打或需要修改标签时，需要先将标签删除，再打新标签。git tag -d v0.1.2 # 删除标签 参数d即delete的缩写，意为删除其后指定的标签。 给指定的commit打标签打标签不必要在head之上，也可在之前的版本上打，这需要你知道某个提交对象的校验和（通过git log获取）。git tag -a v0.1.1 9fbc3d0 标签发布通常的git push不会将标签对象提交到git服务器，我们需要进行显式的操作： git push origin v0.1.2 # 将v0.1.2标签提交到git服务器git push origin -–tags # 将本地所有标签一次性提交到git服务器]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5分钟学会git(一)]]></title>
    <url>%2F2016%2F04%2F12%2F5%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9Agit(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[我之前有一份私人git笔记老长老长了, 今天得空, 把它浓缩成5分钟版本.感觉纯基础性的东西整理成博客差也差不多了, 还有很多凌乱的工作笔记慢慢在一点一点整理放上来吧,估计下面几篇博客就开始游戏服务器的开发心得之类的了. 本篇博客因为要5分钟撸完git, 所以语言尽量精简, 只说新人必须知道的, 如果要git进阶的, 后面再另写博客说明, 不该说的废话就不说了 安装 sudo apt-get install git 查看状态 比如查看当前分支的状态 : git status, 这条命令也会给很多其他的git命令提示的喔 查看当前在哪个分支 : git branch12345b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git branch master new_test_branch* old_demo plugin 标记为*的那个就是当前分支, 也就是old_demo分支 克隆 比如从我的一个远端github项目克隆一份到本地 : git clone git@github.com:nosix1992/Flock-AI-Fish-Unreal-VR.git这个地址是这样得来的, 如图 : 分支 比如创建一个新的分支test_branch : git branch test_branch 比如切换到分支test_branch : git checkout test_branch 比如把test_branch合并到主分支master上来 : 先切换到master上来git checkout master 然后 git merge test_branch git rebase test_branch rebase 跟 merge 的区别你们可以理解成有两个书架，你需要把两个书架的书整理到一起去，第一种做法是 merge ，比较粗鲁暴力，就直接腾出一块地方把另一个书架的书全部放进去，虽然暴力，但是这种做法你可以知道哪些书是来自另一个书架的；第二种做法就是 rebase ，他会把两个书架的书先进行比较，按照购书的时间来给他重新排序，然后重新放置好，这样做的好处就是合并之后的书架看起来很有逻辑，但是你很难清晰的知道哪些书来自哪个书架的。各有好处的，不同的团队根据不同的需要以及不同的习惯来选择就好。 比如删除分支test_branch : git branch -d test_branch git branch -D test_branch 有些时候可能会删除失败，比如如果a分支的代码还没有合并到master，你执行 git branch -d a 是删除不了的，它会智能的提示你a分支还有未合并的代码，但是如果你非要删除，那就执行 git branch -D a 就可以强制删除a分支。 提交 比如将修改之后的文件test_file加入到暂存区里 : git add test_file 撤销刚刚的git add(也就是说把test_file从暂存区中移出) : git reset HEAD test_file 比如将暂存区里的提交并加入提交信息”update test_file” : git commit -m “update test_file” 把git commit撤销 : 只是把commit撤销并且把文件从暂存区中移出, 但保留已有的文件更改 : 通用命令为 git reset commit_id, 这个commit_id用git log命令来查看, 比如要恢复到刚刚提交的上一次提交的版本, 就用git reset HEAD^(这句命令的意思是说: 恢复到commit id 为HEAD^的版本, HEAD是指向最新的提交，上一次提交是HEAD^,上上次是HEAD^^,也可以写成HEAD～2 ,依次类推. ) 把commit撤销且不保留已有的文件更改 : git reset –hard commit_id 比如只是撤销某个文件test_file的修改 : git checkout –test_file 将代码推到远端 : 这之前的所有这些add, commit都是本地仓库的操作, 比如我们把本地的master分支推到github的那个项目的master分支 : git push origin master]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 很基础的易混淆点（二）]]></title>
    <url>%2F2015%2F12%2F09%2FC%2B%2B%20%E5%BE%88%E5%9F%BA%E7%A1%80%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E7%82%B9%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[位操作运算符的问题二进制的100 的第0位是 01(第二位) 0(第一位) 0(第0位)，所以把一个数的第三位进行清零、置位、取反的操作如下：123456789101112131415161718192021#include &lt;stdio.h&gt;#define Bit3 (0X01&lt;&lt;3)/*对一个数的第三位进行清零、置位、取反*/int main()&#123; int a=15 ; // 0000 1111 printf(&quot;原大小：%d\n&quot;, a); a &amp;= ~Bit3; //清零, 0000 0111 printf(&quot;清零后：%d\n&quot;, a); a |= Bit3; //置位, 0000 1111 printf(&quot;置位后：%d\n&quot;, a); a ^= Bit3; //取反, 0000 0111 printf(&quot;取反后：%d\n&quot;, a); return 0;&#125; 字符串分配的位置问题程序的存储区域分为：代码段、只读数据段、已初始化的读写数据段、未初始化的数据段、堆、栈。1、代码段、只读数据段、已初始化的读写数据段、未初始化的数据段都属于静态区域。2、堆内存只在程序运行时出现，一般有程序员分配和释放。3、栈内存只在程序运行时出现，在函数内部使用的变量，函数参数以及返回值将使用栈空间。1234567891011121314151617char* get_str()&#123; char *str = &quot;hello&quot;; //第一种情况：分配在静态存储区上 //char str[] = &quot;hello&quot;; //第二种情况分配在栈上 return str;&#125;int main()&#123; char* p = get_str(); // 如果是第一种情况，下述打印可以打印出正确的值；但是第二种情况打印结果是错的。 printf(&quot;%s/n&quot;, p); *++p = &apos;a&apos;; // 如果是第一种情况，运行时将会段错误，因为不能修改它； printf(&quot;%s/n&quot;, p); return 0;&#125; 复杂类型的声明和typedef定义 用变量a给出下面的定义:一个有10个指针的数组，该指针指向一个函数，该函数有一个整型参数并返回一个整型数 int (*a[10])(int); typedef表示一个长度为4的数组;typedef int ARR[4]; typedef表示一个函数指针有一个整型参数并返回一个整型数：typedef int（*FUNC）（int）；]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua网络编程环境简单安装]]></title>
    <url>%2F2015%2F11%2F08%2FLua%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Install luasudo apt-get install lua5.1 luarocks到luarocks的官网下载luarocks, 直接apt-get的已经太老旧, 默认的配置文件有错 luarocks 命令： luarocks build XXX 建立/编译一个包 luarocks download XXX 从rocks服务器下载一个指定文件或者包 luarocks help luarocks帮助 luarocks install XXX 安装包 luarocks make XXX 下载并编译包 luarocks pack 打包 luarocks list 显示已安装的列表 luarocks path 返回包地址 luarocks remove XXX 删除 luarocks search Query the LuaRocks repositories luarocks show Shows information about an installed rock. luarocks unpack Unpack the contents of a rock. Install lua-socket如果有安装 Lua 模块的安装和部署工具 – luarocks， 那么一条指令就能安装部署好 LuaSocket： luarocks install luasocket 关于json如果想安装一个解析 JSON(JavaScript Object Notation) 的模块，可以用 search 参数先搜索一下有什么可安装的解析 JSON 的模块： luarocks search json 假设想安装一个名为 json4lua 模块，可以用 install 参数来安装： luarocks install json4lua]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令笔记整理之tcpdump]]></title>
    <url>%2F2015%2F11%2F03%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B9%8Btcpdump%2F</url>
    <content type="text"><![CDATA[强大的抓包工具, 博大精深内容太多, 所以这篇博客整理得只说常用, 具体的参考tcpdump用户手册,tcpdump需要root权限, 所以记得加上sudo 常用参数 -nn选项：意思是说当tcpdump遇到协议号或端口号时，不要将这些号码转换成对应的协议名称或端口名称。比如，大家都知道80是http端口，tcpdump就不会将它显示成http了 -c选项：是Count的含义，这设置了我们希望tcpdump帮我们抓几个包。 -i : 指定哪一张网卡 -l : 使得输出变为行缓冲 -t : 输出时不打印时间戳 -v : 输出更详细的信息 -F : 指定过滤表达式所在的文件, 可以建立了一个filter.txt文本文件来存储过滤表达式，然后通过-F来指定filter.txt -w : 将流量保存到文件中 -r : 读取raw packets文件 常用过滤规则 只看到目的机器dst(比如是qq.com)之间的网络包sudo tcpdump -i eth0 ‘dst qq.com’ 也可以写成 sudo tcpdump -i eth0 ‘dst host qq.com’ 注 : 上述的那个host可以省略tcpdump支持如下的类型： host：指定主机名或IP地址，例如’host roclinux.cn’或’host 202.112.18.34′ net ：指定网络段，例如’arp net 128.3’或’dst net 128.3′ portrange：指定端口区域，例如’src or dst portrange 6000-6008′ port : 端口如果我们没有设置过滤类型，那么默认是host。 只抓udp的包sudo tcpdump -i eth0 ‘udp’ tcpdump具有根据网络包的协议来进行过滤的能力，我们还可以把udp改为ether、ip、ip6、arp、tcp、rarp等 只抓目的机器的某个端口的包(比如只抓baidu.com的53或者80端口的包)sudo tcpdump -i eth0 ‘dst baidu.com and (dst port 53 or dst port 80)’ 通过eth0网卡的，且来源是qq.com服务器或者目标是qq.com服务器的网络包sudo tcpdump -i eth0 ‘host qq.com’ 通过eth0网卡的，且qq.com和baidu.com之间通讯的网络包，或者qq.com和sina.cn之间通讯的网络包tcpdump -i eth0 ‘host qq.com and (baidu.com or sina.cn)’ 获取和baidu.com之间建立TCP三次握手中第一个网络包，即带有SYN标记位的网络包sudo tcpdump -i eth0 ‘tcp[tcpflags] &amp; tcp-syn != 0 and dst host baidu.com’ 注 :因为用proto [ expr : size]语法在写过滤表达式时，你需要把协议格式完全背在脑子里，才能把表达式写对。可这对大多数人来说，可能有些困难。为了让tcpdump工具更人性化一些，有一些常用的偏移量，可以通过一些名称来代替，比如icmptype表示ICMP协议的类型域、icmpcode表示ICMP的code域，tcpflags则表示TCP协议的标志字段域。 更进一步的，对于ICMP的类型域，可以用这些名称具体指代：icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert, icmp-routersolicit, icmp-timxceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply, icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply。 而对于TCP协议的标志字段域，则可以细分为tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg。 输出内容解释1234567891011121314151617b@b-VirtualBox:~$ sudo tcpdump -i eth0 &apos;host baidu.com&apos;tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes06:46:17.487920 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [S], seq 546310089, win 29200, options [mss 1460,sackOK,TS val 1221546 ecr 0,nop,wscale 7], length 006:46:17.530422 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [S.], seq 3245676077, ack 546310090, win 8192, options [mss 1440,sackOK,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,wscale 5], length 006:46:17.530458 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 1, win 229, length 006:46:17.530982 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [P.], seq 1:504, ack 1, win 229, length 50306:46:17.576476 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [.], ack 504, win 216, length 006:46:17.577447 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [P.], seq 1:291, ack 504, win 216, length 29006:46:17.577459 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 291, win 237, length 006:46:17.577482 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [P.], seq 291:452, ack 504, win 216, length 16106:46:17.577485 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, length 006:46:17.866950 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [P.], seq 291:452, ack 504, win 216, length 16106:46:17.866966 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, options [nop,nop,sack 1 &#123;291:452&#125;], length 006:46:27.865805 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, length 006:46:27.909962 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [.], ack 504, win 216, length 006:46:37.925624 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, length 0]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用文本处理命令笔记整理(二)]]></title>
    <url>%2F2015%2F10%2F23%2Flinux%E5%B8%B8%E7%94%A8%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[sed sed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 sed命令 a\ 在当前行下面插入文本。 i\ 在当前行上面插入文本。 c\ 把选定的行改为新的文本。 d 删除，删除选择的行。 D 删除模板块的第一行。 s 替换指定字符 h 拷贝模板块的内容到内存中的缓冲区。 H 追加模板块的内容到内存中的缓冲区。 g 获得内存缓冲区的内容，并替代当前模板块中的文本。 G 获得内存缓冲区的内容，并追加到当前模板块文本的后面。 l 列表不能打印字符的清单。 n 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。 N 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。 p 打印模板块的行。 P(大写) 打印模板块的第一行。 q 退出Sed。 b lable 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。 r file 从file中读行。 t label if分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 T label 错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 w file 写并追加模板块到file末尾。 W file 写并追加模板块的第一行到file末尾。 ! 表示后面的命令对所有没有被选定的行发生作用。 = 打印当前行号码。 把注释扩展到下一个换行符以前。 sed替换标记 g 表示行内全面替换。 p 表示打印行。 w 表示把行写入一个文件。 x 表示互换模板块中的文本和缓冲区中的文本。 y 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \1 子串匹配标记 &amp; 已匹配字符串标记 sed元字符集 ^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 $ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。 . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。 * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。 [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。 [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。 (..) 匹配子串，保存匹配的字符，如s/(love)able/\1rs，loveable被替换成lovers。 &amp; 保存搜索字符用来替换其他字符，如s/love/&amp;/，love这成love。 \&lt; 匹配单词的开始，如:/\ 匹配单词的结束，如/love>/匹配包含以love结尾的单词的行。 x{m} 重复字符x，m次，如：/0{5}/匹配包含5个0的行。 x{m,} 重复字符x，至少m次，如：/0{5,}/匹配至少有5个0的行。 x{m,n} 重复字符x，至少m次，不多于n次，如：/0{5,10}/匹配5~10个0的行。 直接编辑文件选项-i，否则并不会修改源文件 sed常用用法1：增123456b@b-VirtualBox:~/my_temp_test/abc$ cat abc3&amp;&amp; gg&amp;b@b-VirtualBox:~/my_temp_test/abc$ sed -i &apos;/gg/a\hello, my friend&apos; abc3b@b-VirtualBox:~/my_temp_test/abc$ cat abc3&amp;&amp; gg&amp;hello, my friend sed -i ‘/gg/a\hello, my friend’ abc3的含义是：在abc3文件中的“gg”字符串的下一行插入“hello， my friend” sed常用用法2：删123456b@b-VirtualBox:~/my_temp_test/abc$ cat abc3&amp;&amp; gg&amp;hello, my friendb@b-VirtualBox:~/my_temp_test/abc$ sed -i &apos;/gg/d&apos; abc3b@b-VirtualBox:~/my_temp_test/abc$ cat abc3hello, my friend sed -i ‘/gg/d’ abc3的含义是：将abc3文件中所有包含的“gg”字符串的行删除 sed常用用法3：改12345b@b-VirtualBox:~/my_temp_test/abc$ cat abc3hello, my friendb@b-VirtualBox:~/my_temp_test/abc$ sed -i &apos;s/hello/welcome/g&apos; abc3b@b-VirtualBox:~/my_temp_test/abc$ cat abc3welcome, my friend sed -i ‘s/hello/welcome/g’ abc3的含义是：将abc3文件中所有包含的“gg”字符串都修改为“welcome”]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用文本处理命令笔记整理(一)]]></title>
    <url>%2F2015%2F10%2F21%2Flinux%E5%B8%B8%E7%94%A8%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[linux常用文本处理的命令的使用率很高， 所以整理了一些之前的笔记，用markdown来记录备忘。首先抛出问题， 带着问题来学记忆知识更有动力： 如何通过一条命令取得eth0的IP4地址 ： ` ifconfig eth0 | grep -w &apos;inet&apos; | awk &apos;{print $2}&apos; | awk -F: &apos;{print $2}&apos;` 如何通过一条命令替换当前路径下所有文件中的所有“xxx”为“yyy“ ： `ls -alF | grep &apos;^-&apos; | xargs sed -i &apos;s/xxx/yyy/g&apos;` 如何通过一条命令杀掉占用端口34600的进程 ：` sudo lsof -i:34600 | grep -v &apos;PID&apos; | awk &apos;{print $2}&apos; | xargs kill -9` grep grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 -a 不要忽略二进制数据。 -A&lt;显示列数&gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。 -b 在显示符合范本样式的那一行之外，并显示该行之前的内容。 -c 计算符合范本样式的列数。 -C&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。 -d&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。 -e&lt;范本样式&gt; 指定字符串作为查找文件内容的范本样式。 -E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。 -f&lt;范本文件&gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。 -F 将范本样式视为固定字符串的列表。 -G 将范本样式视为普通的表示法来使用。 -h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。 -H 在显示符合范本样式的那一列之前，标示该列的文件名称。 -i 胡列字符大小写的差别。（常用） -l 列出文件内容符合指定的范本样式的文件名称。 -L 列出文件内容不符合指定的范本样式的文件名称。 -n 在显示符合范本样式的那一列之前，标示出该列的编号。 -q 不显示任何信息。 -R/-r 此参数的效果和指定“-d recurse”参数相同。 -s 不显示错误信息。 -v 反转查找。（常用） -w 只显示全字符合的列。（常用） -x 只显示全列符合的列。 -y 此参数效果跟“-i”相同。 -o 只输出文件中匹配到的部分。 awk awk是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 常用命令选项 -F fs fs指定输入分隔符（awk默认的分隔符是空格），fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk 常用用法123456b@b-VirtualBox:~/my_temp_test/abc$ cat abc3klj;k uu&amp;&amp; ss&amp;b@b-VirtualBox:~/my_temp_test/abc$ cat abc3 | awk &apos;&#123;print $NF&#125;&apos;uuss&amp; cat abc3 | awk ‘{print $NF}’的含义是：输出abc3文件的每一行的最后一列12b@b-VirtualBox:~/my_temp_test/abc$ cat abc3 | grep k | awk -F\; &apos;&#123;print $1&#125;&apos;klj cat abc3 | grep k | awk -F\; ‘{print $1}’的含义是：先输入含有k的那一行（即klj；k）， 然后对那一行以；（\;， 这个分号需要转义）分隔，打印出分隔后的第一列（即klj）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hash索引btree索引聚簇索引非聚簇索引]]></title>
    <url>%2F2015%2F09%2F12%2Fhash%E7%B4%A2%E5%BC%95btree%E7%B4%A2%E5%BC%95%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引概要索引是帮助mysql获取数据的数据结构。最常见的索引是 Btree索引 Hash索引 不同的引擎对于索引有不同的支持： Innodb和MyISAM默认的索引是Btree索引； Mermory默认的索引是Hash索引。 Hash索引 Mermory默认的索引是Hash索引。 所谓Hash索引，当我们要给某张表某列增加索引时， 将这张表的这一列进行哈希算法计算，得到哈希值， 排序在哈希数组上。所以Hash索引可以一次定位， 其效率很高，而Btree索引需要经过多次的磁盘IO， 但是innodb和myisam之所以没有采用它，是因为它存在着好多缺点. Hash索引的缺点（1）Hash 索引仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询。 由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。 （2）Hash 索引无法被用来避免数据的排序操作。 由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算； （3）Hash 索引不能利用部分索引键查询。 对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。 （4）Hash 索引在任何时候都不能避免表扫描。 前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。 （5）Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。 对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下 Btree索引 Innodb和MyISAM默认的索引是Btree索引； 至于Btree索引，它是以B+树为存储结构实现的。 但是Btree索引的存储结构在Innodb和MyISAM中有很大区别。 btree索引在MyISAM中的实现在MyISAM中，我们如果要对某张表的某列建立Btree索引的话，如图： 所以我们经常会说MyISAM中数据文件和索引文件是分开的。因此MyISAM的索引方式也称为非聚集,至于辅助索引，类似于主索引，唯一区别就是主索引上的值不能重复，而辅助索引可以重复。 因此当我们根据Btree索引去搜索的时候，若key存在，在data域找到其地址，然后根据地址去表中查找数据记录。 btree索引在Innodb中的实现至于Innodb它跟上面又有很大不同，它的叶子节点存储的并不是表的地址，而是数据 我们可以看到这里并没有将地址放入叶子节点，而是直接放入了对应的数据， 这也就是我们平常说到的，Innodb的索引文件就是数据文件， 那么对于Innodb的辅助索引结构跟主索引也相差很多，如图： 我们可以发现，这里叶子节点存储的是主键的信息， 所以我们在利用辅助索引的时候，检索到主键信息， 然后再通过主键去主索引中定位表中的数据，这就可以说明Innodb中主键之所以不宜用过长的字段，由于所有的辅助索引都包含主索引， 所以很容易让辅助索引变得庞大。 我们还可以发现：在Innodb中尽量使用自增的主键， 这样每次增加数据时只需要在后面添加即可， 非单调的主键在插入时会需要维持B+tree特性而进行分裂调整，十分低效。 Btree索引中的最左匹配原则：Btree是按照从左到右的顺序来建立搜索树的。 比如索引是(name,age,sex)， 会先检查name字段，如果name字段相同再去检查后两个字段。 所以当传进来的是后两个字段的数据（age，sex）， 因为建立搜索树的时候是按照第一个字段建立的，所以必须根据name字段才能知道下一个字段去哪里查询。 所以传进来的是（name，sex）时，首先会根据name指定搜索方向，但是第二个字段缺失，所以将name字段正确的都找到后，然后才会去匹配sex的数据。 建立索引的规则： 1、利用最左前缀：Mysql会一直向右查找直到遇到范围操作（&gt;，&lt;，like、between）就停止匹配。 比如a=1 and b=2 and c&gt;3 and d=6；此时如果建立了（a,b,c,d）索引，那么后面的d索引是完全没有用到，当换成了（a,b,d,c）就可以用到。 2、不能过度索引：在修改表内容的时候，索引必须更新或者重构，所以索引过多时，会消耗更多的时间。 3、尽量扩展索引而不要新建索引 4、最适合的索引的列是出现在where子句中的列或连接子句中指定的列。 5、不同值较少的列不必要建立索引（性别）。 练习题 数据索引的正确是(正确答案A, D) A、一个表只能有一个聚族索引，多个非聚族索引B、字符串模糊查询不适合索引C、哈希 索引有利于查询字段用于大小范围的比较查询D、多余的索引字段会降低性能 Select A,B from Table1 where A between60 and 100 order by B，下面哪些优化sql性能(正确答案B) A、字段A 建立hash索引，字段 B不建立索引B、字段 A 建立btree索引，字段 B不建立索引C、字段A 不建立 索引，字段 B建立btree索引]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>btree索引</tag>
        <tag>hash索引</tag>
        <tag>聚簇索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 很基础的易混淆点（一）]]></title>
    <url>%2F2015%2F09%2F09%2FC%2B%2B%20%E5%BE%88%E5%9F%BA%E7%A1%80%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E7%82%B9%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[###2.1.1 : C++标准规定的各种算术类型的尺寸的最小值, 同时允许编译器赋予这些类型更大的尺寸. 比如char的最小尺寸为8位 执行浮点数运算选用double ，这是因为float 通常精度不够而且双精度浮点 数和单精度浮点数的计算代价相差无儿。事实上， 对于某些机器来说，双精度运 算甚至比单精度还快 ###2.1.2 : 当我们赋给无符号类型一个超出它表示范围的值时，结果是初始值对无符号类型表 示数值总数取棋后的余数。例如， 8 比特大小的un signe d char 可以表示0 至 255 区间内的值，如果我们赋了一个区间以外的值，则实际的结果是该值对256 取模后所得的余数。因此，把 -1 赋给8 比特大小的uns 工gned char 所得的结果 是255 当我们赋给带符号类型一个超出它表示范围的值时，结果是未定义的( undefined )。 此时， 程序，可能继续工作、可能崩溃，也可能生成垃圾数据。 如果表达式里既有带符号类型又有无符号类型， 当带符号类型取值为负时会出现异 常结果， 这是因为带符号数会自动地转换成无符号数。例如，在一个形如a*b 的式子 中，如果a = -1 , b = 1 ，而且a 和b 都是int ，则表达式的值显然为- 1 0 然而，如 果a 是int ， 而b 是unsigned ， 则结果须视在当前机器上int 所占位数而定。在我 们的环境里，结果是4294967295 ###2.2.1 : 如果是内置类型的变量未被显式初始化，它的值由定义的位置决定。定义于任何函数 体之外的变量被初始化为0 。然而如6. 1. 1 节(第1 85 页〉所示， 一种例外情况是，定义 在函数体内部的内置类型变量将不被初始化( tminitialized ) 。一个未被初始化的内置类型 变量的值是未定义的(参见2. 1. 2 节， 第33 页) ，如果试图拷贝或以其他形式谛问此类值 将引发错误 定义于函数体内的内置类型的对象如果没有初始化，时值未定义。类的对象 如果没有显式地初始化，则其位由类确定。 ###2.2.2 : 为了支持分离式编译， C←←语言将声明和定义区分开来。声明( declaration ) 使得名字 为程序所知， 一个文件如果想使用别处定义的名字则必须包含对那个名字的声明。而定义 ( defi nition ) 负责创建与名字关联的实体。 变量声明规定了变量的类型和名字， 在这一点上定义与之相同。但是除此之外，定义 还申请存储空间，也可能会为变量赋一个初始值。 如果想声明一个变量;而非定义它，就在变量名前添加关键字extern ，而且不要显式 地初始化变量: extern int i ; // 声明i 而非定义i int j ; / / 声明并定义j 任何包含了显式初始化的声明即成为定义。我们能给由extern 关键字标记的变量赋 一个初始值，但是这么做也就抵消了extern 的作用。extern 语句如果包含初始值就不 再是声明，而变成定义了: extern doub1e pi = 3 . 1416 ; // 定义 在函数体内部，如果试图初始化一个由extern 关键字标记的变革， 将引发错误 ###2.2.3 : C++也为标准库保留了一些名字。用户在自定义的标识符中不能连续出现两个下画钱，也不能以下画线紧连大写字句开头。此外，定义在函数体外的标识稍不能以下画线 开头。 比如: int _ = 3; 是合法的 ###2.3.1 : 其他所 有引用的类型都要和l 与之绑定的对象严格匹配。而且，引用只能绑定在对象上，而不能与 字面值或某个表达式的计算结果绑定在一起， 相关原因将在2 .4 . 1 节详述: int &amp;refVa14 = 10 ; //错误· 引用类型的初始值必须是一个对象 double dval = 3.14 ; int &amp;refVa15 = dva1 ; // 错误: 此处引用类型的初始位必须是int 型对象 ###2.3.2 : 因为引用不是对象， 没有实际地址，所以不能定义指向引用的指针。 ###2.4 : 默认状态下， const 对象仅在文件内有效 当以编译时初始化的方式定义一个const 对象时，就如对bufSize 的定义一样: const int bufS 工ze = 512; 11 输入缓冲区大小 编译器将在编译过程中把用到该变量的地方都替换成对应的值。也就是说，编译器会找到 代码中所有用到bufSize 的地方，然后用512 替换。 为了执行上述替换， 编译器必须知道变量的初始值。如果程序包含多个文件，则每个 用了co nst 对象的文件都必须得能访问到它的初始值才行。要做到这一点，就必须在每 一个用到变量的文件中都有对它的定义(参见2.2.2 节， 第4 1 页)。为了支持这一用法， 同时避免对同一变量的重复定义，默认情况下， const 对象被设定为仅在文件内有效。、 多个文件中出现了同名的const 变量时，其实等同于在不同文件中分别定义了独立的变量。 某些时候有这样一种const 变量，它的初始值不是一个常量表达式，但又确实有必 要在文件间共享。这种情况f ， 我们不希望编译器为每个文件分别生成独立的变量。相反， 我们想让这类const 对象像其他(非常量)对象一样工作，也就是说，只在一个文件中 定义const ，而在其他多个文件中声明并使用它。 解决的办法是，对于c o nst 变量不管是声明还是定义都添加extern 关键字， 这样 只需定义一次就可以了: // file 1 . cc 定义并初始化了一个常壶，该常量能被其他文件访问 extern const int bufS 工ze = fcn(); // file 1 . h 头文件 extern const int bufSize ; /1 与f ile 1. cc 中定义的bufS 工ze 是同一个 如上述程序所示， fi1e 1. cc 定义并初始化了bufSize 。因为这条语句包含了初始值， 所以它(显然〉是一次定义。然而，因为b ufSize 是←个常量，必须用extern 加以限 定使其被其他文件使用。 file 1. h 头文件中的声明也由extern 做了限定，其作用是指明bufS 工ze 并非本 文件FiIi 独有，它的定义将在别处出现。 ###2.4.1 初始化和对const 的引用 2 . 3 . 1 节(第46 页〉提到， 号| 用的类型必须与其所引用对象的类型→致，但是有两个 例外。第一种例外情况就是在初始化常量引用时允许用任意表达式作为初始值，只要该表 达式的结果能转换成(参见2.1 .2 节，第3 2 页)引用的类型叩可。尤其，允许为一个常量 引用绑定非常量的对象、字面值， 甚至是个-般表达式: int i= 42 ; . const int &amp;r1 = i ; // ft许将c ons t in t&amp;#~ 定到一个普通int 对象上 const int &amp;r2 = 42; // 正确r1 是一个常量引用 const int &amp;r3 = r1 * 2 ; // 正确r3 是一个常受引用 int &amp;r4 = r1 * 2 ; // 错误r4 是一个普通的非常受引用 要想、理解这种例外情况的原因，陆简单的办法是弄清楚当一个常量引用被绑定到另外一种 类型上时到底发生了什么: doub1e dval = 3 . 14 ; const int &amp;ri = dva1 ; 此处ri 引用了一个int 型的数。对口的操作应该是整数运算，但dval 却是一个双精 度浮点数而非整数。因此为了确保让rl 绑定一个整数，编译器把上述代码变成了如下 形式: const int temp = dval; 1/ 由双精度浮点数生成一个临时的整型常量 const int &amp;ri = temp ; 11 让rl 绑定这个临时受 在这种情况下， ri 绑定了一个临时量( tempo ra ry )对象。所谓临时量对象就是当编译器 而要一个空间来暂存表达式的求值结果时临时创建的一个未命名的对象。c++程序员们常 常把临时量对象简称为临时量。 接下来探讨当ri 不是常量时，如果执行了类似于上面的初始化过程将带来什么样的 后果。如果且不是常量，就允许对ri 赋值，这样就会改变ri 所引用对象的值。注意， 此时绑定的对象是一个临时量;而三11:: dvalo 程序员既然让rl 引用dval ， 就肯定想通过 ri 改变dval 的值，否则干什么要给ri 赋值l呢?如此看来， 既然大家基本上不会想着把 引用绑定到临时量上， c++语言也就把这种行为归为非法。 ###2.5.2 和原来另I~些只对应一种特定类型的说明符(比如double) 不|司. auto 让编译器通QÐ 过初始值来推算变量的类型。显然. auto 定义的变量必须有初始值: 使用auto 也能在一条语句中声明多个变量。因为一条声明语句只能有一个基本数据 类型，所以该语句中所有变量的初始基本数据类型都必须一样: int i = 0; const int ci = i; auto &amp;n = i, *p = &amp;ci // 错误i 的类型是int 而&amp; ci 的类型是const int]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>C++Primer</tag>
        <tag>EffectiveC++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb多进程调试]]></title>
    <url>%2F2015%2F08%2F31%2Fgdb%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%B0%83%E8%AF%95%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[gdb多进程调试 set follow-fork-mode [parent|child] set detach-on-fork [on|off] follow-fork-mode detach-on-fork 说明 parent on 只调试主进程（GDB默认） child on 只调试子进程 parent off 同时调试两个进程，gdb跟主进程，子进程block在fork位置 child off 同时调试两个进程，gdb跟子进程，主进程block在fork位置 查询正在调试的进程：info inferiors 切换调试的进程： inferior +inferior number catch fork命令可以捕获进程的创建 attach + pid ， 可以附到一个正在运行的进程上进行调试 gdb多线程调试 show scheduler-locking //显示当前scheduler-locking set scheduler-locking [on/off/step] //设置scheduler-locking on：只有当前调试线程运行，其他线程处于暂停状态。 off：当前调试线程外的其他线程一直在正常运行。 step：其他线程跟随当前调试线程运行，但具体怎么协同运行，测试中无法体现。 注意：set scheduler-locking要处于线程运行环境下才能生效，也就是程序已经运行并且暂停在某个断点处，否则会出现“Target ‘exec’ cannot support this command.”这样的错误；而且经过测试，设置后的scheduler-locking值在整个进程内有效，不属于某个线程。 gdb多进程/多线程调试实战例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158b@b-VirtualBox:~/Documents/temp_test$ sudo gdb ./o_multi_thread_process [sudo] password for b: GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1Copyright (C) 2014 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot;and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from ./o_multi_thread_process...done.(gdb) attach 3027Attaching to program: /home/b/Documents/temp_test/o_multi_thread_process, process 3027Reading symbols from /lib/x86_64-linux-gnu/libpthread.so.0...Reading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libpthread-2.19.so...done.done.[New LWP 3029][Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Loaded symbols for /lib/x86_64-linux-gnu/libpthread.so.0Reading symbols from /lib/x86_64-linux-gnu/libc.so.6...Reading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libc-2.19.so...done.done.Loaded symbols for /lib/x86_64-linux-gnu/libc.so.6Reading symbols from /lib64/ld-linux-x86-64.so.2...Reading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/ld-2.19.so...done.done.Loaded symbols for /lib64/ld-linux-x86-64.so.20x00007f5c9acb8dfd in nanosleep () at ../sysdeps/unix/syscall-template.S:8181 ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) set follow-fork-mode parent (gdb) set detach-on-fork off(gdb) catch forkCatchpoint 1 (fork)(gdb) rStarting program: /home/b/Documents/temp_test/o_multi_thread_process [Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Catchpoint 1 (forked process 3002), 0x00007ffff78b7ee4 in __libc_fork () at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:130130 ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c: No such file or directory.(gdb) info inferiors Num Description Executable * 1 process 2998 /home/b/Documents/temp_test/o_multi_thread_process (gdb) b 14Breakpoint 2 at 0x7ffff78b7f5b: file ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c, line 14.(gdb) info breakpoints Num Type Disp Enb Address What1 catchpoint keep y fork, process 3002 catchpoint already hit 1 time2 breakpoint keep y 0x00007ffff78b7f5b in __libc_fork at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:14(gdb) d 2(gdb) info breakpoints Num Type Disp Enb Address What1 catchpoint keep y fork, process 3002 catchpoint already hit 1 time(gdb) b multi_thread_process.cpp : 14Breakpoint 3 at 0x4007f4: file ./multi_thread_process.cpp, line 14.(gdb) cContinuing.[New process 3002][Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Reading symbols from /usr/lib/debug/lib/x86_64-linux-gnu/libpthread-2.19.so...done.Reading symbols from /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.19.so...done.Reading symbols from /usr/lib/debug/lib/x86_64-linux-gnu/ld-2.19.so...done.Breakpoint 3, main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:1515 if(pid != 0)(gdb) info inferiors Num Description Executable 2 process 3002 /home/b/Documents/temp_test/o_multi_thread_process * 1 process 2998 /home/b/Documents/temp_test/o_multi_thread_process (gdb) inferior 2[Switching to inferior 2 [process 3002] (/home/b/Documents/temp_test/o_multi_thread_process)][Switching to thread 2 (Thread 0x7ffff7fdf740 (LWP 3002))] 0 0x00007ffff78b7ee4 in __libc_fork () at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:130130 ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c: No such file or directory.(gdb) set scheduler-locking on(gdb) b multi_thread_process.cpp : 50Breakpoint 4 at 0x400916: multi_thread_process.cpp:50. (2 locations)(gdb) info threads Id Target Id Frame * 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; 0x00007ffff78b7ee4 in __libc_fork () at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:130 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15(gdb) cContinuing.Breakpoint 3, main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:1515 if(pid != 0)(gdb) info threads Id Target Id Frame * 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15(gdb) cContinuing.ProcessB: 3002 step1ProcessB: 3002 step2ProcessB: 3002 step3^CProgram received signal SIGINT, Interrupt.0x00007ffff78b7de0 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:8181 ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) info threads Id Target Id Frame * 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; 0x00007ffff78b7de0 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:81 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15(gdb) info inferiors Num Description Executable * 2 process 3002 /home/b/Documents/temp_test/o_multi_thread_process 1 process 2998 /home/b/Documents/temp_test/o_multi_thread_process (gdb) inferior 1[Switching to inferior 1 [process 2998] (/home/b/Documents/temp_test/o_multi_thread_process)][Switching to thread 1 (Thread 0x7ffff7fdf740 (LWP 2998))] 0 main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:1515 if(pid != 0)(gdb) list10 &#123;11 int pid;12 13 pid = fork();14 15 if(pid != 0)16 processA();17 else18 processB();19 (gdb) rThe program being debugged has been started already.Start it from the beginning? (y or n) nProgram not restarted.(gdb) cContinuing.ProcessA: 2998 step1[New Thread 0x7ffff77f6700 (LWP 3017)]^CProgram received signal SIGINT, Interrupt.0x00007ffff78b7dfd in nanosleep () at ../sysdeps/unix/syscall-template.S:8181 ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) info threads Id Target Id Frame 3 Thread 0x7ffff77f6700 (LWP 3017) &quot;o_multi_thread_&quot; clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:81 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; 0x00007ffff78b7de0 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:81* 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; 0x00007ffff78b7dfd in nanosleep () at ../sysdeps/unix/syscall-template.S:81(gdb)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>gdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用SIG信号及其键值]]></title>
    <url>%2F2015%2F08%2F04%2FLinux%20%E5%B8%B8%E7%94%A8SIG%E4%BF%A1%E5%8F%B7%E5%8F%8A%E5%85%B6%E9%94%AE%E5%80%BC%2F</url>
    <content type="text"><![CDATA[01 SIGHUP 挂起（hangup） 02 SIGINT 中断，当用户从键盘按^c键或^break键时 03 SIGQUIT 退出，当用户从键盘按quit键时 04 SIGILL 非法指令 05 SIGTRAP 跟踪陷阱（trace trap），启动进程，跟踪代码的执行 06 SIGIOT IOT指令 07 SIGEMT EMT指令 08 SIGFPE 浮点运算溢出 09 SIGKILL 杀死、终止进程 10 SIGBUS 总线错误 11 SIGSEGV 段违例（segmentation violation），进程试图去访问其虚地址空间以外的位置 12 SIGSYS 系统调用中参数错，如系统调用号非法 13 SIGPIPE 向某个非读管道中写入数据 14 SIGALRM 闹钟。当某进程希望在某时间后接收信号时发此信号 15 SIGTERM 软件终止（software termination） 16 SIGUSR1 用户自定义信号1 17 SIGUSR2 用户自定义信号2 18 SIGCLD 某个子进程死 19 SIGPWR 电源故障]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的超级全局变量小结]]></title>
    <url>%2F2015%2F07%2F13%2FPHP%E7%9A%84%E8%B6%85%E7%BA%A7%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[PHP 超级全局变量概绍 PHP中预定义了几个超级全局变量（superglobals） ， 这意味着它们在一个脚本的全部作用域中都可用。 你不需要特别说明，就可以在函数及类中使用。 PHP 超级全局变量列表: $GLOBALS $_SERVER $_REQUEST $_POST $_GET $_FILES $_ENV $_COOKIE $_SESSION $GLOBALS$GLOBALS 是PHP的一个超级全局变量组， 在一个PHP脚本的全部作用域中都可以访问。 $GLOBALS 是一个包含了全部变量的全局组合数组。变量的名字就是数组的键。 以下实例介绍了如何使用超级全局变量 $GLOBALS: 123456789101112&lt;?php $x = 75; $y = 25; function addition() &#123; $GLOBALS[&apos;z&apos;] = $GLOBALS[&apos;x&apos;] + $GLOBALS[&apos;y&apos;]; &#125; addition(); echo $z; ?&gt; 以上实例中 z 是一个$GLOBALS数组中的超级全局变量，该变量同样可以在函数外访问。 $_SERVER$_SERVER 是一个包含了诸如头信息(header)、路径(path)、以及脚本位置(script locations)等等信息的数组。 这个数组中的项目由 Web 服务器创建。 不能保证每个服务器都提供全部项目；服务器可能会忽略一些，或 者提供一些没有在这里列举出来的项目。 以下实例中展示了如何使用$_SERVER中的元素: 12345678910111213&lt;?php echo $_SERVER[&apos;PHP_SELF&apos;];echo &quot;&lt;br&gt;&quot;;echo $_SERVER[&apos;SERVER_NAME&apos;];echo &quot;&lt;br&gt;&quot;;echo $_SERVER[&apos;HTTP_HOST&apos;];echo &quot;&lt;br&gt;&quot;;echo $_SERVER[&apos;HTTP_REFERER&apos;];echo &quot;&lt;br&gt;&quot;;echo $_SERVER[&apos;HTTP_USER_AGENT&apos;];echo &quot;&lt;br&gt;&quot;;echo $_SERVER[&apos;SCRIPT_NAME&apos;];?&gt; $_REQUESTPHP $_REQUEST 用于收集HTML表单提交的数据。 以下实例显示了一个输入字段（input）及提交按钮(submit)的表单(form)。 当用户通过点击 “Submit” 按钮提交表单数据时, 表单数据将发送至标签中 action 属性中指定的脚本文件。 在这个实例中，我们指定文件来处理表单数据。 如果你希望其他的PHP文件来处理该数据，你可以修改该指定的脚本文件名。 然后，我们可以使用超级全局变量 $_REQUEST 来收集表单中的 input 字段数据: 123456789101112131415 &lt;html&gt;&lt;body&gt;&lt;form method=&quot;post&quot; action=&quot;&lt;?php echo $_SERVER[&apos;PHP_SELF&apos;];?&gt;&quot;&gt;Name: &lt;input type=&quot;text&quot; name=&quot;fname&quot;&gt;&lt;input type=&quot;submit&quot;&gt;&lt;/form&gt;&lt;?php $name = $_REQUEST[&apos;fname&apos;]; echo $name; ?&gt;&lt;/body&gt;&lt;/html&gt; $_POSTPHP $_POST 被广泛应用于收集表单数据， 在HTML form标签的指定该属性：”method=”post”。 以下实例显示了一个输入字段（input）及提交按钮(submit)的表单(form)。 当用户通过点击 “Submit” 按钮提交表单数据时, 表单数据将发送至标签中 action 属性中指定的脚本文件。 在这个实例中，我们指定文件来处理表单数据。 如果你希望其他的PHP文件来处理该数据，你可以修改该指定的脚本文件名。 然后，我们可以使用超级全局变量 $_POST 来收集表单中的 input 字段数据: 123456789101112131415&lt;html&gt;&lt;body&gt;&lt;form method=&quot;post&quot; action=&quot;&lt;?php echo $_SERVER[&apos;PHP_SELF&apos;];?&gt;&quot;&gt;Name: &lt;input type=&quot;text&quot; name=&quot;fname&quot;&gt;&lt;input type=&quot;submit&quot;&gt;&lt;/form&gt;&lt;?php $name = $_POST[&apos;fname&apos;]; echo $name; ?&gt;&lt;/body&gt;&lt;/html&gt; $_GETPHP $_GET 同样被广泛应用于收集表单数据， 在HTML form标签的指定该属性：”method=”get”。 $_GET 也可以收集URL中发送的数据。 假定我们有一个包含参数的超链接HTML页面：1234567&lt;html&gt;&lt;body&gt;&lt;a href=&quot;test_get.php?subject=PHP&amp;web=runoob.com&quot;&gt;Test $GET&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 当用户点击链接 “Test $GET”, 参数 “subject” 和 “web” 将发送至”test_get.php”, 你可以在 “test_get.php” 文件中使用 $_GET 变量来获取这些数据。 以下实例显示了 “test_get.php” 文件的代码:123456789&lt;html&gt;&lt;body&gt;&lt;?php echo &quot;Study &quot; . $_GET[&apos;subject&apos;] . &quot; at &quot; . $_GET[&apos;web&apos;];?&gt;&lt;/body&gt;&lt;/html&gt; $_REQUEST、$_POST、$_GET的区别和联系小结1. $_REQUESTphp中$_REQUEST可以获取以POST方法和GET方法提交的数据，但是速度比较慢 2. $_GET用来获取由浏览器通过GET方法提交的数据。GET方法他是通过把参数数据加在提交表单的action属性所指的URL中，值和表单内每个字段一一对应，然后在URL中可以看到，但是有如下缺点： 安全性不好，在URL中可以看得到 传送数据量较小，不能大于2KB。 3. $_POST用来获取由浏览器通过POST方法提交的数据。POST方法他是通过HTTP POST机制，将表单的各个字段放置在HTTP HEADER内一起传送到action属性所指的URL地址中，用户看不到这个过程。他提交的大小一般来说不受限制，但是具体根据服务器的不同，还是略有不同。相对于_GET方式安全性略高 4. $_REQUEST、$_POST、$_GET 的区别和联系$_REQUEST[“参数”]具用$_POST[“参数”] $_GET[“参数”]的功能,但是$_REQUEST[“参数”]比较慢。通过post和get方法提交的所有数据都可以通过$_REQUEST数组[“参数”]获得]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python和lua数据类型的比较]]></title>
    <url>%2F2015%2F07%2F11%2Fpython%E5%92%8Clua%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[Python比较特殊的数据类型：List []例如 :123456789101112#!/usr/bin/python# -*- coding: UTF-8 -*- list = [ &apos;runoob&apos;, 786 , 2.23, &apos;john&apos;, 70.2 ]tinylist = [123, &apos;john&apos;] print list # 输出完整列表print list[0] # 输出列表的第一个元素print list[1:3] # 输出第二个至第三个的元素 print list[2:] # 输出从第三个开始至列表末尾的所有元素print tinylist * 2 # 输出列表两次print list + tinylist # 打印组合的列表 以上实例输出结果：123456[&apos;runoob&apos;, 786, 2.23, &apos;john&apos;, 70.2]runoob[786, 2.23][2.23, &apos;john&apos;, 70.2][123, &apos;john&apos;, 123, &apos;john&apos;][&apos;runoob&apos;, 786, 2.23, &apos;john&apos;, 70.2, 123, &apos;john&apos;] Tuple（元祖）(),相当于只读列表，不可以二次赋值tuple = ( &#39;runoob&#39;, 786 , 2.23, &#39;john&#39;, 70.2 ), 除了元祖用()而list用[], 而且元祖只是可读的, 其他的跟list一毛一样 dictionary（字典）{}，key值对123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*- dict = &#123;&#125;dict[&apos;one&apos;] = &quot;This is one&quot;dict[2] = &quot;This is two&quot; tinydict = &#123;&apos;name&apos;: &apos;john&apos;,&apos;code&apos;:6734, &apos;dept&apos;: &apos;sales&apos;&#125; print dict[&apos;one&apos;] # 输出键为&apos;one&apos; 的值print dict[2] # 输出键为 2 的值print tinydict # 输出完整的字典print tinydict.keys() # 输出所有键print tinydict.values() # 输出所有值 输出结果为:12345This is oneThis is two&#123;&apos;dept&apos;: &apos;sales&apos;, &apos;code&apos;: 6734, &apos;name&apos;: &apos;john&apos;&#125;[&apos;dept&apos;, &apos;code&apos;, &apos;name&apos;][&apos;sales&apos;, 6734, &apos;john&apos;] lua比较特殊的数据类型lua变量 变量在使用前，必须在代码中进行声明，即创建该变量。 编译程序执行代码之前编译器需要知道如何给语句变量开辟存储区，用于存储变量的值。 Lua 变量有三种类型：全局变量、局部变量、表中的域。 Lua 中的变量全是全局变量，那怕是语句块或是函数里，除非用 local 显式声明为局部变量。 局部变量的作用域为从声明位置开始到所在语句块结束。 变量的默认值均为 nil。 test.lua 文件脚本123456789101112131415161718a = 5 -- 全局变量local b = 5 -- 局部变量function joke() c = 5 -- 全局变量 local d = 6 -- 局部变量endjoke()print(c,d) --&gt; 5 nildo local a = 6 -- 局部变量 b = 6 -- 全局变量 print(a,b); --&gt; 6 6endprint(a,b) --&gt; 5 6 执行以上实例输出结果为： 1234$ lua test.lua 5 nil6 65 6 lua的特有的东西table（表）在 Lua 里，table 的创建是通过”构造表达式”来完成， 最简单构造表达式是{}，用来创建一个空表。 也可以在表里添加一些数据，直接初始化表:12345-- 创建一个空的 tablelocal tbl1 = &#123;&#125; -- 直接初始表local tbl2 = &#123;&quot;apple&quot;, &quot;pear&quot;, &quot;orange&quot;, &quot;grape&quot;&#125; Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字或者是字符串。 123456789-- table_test.lua 脚本文件a = &#123;&#125;a[&quot;key&quot;] = &quot;value&quot;key = 10a[key] = 22a[key] = a[key] + 11for k, v in pairs(a) do print(k .. &quot; : &quot; .. v)end 脚本执行结果为：123$ lua table_test.lua key : value10 : 33 不同于其他语言的数组把 0 作为数组的初始索引，在 Lua 里表的默认初始索引一般以 1 开始。12345-- table_test2.lua 脚本文件local tbl = &#123;&quot;apple&quot;, &quot;pear&quot;, &quot;orange&quot;, &quot;grape&quot;&#125;for key, val in pairs(tbl) do print(&quot;Key&quot;, key)end 脚本执行结果为：12345$ lua table_test2.lua Key 1Key 2Key 3Key 4 table 不会固定长度大小，有新数据添加时 table 长度会自动增长，没初始的 table 都是 nil。12345678-- table_test3.lua 脚本文件a3 = &#123;&#125;for i = 1, 10 do a3[i] = ienda3[&quot;key&quot;] = &quot;val&quot;print(a3[&quot;key&quot;])print(a3[&quot;none&quot;]) 脚本执行结果为：123$ lua table_test3.lua valnil]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>lua</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis概要之数据类型]]></title>
    <url>%2F2015%2F07%2F11%2Fredis%E6%A6%82%E8%A6%81%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Redis简介要义 Redis运行在内存中但是可以持久化到磁盘, 重启的时候可以再次加载进行使用 Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行 Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作 Redis支持数据的备份，即master-slave模式的数据备份 Redis数据类型 Redis的数据类型很重要, 这是他做很多事情的基础, 不理解的话很难用好 String(字符串)string是redis最基本的类型，你可以理解成与Memcached一模一样的类型， 一个key对应一个value。 string类型是二进制安全的。 二进制安全的意思是redis的string可以包含任何数据。 比如jpg图片或者序列化的对象 。 string类型是Redis最基本的数据类型，一个键最大能存储512MB。 实例 : 1234redis 127.0.0.1:6379&gt; SET name &quot;runoob&quot;OKredis 127.0.0.1:6379&gt; GET name&quot;runoob&quot; Hash（哈希）Redis hash 是一个键名对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 实例 :123456789127.0.0.1:6379&gt; HMSET user:1 username runoob password runoob points 200OK127.0.0.1:6379&gt; HGETALL user:11) &quot;username&quot;2) &quot;runoob&quot;3) &quot;password&quot;4) &quot;runoob&quot;5) &quot;points&quot;6) &quot;200&quot; 以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象。 实例中我们使用了 Redis HMSET, HGETALL 命令，user:1 为键值。 每个 hash 可以存储 232 -1 键值对（40多亿）。 List（列表）Redis 列表是简单的字符串列表，按照插入顺序排序。 你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 实例 :1234567891011redis 127.0.0.1:6379&gt; lpush runoob redis(integer) 1redis 127.0.0.1:6379&gt; lpush runoob mongodb(integer) 2redis 127.0.0.1:6379&gt; lpush runoob rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange runoob 0 101) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;redis 127.0.0.1:6379&gt; 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。 Set（集合）Redis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 sadd 命令添加一个string元素到,key对应的set集合中，成功返回1, 如果元素已经在集合中返回0,key对应的set不存在返回错误。 sadd key member 实例 :12345678910111213redis 127.0.0.1:6379&gt; sadd runoob redis(integer) 1redis 127.0.0.1:6379&gt; sadd runoob mongodb(integer) 1redis 127.0.0.1:6379&gt; sadd runoob rabitmq(integer) 1redis 127.0.0.1:6379&gt; sadd runoob rabitmq(integer) 0redis 127.0.0.1:6379&gt; smembers runoob1) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot; 注意：以上实例中 rabitmq 添加了两次， 但根据集合内元素的唯一性，第二次插入的元素将被忽略。 集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。 zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 zadd 命令添加元素到集合，元素在集合中存在则更新对应scorezadd key score member实例 :12345678910111213redis 127.0.0.1:6379&gt; zadd runoob 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 0redis 127.0.0.1:6379&gt; ZRANGEBYSCORE runoob 0 10001) &quot;redis&quot;2) &quot;mongodb&quot;3) &quot;rabitmq&quot;]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[socket可读可写条件与非阻塞connect或accept浅析]]></title>
    <url>%2F2015%2F06%2F22%2Fsocket%E5%8F%AF%E8%AF%BB%E5%8F%AF%E5%86%99%E6%9D%A1%E4%BB%B6%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9Econnect%E6%88%96accept%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[socket可读的条件: socket的接收缓冲区中的数据字节大于等于该socket的接收缓冲区低水位标记的当前大小。对这样的socket的读操作将不阻塞并返回一个大于0的值(也就是返回准备好读入的数据)。我们可以用SO_RCVLOWATsocket选项来设置该socket的低水位标记。对于TCP和UDP .socket而言，其缺省值为1. 该连接的读这一半关闭(也就是接收了FIN的TCP连接)。对这样的socket的读操作将不阻塞并返回0 给监听套接字准备好新连接 有一个socket有异常错误条件待处理.对于这样的socket的读操作将不会阻塞,并且返回一个错误(-1),errno则设置成明确的错误条件.这些待处理的错误也可通过指定socket选项SO_ERROR调用getsockopt来取得并清除; socket可写的条件: socket的发送缓冲区中的数据字节大于等于该socket的发送缓冲区低水位标记的当前大小。对这样的socket的写操作将不阻塞并返回一个大于0的值(也就是返回准备好写入的数据)。我们可以用SO_SNDLOWAT socket选项来设置该socket的低水位标记。对于TCP和UDPsocket而言，其缺省值为2048 该连接的写这一半关闭。对这样的socket的写操作将产生SIGPIPE信号，该信号的缺省行为是终止进程。 使用非阻塞connect的套接字已建立连接, 或者connect已经以失败告终 有一个socket异常错误条件待处理.对于这样的socket的写操作将不会阻塞并且返回一个错误(-1),errno则设置成明确的错误条件.这些待处理的错误也可以通过指定socket选项SO_ERROR调用getsockopt函数来取得并清除; 非阻塞connect/accept相关述的各种条件可以大体总结为下图 注意 : 当socket异常错误的时候socket是可读并可写的, 所以在非阻塞connect(判断是否可写)/accept(判断是否可读)的时候要特别注意这种情况, 要用getsockopt函数, 使用SO_ERROR选项来检查处理.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>socket</tag>
        <tag>非阻塞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关系型数据库与NoSQL的爱恨情仇]]></title>
    <url>%2F2015%2F05%2F20%2F%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8ENoSQL%E7%9A%84%E7%88%B1%E6%81%A8%E6%83%85%E4%BB%87%2F</url>
    <content type="text"><![CDATA[NoSQL因关系数据库的不足而生随着互联网的不断发展，各种类型的应用层出不穷，所以导致在这个云计算的时代， 对技术提出了更多的需求，主要体现在下面这四个方面： 低延迟的读写速度：应用快速地反应能极大地提升用户的满意度; 支撑海量的数据和流量：对于搜索这样大型应用而言，需要利用PB级别的数据和能应对百万级的流量; 大规模集群的管理：系统管理员希望分布式应用能更简单的部署和管理; 庞大运营成本的考量：IT经理们希望在硬件成本、软件成本和人力成本能够有大幅度地降低; 目前世界上主流的存储系统大部分还是采用了关系型数据库，其主要有一下优点： 事务处理—保持数据的一致性； 由于以标准化为前提，数据更新的开销很小（相同的字段基本上只有一处）； 可以进行Join等复杂查询。 虽然关系型数据库已经在业界的数据存储方面占据不可动摇的地位，但是由于其天生的几个限制， 使其很难满足上面这几个需求： 扩展困难：由于存在类似Join这样多表查询机制，使得数据库在扩展方面很艰难; 读写慢：这种情况主要发生在数据量达到一定规模时由于关系型数据库的系统逻辑非常复杂，使得其非常容易发生死锁等的并发问题，所以导致其读写速度下滑非常严重; 成本高：企业级数据库的License价格很惊人，并且随着系统的规模，而不断上升; 有限的支撑容量：现有关系型解决方案还无法支撑Google这样海量的数据存储; 业界为了解决上面提到的几个需求，推出了多款新类型的数据库，并且由于它们在设计上和传统的NoSQL数据库相比有很大的不同，所以被统称为“NoSQL”系列数据库。 总的来说，在设计上，它们非常关注对数据高并发地读写和对海量数据的存储等，与关系型数据库相比，它们在架构和数据模型方量面做了“减法”， 而在扩展和并发等方面做了“加法”。 现在主流的NoSQL数据库有MongoDB和Redis以及BigTable、Hbase、Cassandra、SimpleDB、CouchDB、等。 接下来，将关注NoSQL数据库到底存在哪些优缺点。 NoSQL的优缺点在优势方面，主要体现在下面这三点： 简单的扩展：典型例子是Cassandra，由于其架构是类似于经典的P2P，所以能通过轻松地添加新的节点来扩展这个集群; 快速的读写：主要例子有redis，由于其逻辑简单，而且纯内存操作，使得其性能非常出色，单节点每秒可以处理超过10万次读写操作; 低廉的成本：这是大多数分布式数据库共有的特点，因为主要都是开源软件，没有昂贵的License成本; 但瑕不掩瑜，NoSQL数据库还存在着很多的不足，常见主要有下面这几个： 不提供对SQL的支持：如果不支持SQL这样的工业标准，将会对用户产生一定的学习和应用迁移成本; 支持的特性不够丰富：现有产品所提供的功能都比较有限，大多数NoSQL数据库都不支持事务，也不像MS SQL Server和Oracle那样能提供各种附加功能，比如BI和报表等; 现有产品的不够成熟：大多数产品都还处于初创期，和关系型数据库几十年的完善不可同日而语; 上面NoSQL产品的优缺点都是些比较共通的，在实际情况下，每个产品都会根据自己所遵从的数据模型和CAP理念而有所不同.]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型之详述C++对象的内存布局]]></title>
    <url>%2F2015%2F05%2F03%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E4%B9%8B%E8%AF%A6%E8%BF%B0C%2B%2B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[转自CDSN阅读原文 在C++对象模型之简述C++对象的内存布局一文中，详细分析了各种成员变量和成员函数对一个类（没有任何继承的）对象的内存分布的影响，及详细讲解了如何遍历对象的内存，包括虚函数表。如果你在阅读本文之前，还没有看过C++对象模型之简述C++对象的内存布局一文，建议先阅读一下。而本文主要讨论继承对于对象的内存分布的影响，包括：继承后类的对象的成员的布局、继承对于虚函数表的影响、virtual函数机制如何实现、运行时类型识别等。由于在C++中继承的关系比较复杂，所以本文会讨论如下的继承情况：1）单一继承2）多重继承3）重复继承4）单一虚拟继承5）钻石型虚拟继承此外，当一个类作为一个基类时，它的析构函数应该是virtual函数，这样下面的代码才能正确地运行Base p = new&nbsp;Derived;…delete p;在本文的例子，为了验证虚函数表的内容，会遍历并调用虚函数表中的所有函数。但是当析构函数为virtual时，在遍历的过程中就会调用到对象的析构函数，从而对对象进行析构的操作，导致接下来的调用出错。但是本文的目的是分析和验证C++对象的内存布局，而不是设计一个软件，析构函数为非virtual函数，并不会影响我们的分析和理解，因为virtual析构函数与其他的virtual函数是一样的，只是做的事不一样。所以在本文中的例子中，析构函数均不为virtual，特此说明一下。同时为了调用的方便，所有的virtual的函数原型均为：返回值为void，参数也为void。注：以下的例子中的测试环境为：32位Ubuntu 14.04 g++ 4.8.2，若在不同的环境中进行测试，结果可能有不同。1、根据指向虚函数表的指针（vptr）遍历虚函数表由于在访问对象的内存时，都要遍历虚函数表来确定虚函数表中的内容，所以对这部分的功能抽象出来，写成一个函数，如下：void visitVtbl(int **vtbl, int count){ cout &lt;&lt; vtbl &lt;&lt; endl; cout &lt;&lt; &quot;\t[-1]: &quot; &lt;&lt; (long)vtbl[-1] &lt;&lt; endl; typedef void (FuncPtr)(); for (int i = 0; vtbl[i] &amp;&amp; i &lt; count; ++i) { cout &lt;&lt; &quot;\t[&quot; &lt;&lt; i &lt;&lt; &quot;]: &quot; &lt;&lt; vtbl[i] &lt;&lt; &quot; -&gt; &quot;; FuncPtr func = (FuncPtr)vtbl[i]; func(); }}代码解释：参数vtbl为虚函数表的第一个元素的地址，也就是对象中的vptr的值。参数count指的是该虚函数表中虚函数的数量。由于虚函数表中保存的信息并不全是虚函数的地址，也不是所有的虚函数表中都以NULL表示虚函数表中的函数地址已经到了尽头。所以为了让测试程序更好地运行，所以加上这一参数。虚函数表保存的是函数的指针，若把虚函数表当作一个数组，则要指向该数组需要一个双指针，即参数中的int vtbl，获取函数指针的值，即获取数组中元素的值，可以通过vtbl[i]来获得。虚函数表中还保存着对象的类型信息，通常为了便于查找对象的类型信息，使用虚函数表中的索引（下标）为-1的位置保存该类对应的类型信息对象（即类std::type_info的对象）的地址，即保存在第一个虚函数的地址之前。2、单一继承类的具体代码如下：class Base{ public: Base() { mBase1 = 101; mBase2 = 102; } virtual void func1() { cout &lt;&lt; &quot;Base::func1()&quot; &lt;&lt; endl; } virtual void func2() { cout &lt;&lt; &quot;Base::func2()&quot; &lt;&lt; endl; } private: int mBase1; int mBase2;};class Derived : public Base{ public: Derived(): Base() { mDerived1 = 1001; mDerived2 = 1002; } virtual void func2() { cout &lt;&lt; &quot;Derived::func2()&quot; &lt;&lt; endl; } virtual void func3() { cout &lt;&lt; &quot;Derived::func3()&quot; &lt;&lt; endl; } private: int mDerived1; int mDerived2;};使用如下的代码进行测试：int main(){ Derived d; char p = (char)&amp;d; visitVtbl((int)(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; return 0;}代码解释：在测试代码中，最难明白的就是以下语句中的参数：visitVtbl((int**)(int)p, 3);char指针p指向了对象中的vptr，由于vptr也是一个指针，所以p应该是一个双指针，对其解引用（*p）可以获得vptr的值。然而在同一个系统中，无论是什么类型的指针，其占用的内存大小都是相同的（一般在32位系统中为4字节，64位系统中为8字节），所以可以通过以下语句获取vptr的值：&nbsp;(int)(int)p;该语句，进行了三件事：1）把char指针p进行类型转换，转换成int，即（int**)p;2）通过解引用运行符“”，获得vptr的值，类型为int。其实vptr本质是一个双指针，但是所有的指针占用的内存都是相等的，所以这个操作并不会导致地址值的截断。即(int)p;3）由于vptr本质是一个双指针，所以再一次把vptr转化成一个双指针。即(int)(int**)p;注：在不少的文章中，可以看到作者把虚函数表中的项的内容当做一个整数来对待，但是本文中，我并没有这样做。因为在不同的系统（32位或64位）中的指针的位数是不同的，为了让代码能兼容32位和64位的系统，这里统一把虚函数表中的项当指针看待。在以后的例子若中出现相似的代码，都是相同的原理，不再解释。其运行结果如下：根据测试的输出的结果，可以得出类Derived的对象的内存布局图如下：据此，针对单一继承可以得出以下结论：1）vptr位于对象的最前端。2）非static的成员变量根据其继承顺序和声明顺序排在vptr的后面。3）派生类继承基类所声明的虚函数，即基类的虚函数地址会被复制到派生类的虚函数表中的相应的项中。4）派生类中新加入的virtual函数跟在其继承而来的virtual的后面，如本例中，子类增加的virtual函数func3被添加到func2后面。5）若子类重写其父类的virtual函数，则子类的虚函数表中该virtual函数对应的项会更新为新函数的地址，如本例中，子类重写了virtual函数func2，则虚函数表中func2的项更新为子类重写的函数func2的地址。3、多重继承类的具体代码如下：class Base1{ public: Base1() { mBase1 = 101; } virtual void funcA() { cout &lt;&lt; &quot;Base1::funcA()&quot; &lt;&lt; endl; } virtual void funcB() { cout &lt;&lt; &quot;Base1::funcB()&quot; &lt;&lt; endl; } private: int mBase1;};class Base2{ public: Base2() { mBase2 = 102; } virtual void funcA() { cout &lt;&lt; &quot;Base2::funcA()&quot; &lt;&lt; endl; } virtual void funcC() { cout &lt;&lt; &quot;Base2::funcC()&quot; &lt;&lt; endl; } private: int mBase2;};class Derived : public Base1, public Base2{ public: Derived(): Base1(), Base2() { mDerived = 1001; } virtual void funcD() { cout &lt;&lt; &quot;Derived::funcD()&quot; &lt;&lt; endl; } virtual void funcA() { cout &lt;&lt; &quot;Derived::funcA()&quot; &lt;&lt; endl; } private: int mDerived;};使用如下代码进行测试：int main(){ Derived d; char p = (char)&amp;d; visitVtbl((int**)(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); visitVtbl((int)*(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; return 0;}其运行结果如下：根据测试的输出的结果，可以得出类Derived的对象的内存布局图如下：据此，针对多重继承可以得出以下结论：1）在多重继承下，一个子类拥有n-1张额外的虚函数表，n表示其上一层的基类的个数。也就是说，在多重继承下，一个派生类会有n个虚函数表。其中一个为主要实例，它与第一个基类（如本例中的Base1）共享，其他的为次要实例，与其他基类（如本例中的Base2）有关。2）子类新声明的virtual函数，放在主要实例的虚函数表中。如本例中，子类新声明的与Base1共享的虚函数表中。3）每一个父类的子对象在子类的对象保持原样性，并依次按声明次序排列。4）若子类重写virtual函数，则其所有父类中的签名相同的virtual函数被会被改写。如本例中，子类重写了funcA函数，则两个虚函数表中的funcA函数的项均被更新为子类重写的函数的地址。这样做的目的是为了解决不同的父类类型的指针指向同一个子类实例，而能够调用到实际的函数。4、重复继承所谓的重复继承，就是某个父类被间接地重复继承了多次。类的具体代码如下：class Base{ public: Base() { mBase = 11; } virtual void funcA() { cout &lt;&lt; &quot;Base::funcA()&quot; &lt;&lt; endl; } virtual void funcX() { cout &lt;&lt; &quot;Base::funcX()&quot; &lt;&lt; endl; } protected: int mBase;};class Base1 : public Base{ public: Base1(): Base() { mBase1 = 101; } virtual void funcA() { cout &lt;&lt; &quot;Base1::funcA()&quot; &lt;&lt; endl; } virtual void funcB() { cout &lt;&lt; &quot;Base1::funcB()&quot; &lt;&lt; endl; } private: int mBase1;};class Base2 : public Base{ public: Base2(): Base() { mBase2 = 102; } virtual void funcA() { cout &lt;&lt; &quot;Base2::funcA()&quot; &lt;&lt; endl; } virtual void funcC() { cout &lt;&lt; &quot;Base2::funcC()&quot; &lt;&lt; endl; } private: int mBase2;};class Derived : public Base1, public Base2{ public: Derived(): Base1(), Base2() { mDerived = 1001; } virtual void funcD() { cout &lt;&lt; &quot;Derived::funcD()&quot; &lt;&lt; endl; } virtual void funcA() { cout &lt;&lt; &quot;Derived::funcA()&quot; &lt;&lt; endl; } private: int mDerived;};使用如下代码进行测试：int main(){ Derived d; char p = (char)&amp;d; visitVtbl((int)(int)p, 4); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); visitVtbl((int**)(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; return 0;}其运行结果如下：根据测试的输出的结果，可以得出类Derived的对象的内存布局图如下：据此，针对重复继承可以得出以下结论：1）重复继承后，位于继承层次顶端的父类Base分别被子类Base1和Base2继承，并被类Derived继承。所以在D中有类的对象中，存在Base1的子对象，同时也存在Base2的子对象，这两个子对象都拥有Base子对象，所以Base子对象（成员mBase）在Derived中存在两份。2）二义性的原因。由于在子类的对象中，存在两份父类的成员，当在Derived类中使用如下语句：mBase = 1;就会产生歧义。因为在该对象中有两处的变量的名字都叫mBase，所以编译器不能判断究竟该使用哪一个成员变量。所以在访问Base中的成员时，需要加上域作用符来明确说明是哪一个子类的成员，如：Base1::mBase = 1;重复继承可能并不是我们想要的，C++提供虚拟继承来解决这个问题，下面详细讲解虚拟继承。5、单一虚拟继承具体代码如下（类的实现与重复继承中的代码相同，只是Base1的继承关系变为虚拟继承）：class Base { …… };class Base1 : virtual public Base { …… };使用如下的代码进行测试：int main(){ Base1 b1; char p = (char)&amp;b1; visitVtbl((int)*(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); visitVtbl((int)(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; return 0;}其运行结果如下：根据测试的输出的结果，可以得出类B1的对象的内存布局图如下：通过与普通的单一继承比较可以知道，单一虚继承与单一继承的对象的内存布局存在明显的不同。表现为以下的方面：1）成员的顺序问题。在普通的单一继承中，基类的成员位于派生类的成员之前。而在单一虚继承中，首先是其普通基类的成员，接着是派生类的成员，最后是虚基类的成员。2）vptr的个数问题。在普通的单一继承中，派生类只有一个虚函数表，所以其对象只有一个vptr。而在单一虚继承中，派生类的虚函数表有n个（n为虚基类的个数）额外的虚数函数表，即总有n+1个虚函数表。3）派生自虚基类的派生类的虚函数表中，并不含有虚基类中的virtual函数，但是派生类重写的virtual函数会在所有虚函数表中得到更新。如本例中，第一个虚函数表中，并不含有Base::funcX的函数地址。注：在测试代码中，我把count传递的值为3，而结果却只调用了2个函数，可见并不是count参数限制了虚函数表的遍历。一个类如果内含一个或多个虚基类子对象，像Base1那样，将会被分割为两部分：一个不变区域和一个共享区域。不变区域中的数据，不管后续如何变化，总是拥有固定的偏移量（从对象的开头算起），所以这一部分可以被直接存取。共享区域所对应的就是虚基类子对象。6、钻石型虚拟继承具体代码如下（类的实现与重复继承中的代码相同，只是Base1和Base2的继承关系变为虚拟继承）：class Base { …… };class Base1 : virtual public Base { …… };class Base2 : virtual public Base { …… };class Derived : public Base1, public Base2 { …… };使用如下的代码对对象的内存布局进行测试：int main(){ Derived d; char p = (char)&amp;d; visitVtbl((int**)(int)p, 3); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); visitVtbl((int)*(int)p, 2); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; p += sizeof(int); visitVtbl((int)(int)p, 2); p += sizeof(int); cout &lt;&lt; (int)p &lt;&lt; endl; return 0;}其运行结果如下：根据测试的输出的结果，可以得出类Derived的对象的内存布局图如下：使用虚继承后，在派生类的对象中只存在一份的Base子对象，从而避免了二义性。由于是多重继承，且有一个虚基类（Base），所以Derived类拥有三个虚函数表，其对象存在三个vptr。如上图所示，第一个虚函数表是由于多重继承而与第一基类（Base1）共享的主要实例，第二个虚函数表是与其他基类（Base2）有关的次要实例，第三个是虚基类的虚函数表。类Derived的成员与Base1中的成员排列顺序相同，首先是以声明顺序排列其普通基类的成员，接着是派生类的成员，最后是虚基类的成员。派生自虚基类的派生类的虚函数表中，也不含有虚基类中的virtual函数，派生类重写的virtual函数会在所有虚函数表中得到更新。在类Derived的对象中，Base（虚基类）子对象部分为共享区域，而其他部分为不变区域。7、关于虚析构函数的说明上面的的例子中，为了让测试程序正常的运行，我们都没有定义一个virtual的析构函数，但是这并不表示它不是本文的讨论内容。若基类声明了一个virtual析构函数，则其派生类的析构函数会更新其所有的虚函数表中的析构函数的项，把该项中的函数地址更新为派生类的析构函数的函数地址。因为当基类的析构函数为virtual时，若用户不显示提供一个析构函数，编译器则会自动合成一个，所以若基类声明了一个virtual析构函数，则其派生 类中必然存在一个virtual的析构函数，并用这个virutal析构函数更新虚函数表。8、类型信息在C++中，可以使用关键字typeid来获得一个对象所对应的类型信息，例如，以下代码：Base p;……cout &lt;&lt; typeid(p).name() &lt;&lt; endl;由于p是一个指针，它可以指向一个Base的对象，若者是Base的派生类，那么我们如何知道p所指的对象是什么类型呢？通过观察2-6节中的例子的输出，可以发现，无论一个类有多少个虚函数，其下标为-1的项的值（即type_info对象的地址）都是相等的，即它们都指向相同的type_info对象。所以无论使用基类还是派生类的指针指向一个对象，都能根据对象的vptr指向的虚函数表正确地获得该对象所属的类的type_info对象，从而分辨出指针所指对象的真实类型。例如对于如下的测试代码（类的关系和实现是第6节中的钻石型虚拟继承）：int main(){ Derived d; Base basePtr = &amp;d; Base1 base1Ptr = &amp;d; Base2 base2Ptr = &amp;d; Derived derivedPtr = &amp;d; cout &lt;&lt; typeid(basePtr).name() &lt;&lt; endl; cout &lt;&lt; typeid(base1Ptr).name() &lt;&lt; endl; cout &lt;&lt; typeid(base2Ptr).name() &lt;&lt; endl; cout &lt;&lt; typeid(derivedPtr).name() &lt;&lt; endl; return 0;}其输出结果如下从上面的运行可以看出，一个派生类的对象，无论被其任何基类的指针指向，都能通过typeid正确地获得其所指的对象的真实类型。运行结果解释：要理解运行的结果，就要理解当把一个派生类对象指针赋值给其基类指针时会发生什么样的行为。当使用基类的指针指向一个派生类的对象时，编译器会安插相应的代码，调整指针的指向，使基类的指针指向派生类对象中其对应的基类子对象的起始处。所以通过测试代码中的指针赋值，产生如下的结果：basePtr 指向了对象d中的Base子对象的地址起始处，即指向了Base::vptrbase1Ptr 指向了对象d中的Base1子对象的地址起始处，即指向了Base1::vptrbase2Ptr 指向了对象d中的Base2子对象的地址起始处，即指向了Base2::vptrderivedPtr 指向了对象d的地址起始处，即指向了Base1::vptr即现在这些指针都指向了对应的类型的子对象，且其都包括一个vptr，所以就可以通过虚函数表中的第-1项的type_info对象的地址来获取type_info对象，从而获得类型信息。而这些地址值都是相同的，即指向同一个type_info对象，且该type_info对象显示该对象的类型为Derived，也就能正确地输出其类型信息。9、虚函数调用的原理我们知道，在C++中使用指向对象的指针或引用才能触发虚函数的调用，产生多态的结果。例如对于如下的代码片断：Base p;……p-&gt;vfunc(); // vfunc是Base中声明的virtual函数由于指针p可以指向一个Base的对象，也可以指向Base的派生类的对象，而编译器在编译时并不知道p所指向的真实对象到底是什么，那么究竟如何判断呢？从各种的C++对象的内存分布中可以看到，尽管虚函数表中的虚函数地址可能被更新（派生类重写基类的virtual函数）或添加新的项（派生类声明新的virtual函数），但是一个相同签名的虚函数在虚函数表中的索引值却是不变的。所以无论p指向的是Base的对象，还是Base的派生类的对象，其virtual函数vfunc在虚函数表中的索引是不变的（均为1）。在了解了C++对象的内存布局后，就能轻松地回答这个问题了。因为在编译时，编译器根本无需判断p所指向的具体对象是什么，而是根据指针p所指向的对象的Base子对象中的虚函数表来实现函数调用的。编译器可能会把virtual函数调用的代码修改为如下的伪代码：(*p-&gt;vptr[1])(p); // 假设vfunc函数在虚函数表中的索引值为1，参数p为this指针若p指向的是一个Base的对象，则调Base的虚函数表中索引值为1的函数。若p指向的是一个Base的派生类的对象，则调用Base的派生类对象的Base子对象的虚函数表中的索引值为1的函数。这样便实现了多态 。这种函数调用是根据指针p所指的对象的虚函数表来实现的，在编译时由于无法确定指针p所指的真实对象，所以无法确定真实要调用哪一个函数，只有在运行时根据指针p所指的对象来动态决定。所以说，虚函数是在运行时动态绑定的，而不是在编译时静态绑定的。]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++对象模型之简述C++对象的内存布局]]></title>
    <url>%2F2015%2F05%2F03%2FC%2B%2B%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%AE%80%E8%BF%B0C%2B%2B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[转自CDSN阅读原文 在C++中，有两种类的成员变量：static和非static，有三种成员函数：static、非static和virtual。那么，它们如何影响C++的对象在内存中的分布呢？ 当存在继承的情况下，其内存分布又是如何呢？ 下面就一个非常简单的类，通过逐渐向其中加入各种成员，来逐一分析上述两种成员变量及三种成员函数对类的对象的内存分布的影响。 注：以下的代码的测试结果均是基于Ubuntu 14.04 64位系统下的G++ 4.8.2，若在其他的系统上或使用其他的编译器，可能会运行出不同的结果。 1、含有非static成员变量及成员函数的类的对象的内存分布 类Persion的定义如下： class Person{ public: Person():mId(0), mAge(20){} void print() { cout &lt;&lt; &quot;id: &quot; &lt;&lt; mId &lt;&lt; &quot;, age: &quot; &lt;&lt; mAge &lt;&lt; endl; } private: int mId; int mAge;}; Person类包含两个非static的int型的成员变量，一个构造函数和一个非static成员函数。为弄清楚该类的对象的内存分布，对该类的对象进行一些操作如下： int main(){ Person p1; cout &lt;&lt; &quot;sizeof(p1) == &quot; &lt;&lt; sizeof(p1) &lt;&lt; endl; int p = (int)&amp;p1; cout &lt;&lt; &quot;p.id == &quot; &lt;&lt; p &lt;&lt; &quot;, address: &quot; &lt;&lt; p &lt;&lt; endl; ++p; cout &lt;&lt; &quot;p.age == &quot; &lt;&lt; p &lt;&lt; &quot;, address: &quot; &lt;&lt; p &lt;&lt; endl; cout &lt;&lt; endl; Person p2; cout &lt;&lt; &quot;sizeof(p2) == &quot; &lt;&lt; sizeof(p1) &lt;&lt; endl; p = (int)&amp;p2; cout &lt;&lt; &quot;p.id == &quot; &lt;&lt; p &lt;&lt; &quot;, address: &quot; &lt;&lt; p &lt;&lt; endl; ++p; cout &lt;&lt; &quot;p.age == &quot; &lt;&lt; p &lt;&lt; &quot;, address: &quot; &lt;&lt; p &lt;&lt; endl; return 0;} 其运行结果如下： &nbsp; 从上图可以看到类的对象的占用的内存均为8字节，使用普通的int＊指针可以遍历输出对象内的非static成员变量的值，且两个对象中的相同的非static成员变量的地址各不相同。 据此，可以得出结论，在C++中，非static成员变量被放置于每一个类对象中，非static成员函数放在类的对象之外，且非static成员变量在内存中的存放顺序与其在类内的声明顺序一致。即person对象的内存分布如下图所示： 2、含有static和非static成员变量和成员函数的类的对象的内存分布 向Person类中加入一个static成员变量和一个static成员函数，如下：class Person{ public: Person():mId(0), mAge(20){ ++sCount; } ~Person(){ –sCount; } void print() { cout &lt;&lt; &quot;id: &quot; &lt;&lt; mId &lt;&lt; &quot;, age: &quot; &lt;&lt; mAge &lt;&lt; endl; } static int personCount() { return sCount; } private: static int sCount; int mId; int mAge;}; 测试代码不变，与第1节中的代码相同。其运行结果不变，与第1节中的运行结果相同。 据此，可以得出：static成员变量存放在类的对象之外，static成员函数也放在类的对象之外。其内存分布如下图所示：3、加入virtual成员函数的类的对象的内存分布 在Person类中加入一个virtual函数，并把前面的print函数修改为函数，如下： class Person{ public: Person():mId(0), mAge(20){ ++sCount; } static int personCount() { return sCount; } virtual void print() { cout &lt;&lt; &quot;id: &quot; &lt;&lt; mId &lt;&lt; &quot;, age: &quot; &lt;&lt; mAge &lt;&lt; endl; } virtual void job() { cout &lt;&lt; &quot;Person&quot; &lt;&lt; endl; } virtual ~Person() { –sCount; cout &lt;&lt; &quot;~Person&quot; &lt;&lt; endl; } protected: static int sCount; int mId; int mAge;};为了查看类的对象的内存分布，对类的对象执行如下的操作代码，如下： int main(){ Person person; cout &lt;&lt; sizeof(person) &lt;&lt; endl; int p = (int)&amp;person; for (int i = 0; i &lt; sizeof(person) / sizeof(int); ++i, ++p) { cout &lt;&lt; p &lt;&lt; endl; } return 0;} 其运行结果如下： 从上图可以看出，加virtual成员函数后，类的对象的大小为16字节，增加了8。通过int＊指针遍历该对象的内存，可以看到，最后两行显示的是成员数据的值。C++中的虚函数是通过虚函数表（vtbl）来实现，每一个类为每一个virtual函数产生一个指针，放在表格中，这个表格就是虚函数表。每一个类对象会被安插一个指针（vptr），指向该类的虚函数表。vptr的设定和重置都由每一个类的构造函数、析构函数和复制赋值运算符自动完成。由于本人的系统是64位的系统，一个指针的大小为8字节，所以可以推出，在本人的环境中，类的对象的安插的vptr放在该对象所占内存的最前面。其内存分布图如下：注：虚函数的顺序是按虚函数定义顺序定义的，但是它还包含其他的一些字段，本人还未明白它是什么，在下一节会详细说明虚函数表的内容。4、虚函数表（vtbl）的内容及函数指针存放顺序在第3节中，我们可以知道了指向虚函数表的指针（vptr）在类中的位置了，而函数表中的数据都是函数指针，于是便可利用这点来遍历虚函数表，并测试出虚函数表中的内容。测试代码如下：typedef void (FuncPtr)();int main(){ Person person; int vtbl = (int)(int)&amp;person; for (int i = 0; i &lt; 3 &amp;&amp; vtbl != NULL; ++i) { FuncPtr func = (FuncPtr)vtbl; func(); ++vtbl; } while (vtbl) { cout &lt;&lt; &quot;vtbl == &quot; &lt;&lt; *vtbl &lt;&lt; endl; ++vtbl; } return 0;}代码解释：由于虚函数表位于对象的首位置上，且虚函数表保存的是函数的指针，若把虚函数表当作一个数组，则要指向该数组需要一个双指针。我们可以通过如下方式获取Person类的对象的地址，并转化成int指针：Person person;int p = (int)&amp;person;再通过如下的表达式，获取虚函数表的地址：&nbsp;int vtbl = (int)p;然后，通过如下语句获得虚函数表中函数的地址，并调用函数。FuncPtr func = (FuncPtr)vtbl;func();最后，通过++vtbl可以得到函数表中下一项地址，从而遍历整个虚函数表。其运行结果如下图所示：从上图可以看出，遍历虚函数表，并根据虚函数表中的函数地址调用函数，它先调用print函数，再调用job函数，最后调用析构函数。函数的调用顺序与Person类中的虚函数的定义顺序一致，其内存分布与第3节中的对象内存分布图相一致。从代码和运行结果，可以看出，虚函数表以NULL标志表的结束。但是虚函数表中还含有其他的数据，本人还没有清楚其作用。5、继承对于类的对象的内存分布的影响本文并不打算详细地介绍继承对对象的内存分布的影响，也不介绍虚函数的实现机制。这里主要给出一个经过本人测试的大概的对象内存模型，由于代码较多，不一一贴出。假设所有的类都有非static的成员变量和成员函数、static的成员变量及成员函数和virtual函数。1）单继承（只有一个父类）类的继承关系为：class Derived : public BaseDerived类的对象的内存布局为：虚函数表指针、Base类的非static成员变量、Derived类的非static成员变量。2）多重继承（多个父类）类的继承关系如下：class Derived : public Base1, public Base2Derived类的对象的内存布局为：基类Base1子对象和基类Base2子对象及Derived类的非static成员变量组成。基类子对象包括其虚函数表指针和其非static的成员变量。3）重复继承（继承的多个父类中其父类有相同的超类）类的继承关系如下：class Base1 : public Baseclass Base2:&nbsp; public Baseclass Derived : public Base1, public Base2Derived类的对象的内存布局与多继承相似，但是可以看到基类Base的子对象在Derived类的对象的内存中存在一份拷贝。这样直接使用Derived中基类Base的相关成员时，就会引发歧义，可使用多重虚拟继承消除之。4）多重虚拟继承（使用virtual方式继承，为了保证继承后父类的内存布局只会存在一份）类的继承关系如下：class Base1 : virtual public Baseclass Base2:&nbsp; virtual public Baseclass Derived : public Base1, public Base2Derived类的对象的内存布局与重复继承的类的对象的内存分布类似，但是基类Base的子对象没有拷贝一份，在对象的内存中仅存在在一个Base类的子对象。但是它的非static成员变量放置在对象的末尾处。关于继承对对象的内存布局的影响以及虚函数的实现机制的详细介绍，请参阅——C++对象模型之详述C++对象的内存布局]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux一些不要想当然的事(一)之目录权限]]></title>
    <url>%2F2015%2F03%2F18%2Flinux%E4%B8%80%E4%BA%9B%E4%B8%8D%E8%A6%81%E6%83%B3%E5%BD%93%E7%84%B6%E7%9A%84%E4%BA%8B(%E4%B8%80)%E4%B9%8B%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[目录的可读/可写/可执行权限 不要把目录的这几个权限和档案的这几个权限混淆了, 不要想当然的以为是差不多的, 差很多!记忆技巧 : 档案的rwx是针对于档案的内容来设计的, 而目录的rwx是针对于目录的文件名列表来设计的 目录可读r 目录可读权限r : 只能获得文件列表 特别注意:如果一个目录为非空, 却没有r权限, 即使你有wx的权限, 你用rm -r也是删不掉的, 因为没有r权限拿不到这个目录的文件列表, rm -r 自然也就不晓得要删除什么东西了.只有求助root了123456789101112131415161718192021b@b-VirtualBox:~/my_temp_test/abc$ mkdir tempb@b-VirtualBox:~/my_temp_test/abc$ touch temp/ddb@b-VirtualBox:~/my_temp_test/abc$ ls tempddb@b-VirtualBox:~/my_temp_test/abc$ chmod 444 tempb@b-VirtualBox:~/my_temp_test/abc$ ls templs: cannot access temp/dd: Permission deniedddb@b-VirtualBox:~/my_temp_test/abc$ cd temp/bash: cd: temp/: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ cat temp/dd cat: temp/dd: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ touch temp/yytouch: cannot touch ‘temp/yy’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm temp/dd rm: cannot remove ‘temp/dd’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm -r temprm: descend into write-protected directory ‘temp’? yrm: cannot remove ‘temp/dd’: Permission deniedrm: remove write-protected directory ‘temp’? yrm: cannot remove ‘temp’: Directory not empty 目录可写w 目录可写权限w : 代表可以在目录下增加或删除档案和目录和改名(但是必须得有目录可执行权限x的支持才可以, 所以一般有w就会有x) 不要和档案的可写权限混淆了, 即使没有目录可写权限, 有目录可执行x也是可以修改目录下的档案的, 只要拥有要修改的那个档案的可写权限既可. 但也要注意的是: 档案的w是针对于档案的内容来说的, 你可以编辑修改他的内容, 但是如果想删除这个档案, 你需要这个档案所在的目录的w权限.1234567891011121314b@b-VirtualBox:~/my_temp_test/abc$ chmod 222 tempb@b-VirtualBox:~/my_temp_test/abc$ mkdir temp/uumkdir: cannot create directory ‘temp/uu’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ touch temp/ootouch: cannot touch ‘temp/oo’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ chmod 333 temp b@b-VirtualBox:~/my_temp_test/abc$ mkdir temp/uub@b-VirtualBox:~/my_temp_test/abc$ touch temp/oob@b-VirtualBox:~/my_temp_test/abc$ rm -r temprm: cannot remove ‘temp’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm -r temp/uub@b-VirtualBox:~/my_temp_test/abc$ rm temp/oob@b-VirtualBox:~/my_temp_test/abc$ ls templs: cannot open directory temp: Permission denied 目录可执行x 目录可执行权限x : 有进入目录的权限, 有在这个目录下执行命令的权限. 但不可以删除或者增加档案和目录(因为不具备目录的可写权限w)1234567891011121314151617b@b-VirtualBox:~/my_temp_test/abc$ chmod 111 temp/b@b-VirtualBox:~/my_temp_test/abc$ ls templs: cannot open directory temp: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ echo &quot;xxd&quot; &gt; temp/ddb@b-VirtualBox:~/my_temp_test/abc$ cat temp/ddxxdb@b-VirtualBox:~/my_temp_test/abc$ touch temp/yytouch: cannot touch ‘temp/yy’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm temp/ddrm: cannot remove ‘temp/dd’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm -r temprm: descend into write-protected directory ‘temp’? yrm: remove write-protected directory ‘temp’? yrm: cannot remove ‘temp’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ cd tempb@b-VirtualBox:~/my_temp_test/abc/temp$ lsls: cannot open directory .: Permission denied]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>directory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用运维命令(df和free)笔记整理(三)]]></title>
    <url>%2F2015%2F03%2F11%2FLinux%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4(df%E5%92%8Cfree)%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[df df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 -a或–all：包含全部的文件系统； –block-size=&lt;区块大小&gt;：以指定的区块大小来显示区块数目； -h或–human-readable：以可读性较高的方式来显示信息； -H或–si：与-h参数相同，但在计算时是以1000 Bytes为换算单位而非1024 Bytes； -i或–inodes：显示inode的信息； -k或–kilobytes：指定区块大小为1024字节； -l或–local：仅显示本地端的文件系统； -m或–megabytes：指定区块大小为1048576字节； –no-sync：在取得磁盘使用信息前，不要执行sync指令，此为预设值； -P或–portability：使用POSIX的输出格式； –sync：在取得磁盘使用信息前，先执行sync指令； -t&lt;文件系统类型&gt;或–type=&lt;文件系统类型&gt;：仅显示指定文件系统类型的磁盘信息； -T或–print-type：显示文件系统的类型； -x&lt;文件系统类型&gt;或–exclude-type=&lt;文件系统类型&gt;：不要显示指定文件系统类型的磁盘信息； –help：显示帮助； –version：显示版本信息 df常用用法：df -h12345678910b@b-VirtualBox:~$ df -hFilesystem Size Used Avail Use% Mounted onudev 990M 4.0K 990M 1% /devtmpfs 201M 968K 200M 1% /run/dev/sda1 8.8G 4.1G 4.3G 49% /none 4.0K 0 4.0K 0% /sys/fs/cgroupnone 5.0M 0 5.0M 0% /run/locknone 1001M 76K 1001M 1% /run/shmnone 100M 36K 100M 1% /run/user/dev/sr0 57M 57M 0 100% /media/b/VBOXADDITIONS_5.1.22_115126 free free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。 free常用用法：free -m或者free -g12345b@b-VirtualBox:~$ free -m total used free shared buffers cachedMem: 2000 1231 768 9 72 456-/+ buffers/cache: 702 1297Swap: 1021 0 1021]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用运维命令(netstat和lsof)笔记整理(二)]]></title>
    <url>%2F2015%2F03%2F09%2FLinux%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4(netstat%E5%92%8Clsof)%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[netstat netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 -a或–all：显示所有连线中的Socket； -A&lt;网络类型&gt;或–&lt;网络类型&gt;：列出该网络类型连线中的相关地址； -c或–continuous：持续列出网络状态； -C或–cache：显示路由器配置的快取信息； -e或–extend：显示网络其他相关信息； -F或–fib：显示FIB； -g或–groups：显示多重广播功能群组组员名单； -h或–help：在线帮助； -i或–interfaces：显示网络界面信息表单； -l或–listening：显示监控中的服务器的Socket； -M或–masquerade：显示伪装的网络连线； -n或–numeric：直接使用ip地址，而不通过域名服务器； -N或–netlink或–symbolic：显示网络硬件外围设备的符号连接名称； -o或–timers：显示计时器； -p或–programs：显示正在使用Socket的程序识别码和程序名称； -r或–route：显示Routing Table； -s或–statistice：显示网络工作信息统计表； -t或–tcp：显示TCP传输协议的连线状况； -u或–udp：显示UDP传输协议的连线状况； -v或–verbose：显示指令执行过程； -V或–version：显示版本信息； -w或–raw：显示RAW传输协议的连线状况； -x或–unix：此参数的效果和指定”-A unix”参数相同； –ip或–inet：此参数的效果和指定”-A inet”参数相同。 netstat常用用法：netstat -anlpnetstat -anlpt的含义是 ： 列出所有处于使用tcp协议的 Sockets123456789b@b-VirtualBox:~$ sudo netstat -anlptActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.1.1:53 0.0.0.0:* LISTEN 1075/dnsmasq tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 935/sshd tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN 2271/cupsd tcp6 0 0 :::22 :::* LISTEN 935/sshd tcp6 0 0 ::1:631 :::* LISTEN 2271/cupsd tcp6 1 0 ::1:50654 ::1:631 CLOSE_WAIT 1027/cups-browsed 查看udp的就是netstat -anlpu；只查看tcp和udp的就是netstat -anlptu lsof （list open files） lsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为lsof命令需要访问核心内存和各种文件，所以需要root用户执行。 在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 -a：列出打开文件存在的进程； -c&lt;进程名&gt;：列出指定进程所打开的文件； -g：列出GID号进程详情； -d&lt;文件号&gt;：列出占用该文件号的进程； +d&lt;目录&gt;：列出目录下被打开的文件； +D&lt;目录&gt;：递归列出目录下被打开的文件； -n&lt;目录&gt;：列出使用NFS的文件； -i&lt;条件&gt;：列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt;：列出指定进程号所打开的文件； -u：列出UID号进程详情； -h：显示帮助信息； -v：显示版本信息 -R: 显示PPID（父进程ID） lsof常用用法1：lsof -pps -ef |grep sshd|grep -v grep| awk ‘{print $2}’|xargs sudo lsof -p的含义是：列出sshd进程打开的所有文件描述符123456789101112131415161718192021222324252627282930313233343536373839b@b-VirtualBox:~$ ps -ef |grep sshd|grep -v grep| awk &apos;&#123;print $2&#125;&apos;|xargs sudo lsof -plsof: WARNING: can&apos;t stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs Output information may be incomplete.COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 935 root cwd DIR 8,1 4096 2 /sshd 935 root rtd DIR 8,1 4096 2 /sshd 935 root txt REG 8,1 770944 301274 /usr/sbin/sshdsshd 935 root mem REG 8,1 43616 136982 /lib/x86_64-linux-gnu/libnss_files-2.19.sosshd 935 root mem REG 8,1 47760 136992 /lib/x86_64-linux-gnu/libnss_nis-2.19.sosshd 935 root mem REG 8,1 39824 136978 /lib/x86_64-linux-gnu/libnss_compat-2.19.sosshd 935 root mem REG 8,1 101240 137033 /lib/x86_64-linux-gnu/libresolv-2.19.sosshd 935 root mem REG 8,1 14256 136950 /lib/x86_64-linux-gnu/libkeyutils.so.1.4sshd 935 root mem REG 8,1 43672 403209 /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1sshd 935 root mem REG 8,1 186824 403203 /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1sshd 935 root mem REG 8,1 31792 137035 /lib/x86_64-linux-gnu/librt-2.19.sosshd 935 root mem REG 8,1 141574 137027 /lib/x86_64-linux-gnu/libpthread-2.19.sosshd 935 root mem REG 8,1 252032 137010 /lib/x86_64-linux-gnu/libpcre.so.3.13.1sshd 935 root mem REG 8,1 14664 136924 /lib/x86_64-linux-gnu/libdl-2.19.sosshd 935 root mem REG 8,1 97296 136976 /lib/x86_64-linux-gnu/libnsl-2.19.sosshd 935 root mem REG 8,1 1840928 136907 /lib/x86_64-linux-gnu/libc-2.19.sosshd 935 root mem REG 8,1 14592 136916 /lib/x86_64-linux-gnu/libcom_err.so.2.1sshd 935 root mem REG 8,1 831616 403207 /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3sshd 935 root mem REG 8,1 290520 403037 /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2sshd 935 root mem REG 8,1 43368 136917 /lib/x86_64-linux-gnu/libcrypt-2.19.sosshd 935 root mem REG 8,1 100728 137070 /lib/x86_64-linux-gnu/libz.so.1.2.8sshd 935 root mem REG 8,1 10680 137062 /lib/x86_64-linux-gnu/libutil-2.19.sosshd 935 root mem REG 8,1 1934624 136919 /lib/x86_64-linux-gnu/libcrypto.so.1.0.0sshd 935 root mem REG 8,1 281552 136921 /lib/x86_64-linux-gnu/libdbus-1.so.3.7.6sshd 935 root mem REG 8,1 14536 440884 /usr/lib/x86_64-linux-gnu/libck-connector.so.0.0.0sshd 935 root mem REG 8,1 134296 137037 /lib/x86_64-linux-gnu/libselinux.so.1sshd 935 root mem REG 8,1 55856 136999 /lib/x86_64-linux-gnu/libpam.so.0.83.1sshd 935 root mem REG 8,1 104936 136897 /lib/x86_64-linux-gnu/libaudit.so.1.0.0sshd 935 root mem REG 8,1 36632 137067 /lib/x86_64-linux-gnu/libwrap.so.0.7.6sshd 935 root mem REG 8,1 149120 136883 /lib/x86_64-linux-gnu/ld-2.19.sosshd 935 root 0u CHR 1,3 0t0 6 /dev/nullsshd 935 root 1u CHR 1,3 0t0 6 /dev/nullsshd 935 root 2u CHR 1,3 0t0 6 /dev/nullsshd 935 root 3u IPv4 10479 0t0 TCP *:ssh (LISTEN)sshd 935 root 4u IPv6 10481 0t0 TCP *:ssh (LISTEN) ps -ef | grep sshd | grep -v grep : 获取ps打印出来的列表中的sshd进程所在的那一行（grep -v grep的含义是清除掉包含“grep”字符串的那一行）, 即为： 12b@b-VirtualBox:~$ ps -ef | grep sshd | grep -v greproot 935 1 0 17:37 ? 00:00:00 /usr/sbin/sshd -D awk ‘{print $2}’ : 获取上述命令打印出来结果的第2列（上述结果的第二列为sshd的pid， 是935） xargs sudo lsof -p ： 列出上述结果pid为935的进程打开的所有文件描述符， 等价于sudo lsof -p 935的结果 lsof常用用法：lsof -i:sudo lsof -i:22含义为列出占用22的进程1234b@b-VirtualBox:~$ sudo lsof -i:22COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 935 root 3u IPv4 10479 0t0 TCP *:ssh (LISTEN)sshd 935 root 4u IPv6 10481 0t0 TCP *:ssh (LISTEN)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用运维命令(iostat)笔记整理(一)]]></title>
    <url>%2F2015%2F03%2F07%2FLinux%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4(iostat)%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[在linux服务器开发过程中， 经常需要各种命令配合来查看各种状态，所以整理了一些老的笔记来备忘。 iostat iostat主要用于监控系统设备的IO负载情况，iostat首次运行时显示自系统启动开始的各项统计信息，之后运行iostat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息 -c 仅显示CPU统计信息.与-d选项互斥. -d 仅显示磁盘统计信息.与-c选项互斥. -k 以K为单位显示每秒的磁盘请求数,默认单位块. -t 在输出数据时,打印搜集数据的时间. -V 打印版本号和帮助信息. -x 输出扩展信息. iostat常用用法1：iostat -d指定采样时间间隔与采样次数 我们可以以”iostat interval [count] ”形式指定iostat命令的采样间隔和采样次数：12345678910linux # iostat -d 1 2Linux 2.6.16.60-0.21-smp (linux) 06/13/12Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 0.55 8.93 36.27 6737086 27367728sdb 0.00 0.00 0.00 928 0Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 2.00 0.00 72.00 0 72sdb 0.00 0.00 0.00 0 0 以上命令输出Device的信息，采样时间为1秒，采样2次，若不指定采样次数，则iostat会一直输出采样信息，直到按”ctrl+c”退出命令。注意，第1次采样信息与单独执行iostat的效果一样，为从系统开机到当前执行时刻的统计信息。 iostat常用用法2： iostat -x -k -d123456linux # iostat -x -k -d 1Linux 2.6.16.60-0.21-smp (linux) 06/13/12……Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 0.00 9915.00 1.00 90.00 4.00 34360.00 755.25 11.79 120.57 6.33 57.60 以上各列的含义如下： rrqm/s: 每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并 wrqm/s: 每秒对该设备的写请求被合并次数 r/s: 每秒完成的读次数 w/s: 每秒完成的写次数 rkB/s: 每秒读数据量(kB为单位) wkB/s: 每秒写数据量(kB为单位) avgrq-sz:平均每次IO操作的数据量(扇区数为单位) avgqu-sz: 平均等待处理的IO请求队列长度 await: 平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位) svctm: 平均每次IO请求的处理时间(毫秒为单位) %util: 采用周期内用于IO操作的时间比率，即IO队列非空的时间比率 对于以上示例输出，我们可以获取到以下信息： 每秒向磁盘上写30M左右数据(wkB/s值)每秒有91次IO操作(r/s+w/s)，其中以写操作为主体平均每次IO请求等待处理的时间为120.57毫秒，处理耗时为6.33毫秒等待处理的IO请求队列中，平均有11.79个请求驻留]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的struct模块]]></title>
    <url>%2F2015%2F03%2F02%2Fpython%E7%9A%84struct%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[struct, 这玩意c/c++也有, 顾名思义, 能联想到这玩意是啥了 模块的主要作用就是对python基本类型值与 用python字符串格式表示的C struct类型间 的转化（This module performs conversions between Python values and C structs represented as Python strings.） 基本用法123456789101112import structimport binasciivalues = (1, &apos;abc&apos;, 2.7)s = struct.Struct(&apos;I3sf&apos;)packed_data = s.pack(*values)unpacked_data = s.unpack(packed_data) print &apos;Original values:&apos;, valuesprint &apos;Format string :&apos;, s.formatprint &apos;Uses :&apos;, s.size, &apos;bytes&apos;print &apos;Packed Value :&apos;, binascii.hexlify(packed_data)print &apos;Unpacked Type :&apos;, type(unpacked_data), &apos; Value:&apos;, unpacked_data 输出为:12345Original values: (1, &apos;abc&apos;, 2.7) Format string : I3sf Uses : 12 bytes Packed Value : 0100000061626300cdcc2c40 Unpacked Type : &lt;type &apos;tuple&apos;&gt; Value: (1, &apos;abc&apos;, 2.700000047683716) 代码中， 首先定义了一个元组数据， 包含int、string、float三种数据类型， 然后定义了struct对象，并制定了format‘I3sf’， I 表示int， 3s表示三个字符长度的字符串， f 表示 float。最后通过struct的pack和unpack进行打包和解包。通过输出结果可以发现， value被pack之后， 转化为了一段二进制字节串， 而unpack可以把该字节串再转换回一个元组， 但是值得注意的是对于float的精度发生了改变， 这是由一些比如操作系统等客观因素所决定的。打包之后的数据所占用的字节数与C语言中的struct十分相似。定义format可以参照官方api提供的对照表： 字节序设置另一方面，打包的后的字节顺序默认上是由操作系统的决定的， 当然struct模块也提供了自定义字节顺序的功能， 可以指定大端存储、小端存储等特定的字节顺序， 对于底层通信的字节顺序是十分重要的， 不同的字节顺序和存储方式也会导致字节大小的不同。在format字符串前面加上特定的符号即可以表示不同的字节顺序存储方式， 例如采用小端存储 s = struct.Struct(‘&lt;I3sf’)就可以了。官方api library 也提供了相应的对照列表：]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL一些需要注意的小细节]]></title>
    <url>%2F2015%2F02%2F27%2FMySQL%E4%B8%80%E4%BA%9B%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%B0%8F%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"><![CDATA[distinct关键字 distinct是应用于所有列的, 而不是某一个列1234567891011121314151617181920212223242526272829mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| 56 | 12 || 52 | 10 || 56 | 12 || 56 | 13 |+------+------+4 rows in set (0.00 sec)mysql&gt; select distinct one, two from test_table;+------+------+| one | two |+------+------+| 56 | 12 || 52 | 10 || 56 | 13 |+------+------+3 rows in set (0.00 sec)mysql&gt; select distinct one from test_table;+------+| one |+------+| 56 || 52 |+------+2 rows in set (0.00 sec) and关键字 and的组合优先级比or高 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| 56 | 12 || 52 | 10 || 56 | 12 || 56 | 13 || NULL | NULL |+------+------+5 rows in set (0.00 sec)mysql&gt; select one, two from test_table where one = 52 or one = 56 and two &gt; 12;+------+------+| one | two |+------+------+| 52 | 10 || 56 | 13 |+------+------+2 rows in set (0.00 sec)mysql&gt; select one, two from test_table where one = 52 or (one = 56 and two &gt; 12);+------+------+| one | two |+------+------+| 52 | 10 || 56 | 13 |+------+------+2 rows in set (0.00 sec)mysql&gt; select one, two from test_table where (one = 52 or one = 56) and two &gt; 12;+------+------+| one | two |+------+------+| 56 | 13 |+------+------+1 row in set (0.00 sec) NULL null和空字符是不一样的, 找到他和删除他的方式也比较特别1234567891011121314151617181920212223242526272829303132333435363738mysql&gt; insert into test_table(one , two) values (null, null);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| NULL | NULL |+------+------+1 row in set (0.00 sec)mysql&gt; delete from test_table where one = NULL;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| NULL | NULL |+------+------+1 row in set (0.00 sec)mysql&gt; delete from test_table where one = &apos; &apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| NULL | NULL |+------+------+1 row in set (0.00 sec)mysql&gt; delete from test_table where isnull(one);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_table;Empty set (0.00 sec) rollback 并不是什么都可以回滚的, 典型的如创建表和删除表这些都是不能回退的. 事务是用来管理 insert,update,delete 语句的123456789101112131415161718192021222324252627282930313233343536mysql&gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_tab;+-----+-----+-------+| one | two | three |+-----+-----+-------+| 3 | 4 | 5 |+-----+-----+-------+1 row in set (0.00 sec)mysql&gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into test_tab value (4, 4, 5);Query OK, 1 row affected (0.00 sec)mysql&gt; rollback;Query OK, 0 rows affected (0.01 sec)mysql&gt; select * from test_tab;+-----+-----+-------+| one | two | three |+-----+-----+-------+| 3 | 4 | 5 |+-----+-----+-------+1 row in set (0.00 sec)mysql&gt; drop table test_tab;Query OK, 0 rows affected (0.02 sec)mysql&gt; rollback;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_tab;ERROR 1146 (42S02): Table &apos;b_test_database.test_tab&apos; doesn&apos;t exist]]></content>
      <categories>
        <category>DB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python中的__name__和__main()__]]></title>
    <url>%2F2015%2F02%2F10%2Fpython%E4%B8%AD%E7%9A%84__name__%E5%92%8C__main()__%2F</url>
    <content type="text"><![CDATA[12345678#hello.pydef sayHello(): str=&quot;hello&quot; print(str);if __name__ == &quot;__main__&quot;: print (&apos;This is main of module &quot;hello.py&quot;&apos;) sayHello() python作为一种脚本语言，我们用python写的各个module都可以包含以上那么一个累死c中的main函数，只不过python中的这种__main__与c中有一些区别，类似于php的魔术那一套, 主要体现在： 1、当单独执行该module时，比如单独执行以上hello.py： python hello.py，则输出 12This is main of module &quot;hello.py&quot;hello 可以理解为&quot;if __name__==&quot;__main__&quot;:&quot;这一句与c中的main()函数所表述的是一致的，即作为入口； 2、当该module被其它module 引入使用时，其中的&quot;if __name__==&quot;__main__&quot;:&quot; 所表示的Block不会被执行, 这是因为此时module被其它module引用时， 其__name__的值将发生变化，__name__的值将会是module的名字。 比如在python shell中import hello后，查看hello.__name__： 123import hellohello.__name__&apos;hello&apos; 3、因此，在python中，当一个module作为整体被执行时,moduel.name的值将是&quot;__main__&quot;； 而当一个module被其它module引用时，module.__name__将是module自己的名字， 当然一个module被其它module引用时，其本身并不需要一个可执行的入口main了。]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new和delete为什么要配对用]]></title>
    <url>%2F2015%2F01%2F22%2Fnew%E5%92%8Cdelete%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E9%85%8D%E5%AF%B9%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在 C&#43;&#43; 中，你也许经常使用 new 和 delete 来动态申请和释放内存，但你可曾想过以下问题呢？new 和 delete 是函数吗？new [] 和 delete [] 又是什么？什么时候用它们？你知道 operator new 和 operator delete 吗？为什么 new [] 出来的数组有时可以用 delete 释放有时又不行？…如果你对这些问题都有疑问的话，不妨看看我这篇文章。 new 和 delete 到底是什么如果找工作的同学看一些面试的书，我相信都会遇到这样的题：sizeof 不是函数，然后举出一堆的理由来证明 sizeof 不是函数。在这里，和 sizeof 类&#20284;，new 和 delete 也不是函数，它们都是 C&#43;&#43; 定义的关键字，通过特定的语法可以组成表达式。和 sizeof 不同的是，sizeof 在编译时候就可以确定其返回&#20540;，new 和 delete 背后的机制则比较复杂。继续往下之前，请你想想你认为 new 应该要做些什么？也许你第一反应是，new 不就和 C 语言中的 malloc 函数一样嘛，就用来动态申请空间的。你答对了一半，看看下面语句：string *ps = new string(&quot;hello world&quot;);你就可以看出 new 和 malloc 还是有点不同的，malloc 申请完空间之后不会对内存进行必要的初始化，而 new 可以。所以&nbsp;new&nbsp;expression&nbsp;背后要做的事情不是你想象的那么简单。在我用实例来解释 new 背后的机制之前，你需要知道&nbsp;operator new&nbsp;和&nbsp;operator delete&nbsp;是什么玩意。 operator new 和 operator delete这两个其实是 C&#43;&#43; 语言标准库的库函数，原型分别如下：void operator new(size_t); //allocate an objectvoid operator delete(void ); //free an objectvoid operator new; font-weight:bold”&gt;size_t); //allocate an arrayvoid operator delete; font-weight:bold”&gt;void ); //free an array后面两个你可以先不看，后面再介绍。前面两个均是 C&#43;&#43; 标准库函数，你可能会觉得这是函数吗？请不要怀疑，这就是函数！C&#43;&#43; Primer&nbsp;一书上说这不是重载 new 和 delete 表达式（如&nbsp;operator=&nbsp;就是重载&nbsp;=&nbsp;操作符），因为 new 和 delete 是不允许重载的。但我还没搞清楚为什么要用 operator new 和 operator delete 来命名，比较费解。我们只要知道它们的意思就可以了，这两个函数和 C 语言中的 malloc 和 free 函数有点像了，都是用来申请和释放内存的，并且 operator new 申请内存之后不对内存进行初始化，直接返回申请内存的指针。我们可以直接在我们的程序中使用这几个函数。 new 和 delete 背后机制知道上面两个函数之后，我们用一个实例来解释 new 和 delete 背后的机制：我们不用简单的 C&#43;&#43; 内置类型来举例，使用复杂一点的类类型，定义一个类 A：class A{public: A(int v) : var(v) { fopen_s(&amp;file, &quot;test&quot;, &quot;r&quot;); } ~A() { fclose(file); }private: int var; FILE file;};很简单，类 A 中有两个私有成员，有一个构造函数和一个析构函数，构造函数中初始化私有变量 var 以及打开一个文件，析构函数关闭打开的文件。我们使用class pA = new A(10);来创建一个类的对象，返回其指针 pA。如下图所示 new 背后完成的工作：简单总结一下：首先需要调用上面提到的 operator new 标准库函数，传入的参数为 class A 的大小，这里为 8 个字节，至于为什么是 8 个字节，你可以看看《深入 C&#43;&#43; 对象模型》一书，这里不做多解释。这样函数返回的是分配内存的起始地址，这里假设是 0x007da290。上面分配的内存是未初始化的，也是未类型化的，第二步就在这一块原始的内存上对类对象进行初始化，调用的是相应的构造函数，这里是调用&nbsp;A:A(10);&nbsp;这个函数，从图中也可以看到对这块申请的内存进行了初始化，var=10, file 指向打开的文件。最后一步就是返回新分配并构造好的对象的指针，这里 pA 就指向 0x007da290 这块内存，pA 的类型为类 A 对象的指针。所有这三步，你都可以通过反汇编找到相应的汇编代码，在这里我就不列出了。好了，那么 delete 都干了什么呢？还是接着上面的例子，如果这时想释放掉申请的类的对象怎么办？当然我们可以使用下面的语句来完成：delete pA;delete 所做的事情如下图所示：delete 就做了两件事情：调用 pA 指向对象的析构函数，对打开的文件进行关闭。通过上面提到的标准库函数 operator delete 来释放该对象的内存，传入函数的参数为 pA 的&#20540;，也就是 0x007d290。好了，解释完了 new 和 delete 背后所做的事情了，是不是觉得也很简单？不就多了一个构造函数和析构函数的调用嘛。 如何申请和释放一个数组？我们经常要用到动态分配一个数组，也许是这样的：string psa = new string[10]; //array of 10 empty stringsint pia = new int[10]; //array of 10 uninitialized ints上面在申请一个数组时都用到了&nbsp;new []&nbsp;这个表达式来完成，按照我们上面讲到的 new 和 delete 知识，第一个数组是 string 类型，分配了保存对象的内存空间之后，将调用 string 类型的默认构造函数依次初始化数组中每个元素；第二个是申请具有内置类型的数组，分配了存储 10 个 int 对象的内存空间，但并没有初始化。如果我们想释放空间了，可以用下面两条语句：delete [] psa;delete [] pia;都用到&nbsp;delete []&nbsp;表达式，注意这地方的 [] 一般情况下不能漏掉！我们也可以想象这两个语句分别干了什么：第一个对 10 个 string 对象分别调用析构函数，然后再释放掉为对象分配的所有内存空间；第二个因为是内置类型不存在析构函数，直接释放为 10 个 int 型分配的所有内存空间。这里对于第一种情况就有一个问题了：我们如何知道 psa 指向对象的数组的大小？怎么知道调用几次析构函数？这个问题直接导致我们需要在 new [] 一个对象数组时，需要保存数组的维度，C&#43;&#43; 的做法是在分配数组空间时多分配了 4 个字节的大小，专门保存数组的大小，在 delete [] 时就可以取出这个保存的数，就知道了需要调用析构函数多少次了。还是用图来说明比较清楚，我们定义了一个类 A，但不具体描述类的内容，这个类中有显示的构造函数、析构函数等。那么 当我们调用class A *pAa = new A[3];时需要做的事情如下：从这个图中我们可以看到申请时在数组对象的上面还多分配了 4 个字节用来保存数组的大小，但是最终返回的是对象数组的指针，而不是所有分配空间的起始地址。这样的话，释放就很简单了：delete [] pAa;这里要注意的两点是：调用析构函数的次数是从数组对象指针前面的 4 个字节中取出；传入&nbsp;operator delete[]&nbsp;函数的参数不是数组对象的指针 pAa，而是 pAa 的&#20540;减 4。 为什么 new/delete 、new []/delete[] 要配对使用？其实说了这么多，还没到我写这篇文章的最原始意图。从上面解释的你应该懂了 new/delete、new[]/delete[] 的工作原理了，因为它们之间有差别，所以需要配对使用。但偏偏问题不是这么简单，这也是我遇到的问题，如下这段代码：int pia = new int[10];delete []pia;这肯定是没问题的，但如果把&nbsp;delete []pia;&nbsp;换成&nbsp;delete pia;&nbsp;的话，会出问题吗？这就涉及到上面一节没提到的问题了。上面我提到了在&nbsp;new []&nbsp;时多分配 4 个字节的缘由，因为析构时需要知道数组的大小，但如果不调用析构函数呢（如内置类型，这里的 int 数组）？我们在&nbsp;new []&nbsp;时就没必要多分配那 4 个字节， delete [] 时直接到第二步释放为 int 数组分配的空间。如果这里使用&nbsp;delete pia;那么将会调用&nbsp;operator delete&nbsp;函数，传入的参数是分配给数组的起始地址，所做的事情就是释放掉这块内存空间。不存在问题的。这里说的使用&nbsp;new []&nbsp;用 delete 来释放对象的提前是：对象的类型是内置类型或者是无自定义的析构函数的类类型！我们看看如果是带有自定义析构函数的类类型，用&nbsp;new []&nbsp;来创建类对象数组，而用 delete 来释放会发生什么？用上面的例子来说明：class A pAa = new class A[3];delete pAa;那么&nbsp;delete pAa;&nbsp;做了两件事：调用一次 pAa 指向的对象的析构函数；调用&nbsp;operator delete(pAa);&nbsp;释放内存。显然，这里只对数组的第一个类对象调用了析构函数，后面的两个对象均没调用析构函数，如果类对象中申请了大量的内存需要在析构函数中释放，而你却在销毁数组对象时少调用了析构函数，这会造成内存泄漏。上面的问题你如果说没关系的话，那么第二点就是致命的了！直接释放 pAa 指向的内存空间，这个总是会造成严重的段错误，程序必然会奔溃！因为分配的空间的起始地址是 pAa 指向的地方减去 4 个字节的地方。你应该传入参数设为那个地址！同理，你可以分析如果使用 new 来分配，用&nbsp;delete []&nbsp;来释放会出现什么问题？是不是总会导致程序错误？总的来说，记住一点即可：new/delete、new[]/delete[] 要配套使用总是没错的！]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>new</tag>
        <tag>delete</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-四]]></title>
    <url>%2F2015%2F01%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[分布式系统设计实践基本的理论和策略简单介绍这么多，后面本人会从工程的角度，细化说一下”数据分布“、”副本控制”和”高可用协议” 在分布式系统中，无论是计算还是存储，处理的对象都是数据，数据不存在于一台机器或进程中， 这就牵扯到如何多机均匀分发数据的问题，此小结主要讨论”哈希取模”，”一致性哈希“，”范围表划分“，”数据块划分“ 哈希取模：哈希方式是最常见的数据分布方式，实现方式是通过可以描述记录的业务的id或key(比如用户 id)， 通过Hash函数的计算求余。 余数作为处理该数据的服务器索引编号处理。 如图： 这样的好处是只需要通过计算就可以映射出数据和处理节点的关系，不需要存储映射。 难点就是如果id分布不均匀可能出现计算、存储倾斜的问题，在某个节点上分布过重。 并且当处理节点宕机时，这种”硬哈希“的方式会直接导致部分数据异常，还有扩容非常困难，原来的映射关系全部发生变更。 此处，如果是”无状态“型的节点，影响比较小，但遇到”有状态“的存储节点时，会发生大量数据位置需要变更，发生大量数据迁移的问题。 这个问题在实际生产中，可以通过按2的幂的机器数，成倍扩容的方式来缓解，如图： 不过扩容的数量和方式后收到很大限制。 下面介绍一种”自适应“的方式解决扩容和容灾的问题。 一致性哈希：一致性哈希 – Consistent Hash 是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，最大值+1=最小值。 将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据，如图： 一致性哈希的优点在于可以任意动态添加、删除节点，每次添加、删除一个节点仅影响一致性哈希环上相邻的节点。 为了尽可能均匀的分布节点和数据，一种常见的改进算法是引入虚节点的概念，系统会创建许多虚拟节点，个数远大于当前节点的个数，均匀分布到一致性哈希值域环上。 读写数据时，首先通过数据的哈希值在环上找到对应的虚节点，然后查找到对应的real节点。 这样在扩容和容错时，大量读写的压力会再次被其他部分节点分摊，主要解决了压力集中的问题。 如图： 数据范围划分：有些时候业务的数据id或key分布不是很均匀，并且读写也会呈现聚集的方式。 比如某些id的数据量特别大，这时候可以将数据按Group划分，从业务角度划分比如id为0~10000，已知8000以上的id可能访问量特别大，那么分布可以划分为[[0~8000],[8000~9000],[9000~1000]]。 将小访问量的聚集在一起。 这样可以根据真实场景按需划分，缺点是由于这些信息不能通过计算获取，需要引入一个模块存储这些映射信息。 这就增加了模块依赖，可能会有性能和可用性的额外代价。 数据块划分：许多文件系统经常采用类似设计，将数据按固定块大小(比如HDFS的64MB)，将数据分为一个个大小固定的块，然后这些块均匀的分布在各个节点，这种做法也需要外部节点来存储映射关系。 由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数据总是被均匀切分并分布到集群中。 当集群需要重新负载均衡时，只需通过迁移数据块即可完成。 如图：]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-三]]></title>
    <url>%2F2015%2F01%2F07%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[分布式系统设计策略重试机制一般情况下，写一段网络交互的代码，发起rpc或者http，都会遇到请求超时而失败情况。 可能是网络抖动(暂时的网络变更导致包不可达，比如拓扑变更)或者对端挂掉。 这时一般处理逻辑是将请求包在一个重试循环块里，如下：[cpp] view plain copy print?int retry = 3;while(!request() &amp;&amp; retry–)sched_yield(); // or usleep(100) 此种模式可以防止网络暂时的抖动，一般停顿时间很短，并重试多次后，请求成功！但不能防止对端长时间不能连接(网络问题或进程问题) 心跳机制心跳顾名思义，就是以固定的频率向其他节点汇报当前节点状态的方式。 收到心跳，一般可以认为一个节点和现在的网络拓扑是良好的。 当然，心跳汇报时，一般也会携带一些附加的状态、元数据信息，以便管理。 如下图： 但心跳不是万能的，收到心跳可以确认ok，但是收不到心跳却不能确认节点不存在或者挂掉了，因为可能是网络原因倒是链路不通但是节点依旧在工作。 所以切记，”心跳“只能告诉你正常的状态是ok，它不能发现节点是否真的死亡，有可能还在继续服务。 (后面会介绍一种可靠的方式 – Lease机制) 副本副本指的是针对一份数据的多份冗余拷贝，在不同的节点上持久化同一份数据，当某一个节点的数据丢失时，可以从副本上获取数据。 数据副本是分布式系统解决数据丢失异常的仅有的唯一途径。 当然对多份副本的写入会带来一致性和可用性的问题，比如规定副本数为3，同步写3份，会带来3次IO的性能问题。 还是同步写1份，然后异步写2份，会带来一致性问题，比如后面2份未写成功其他模块就去读了(下个小结会详细讨论如果在副本一致性中间做取舍)。 中心化/无中心化系统模型这方面，无非就是两种：中心节点，例如mysql的MSS单主双从、MongDB Master、HDFS NameNode、MapReduce JobTracker等，有1个或几个节点充当整个系统的核心元数据及节点管理工作，其他节点都和中心节点交互。 这种方式的好处显而易见，数据和管理高度统一集中在一个地方，容易聚合，就像领导者一样，其他人都服从就好。 简单可行。 但是缺点是模块高度集中，容易形成性能瓶颈，并且如果出现异常，就像群龙无首一样。 无中心化的设计，例如cassandra、zookeeper，系统中不存在一个领导者，节点彼此通信并且彼此合作完成任务。 好处在于如果出现异常，不会影响整体系统，局部不可用。 缺点是比较协议复杂，而且需要各个节点间同步信息。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-二]]></title>
    <url>%2F2015%2F01%2F05%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[分布式系统特性CAP是分布式系统里最著名的理论，wiki百科如下 Consistency(all nodes see the same data at the same time) Availability (a guarantee that every request receives a response about whether it was successful or failed) Partition tolerance (the system continues to operate despite arbitrary message loss or failure of part of the system)(摘自 ：http://en.wikipedia.org/wiki/CAP_theorem) 早些时候，国外的大牛已经证明了CAP三者是不能兼得，很多实践也证明了。 本人就不挑战权威了，感兴趣的同学可以自己Google。 本人以自己的观点总结了一下： 一致性可以参考陈皓的博文&lt;&lt;分布式事务处理&gt;&gt; 描述当前所有节点存储数据的统一模型，分为强一致性和弱一致性：强一致性描述了所有节点的数据高度一致，无论从哪个节点读取，都是一样的。 无需担心同一时刻会获得不同的数据。 是级别最高的，实现的代价比较高如图： 弱一致性又分为单调一致性和最终一致性： 1、单调一致性强调数据是按照时间的新旧，单调向最新的数据靠近，不会回退，如： 数据存在三个版本v1-&gt;v2-&gt;v3，获取只能向v3靠近(如取到的是v2，就不可能再次获得v1) 2、最终一致性强调数据经过一个时间窗口之后，只要多尝试几次，最终的状态是一致的，是最新的数据 如图： 强一致性的场景，就好像交易系统，存取钱的+/-操作必须是马上一致的，否则会令很多人误解。 弱一致性的场景，大部分就像web互联网的模式，比如发了一条微博，改了某些配置，可能不会马上生效，但刷新几次后就可以看到了，其实弱一致性就是在系统上通过业务可接受的方式换取了一些系统的低复杂度和可用性。 可用性保证系统的正常可运行性，在请求方看来，只要发送了一个请求，就可以得到恢复无论成功还是失败（不会超时）! 分区容忍性在系统某些节点或网络有异常的情况下，系统依旧可以继续服务。 这通常是有负载均衡和副本来支撑的。 例如计算模块异常可通过负载均衡引流到其他平行节点，存储模块通过其他几点上的副本来对外提供服务。 扩展性扩展性是融合在CAP里面的特性，我觉得此处可以单独讲一下。 扩展性直接影响了分布式系统的好坏，系统开发初期不可能把系统的容量、峰值都考虑到，后期肯定牵扯到扩容，而如何做到快而不太影响业务的扩容策略，也是需要考虑的。 (后面在介绍数据分布时会着重讨论这个问题)]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-一]]></title>
    <url>%2F2015%2F01%2F04%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[分布式系统中的概念最简单的分布式系统分布式可繁也可以简，最简单的分布式就是大家最常用的， 在负载均衡服务器后加一堆web服务器，然后在上面搞一个缓存服务器来保存临时状态， 后面共享一个数据库，其实很多号称分布式专家的人也就停留于此， 大致结构如下图所示： 这种环境下真正进行分布式的只是web server而已， 并且web server之间没有任何联系，所以结构和实现都非常简单。 最完备的分布式体系的模块组成有些情况下，对分布式的需求就没这么简单， 在每个环节上都有分布式的需求， 比如Load Balance、DB、Cache和文件等等， 并且当分布式节点之间有关联时， 还得考虑之间的通讯， 另外， 节点非常多的时候， 得有监控和管理来支撑。这样看起来， 分布式是一个非常庞大的体系， 只不过你可以根据具体需求进行适当地裁剪。按照最完备的分布式体系来看， 可以由以下模块组成： 分布式任务处理服务：负责具体的业务逻辑处理 分布式节点注册和查询：负责管理所有分布式节点的命名和物理信息的注册与询，是节点之间联系的桥梁 分布式DB：分布式结构化数据存取 分布式Cache：分布式缓存数据（非持久化）存取 分布式文件：分布式文件存取 网络通信：节点之间的网络数据通信 监控管理：搜集、监控和诊断所有节点运行状态 分布式编程语言：用于分布式环境下的专有编程语言，比如Elang、Scala 分布式算法：为解决分布式环境下一些特有问题的算法，比如解决一致性问题的Paxos算法 三元组其实，分布式系统说白了，就是很多机器组成的集群，靠彼此之间的网络通信，担当的角色可能不同，共同完成同一个事情的系统。 如果按”实体“来划分的话，就是如下这几种： 1、节点 – 系统中按照协议完成计算工作的一个逻辑实体，可能是执行某些工作的进程或机器 2、网络 – 系统的数据传输通道，用来彼此通信。 通信是具有方向性的。 3、存储 – 系统中持久化数据的数据库或者文件存储。 状态特性各个节点的状态可以是“无状态”或者“有状态的”, 一般认为，节点是偏计算和通信的模块，一般是无状态的。 这类应用一般不会存储自己的中间状态信息，比如Nginx，一般情况下是转发请求而已，不会存储中间信息。 另一种“有状态”的，如MySQL等数据库，状态和数据全部持久化到磁盘等介质。 “无状态”的节点一般我们认为是可随意重启的，因为重启后只需要立刻工作就好。 “有状态”的则不同，需要先读取持久化的数据，才能开始服务。 所以，“无状态”的节点一般是可以随意扩展的，“有状态”的节点需要一些控制协议来保证扩展。 系统异常异常，可认为是节点因为某种原因不能工作，此为节点异常。 还有因为网络原因，临时、永久不能被其他节点所访问，此为网络异常。 在分布式系统中，要有对异常的处理，保证集群的正常工作。 分布式系统与单节点的不同从linux write()系统调用说起众所周知，在unix/linux/mac(类Unix)环境下，两个机器通信，最常用的就是通过socket连接对方。 传输数据的话，无非就是调用write()这个系统调用，把一段内存缓冲区发出去。 但是可以进一步想一下，write()之后能确认对方收到了这些数据吗？ 答案肯定是不能，原因就是发送数据需要走内核-&gt;网卡-&gt;链路-&gt;对端网卡-&gt;内核，这一路径太长了，所以只能是异步操作。 write()把数据写入内核缓冲区之后就返回到应用层了，具体后面何时发送、怎么发送、TCP怎么做滑动窗口、流控都是tcp/ip协议栈内核的事情了。 所以在应用层，能确认对方受到了消息只能是对方应用返回数据，逻辑确认了这次发送才认为是成功的。 这就却别与单系统编程，大部分系统调用、库调用只要返回了就说明已经确认完成了。 TCP/IP协议是“不可靠”的教科书上明确写明了互联网是不可靠的，TCP实现了可靠传输。 何来“不可靠”呢？先来看一下网络交互的例子，有A、B两个节点，之间通过TCP连接，现在A、B都想确认自己发出的任何一条消息都能被对方接收并反馈，于是开始了如下操作：A-&gt;B发送数据，然后A需要等待B收到数据的确认，B收到数据后发送确认消息给A，然后B需要等待A收到数据的确认，A收到B的数据确认消息后再次发送确认消息给B，然后A又去需要等待B收到的确认。 死循环了！！ 其实，这就是著名的“拜占庭将军”问题 所以，通信双方是“不可能”同时确认对方受到了自己的信息。 而教科书上定义的其实是指“单向”通信是成立的，比如A向B发起Http调用， 收到了HttpCode 200的响应包，这只能确认，A确认B收到了自己的请求，并且B正常处理了，不能确认的是B确认A受到了它的成功的消息。 不可控的状态在单系统编程中，我们对系统状态是非常可控的。 比如函数调用、逻辑运算，要么成功，要么失败，因为这些操作被框在一个机器内部，cpu/总线/内存都是可以快速得到反馈的。 开发者可以针对这两个状态很明确的做出程序上的判断和后续的操作。 而在分布式的网络环境下，这就变得微妙了。 比如一次rpc、http调用，可能成功、失败，还有可能是“超时”，这就比前者的状态多了一个不可控因素，导致后面的代码不是很容易做出判断。 试想一下，用A用支付宝向B转了一大笔钱，当他按下“确认”后，界面上有个圈在转啊转，然后显示请求超时了，然后A就抓狂了，不知道到底钱转没转过去，开始确认自己的账户、确认B的账户、打电话找客服等等。 所以分布式环境下，我们的其实要时时刻刻考虑面对这种不可控的“第三状态”设计开发，这也是挑战之一。 视异常为正常单系统下，进程/机器的异常概率十分小。 即使出现了问题，可以通过人工干预重启、迁移等手段恢复。 但在分布式环境下，机器上千台，每几分钟都可能出现宕机、死机、网络断网等异常，出现的概率很大。 所以，这种环境下，进程core掉、机器挂掉都是需要我们在编程中认为随时可能出现的，这样才能使我们整个系统健壮起来，所以”容错“是基本需求。 异常可以分为如下几类： 节点错误：一般是由于应用导致，一些coredump和系统错误触发，一般重新服务后可恢复。 硬件错误：由于磁盘或者内存等硬件设备导致某节点不能服务，需要人工干预恢复。 网络错误：由于点对点的网络抖动，暂时的访问错误，一般拓扑稳定后或流量减小可以恢复。 网络分化： 网络中路由器、交换机错误导致网络不可达，但是网络两边都正常，这类错误比较难恢复，并且需要在开发时特别处理。 【这种情况也会比较前面的问题较难处理】]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(链表进阶)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（七）]]></title>
    <url>%2F2014%2F12%2F22%2F(%E9%93%BE%E8%A1%A8%E8%BF%9B%E9%98%B6)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[只谈一下单链表, 链表实在是太重要, 是前面两篇说算法博客的基础, 了解了其应用和衍生, 再去了解其本身就有动力了 这是一篇偏向单链表进阶的博客, 并不会讲单链表的建立/增加/删除等等, 而且这篇博客大多数只说思想不写代码(因为其实蛮简单的..) 存储结构12345typedef struct Node&#123; DataType data; struct Node *next;&#125;Node, *Node_Ptr; 1.找一个单链表的中间结点 算法思想 :(快慢指针的使用)设置两个指针，一个每次移动两个位置，一个每次移动一个位置，当第一个指针到达尾节点时，第二个指针就达到了中间节点的位置 2.判断链表中是否有环 算法思想 :(快慢指针的使用)链表中有环，其实也就是自相交. 用两个指针pslow和pfast从头开始遍历链表，pslow每次前进一个节点，pfast每次前进两个结点，若存在环，则pslow和pfast肯定会在环中相遇，若不存在，则pslow和pfast能正常到达最后一个节点 3.判断两个链表是否相交, 假设两个链表均不带环 算法思想 :如果两个链表相交于某一节点，那么在这个相交节点之后的所有节点都是两个链表所共有的。也就是说，如果两个链表相交，那么最后一个节点肯定是共有的。先遍历第一个链表，记住最后一个节点，然后遍历第二个链表，到最后一个节点时和第一个链表的最后一个节点做比较，如果相同，则相交，否则不相交。 4.链表反转比如一个链表:A-&gt;B-&gt;C-&gt;D-&gt;E反转成为:E-&gt;D-&gt;C-&gt;B-&gt;A 算法思想 :取一个指针指向A的后面那个元素elem, 每次把element放到链表的第一个位置, 遍历完毕之后就反转完毕了,过程如下:第一轮 : A-&gt;B-&gt;C-&gt;D-&gt;E, 把A后面的B设置为element第二轮 : B-&gt;A-&gt;C-&gt;D-&gt;E, 把当前的element(即为B)放到链表的第一个位置, 并把A后面的C设置为element第三轮 : C-&gt;B-&gt;A-&gt;D-&gt;E, 把当前的element(即为C)放到链表的第一个位置, 并把A后面的D设置为element第四轮 : D-&gt;C-&gt;B-&gt;A-&gt;E, 把当前的element(即为D)放到链表的第一个位置, 并把A后面的E设置为element第五轮 : E-&gt;D-&gt;C-&gt;B-&gt;A, 把当前的element(即为E)放到链表的第一个位置, 遍历完毕]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二叉树)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（六）]]></title>
    <url>%2F2014%2F09%2F24%2F(%E4%BA%8C%E5%8F%89%E6%A0%91)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[二叉搜索树(又称二叉查找树或二叉排序树) 有了上面二叉树的基础, 我们继续学习二叉搜索树.我们这里也不给他那种晦涩难懂的定义, 感性的认识二叉搜索树.直接看图, 很容易看得出来, 二叉搜索树每个结点的左孩子都小于右孩子.因为具有n个结点的完全二叉树的最大高度为log2n+1而二叉搜索树的查询/增加的时间复杂度都是O(h), h为树的高度,所以复杂度可以看作O(logn), 所以很明显上图中的a树比b树要高效. 查询1234567891011121314151617181920BTN_Ptr search(BTN_Ptr btp, int key)&#123; while (btp != NULL ) &#123; if ( btp-&gt;data != key) &#123; if ( btp-&gt;data &lt; key ) btp = btp-&gt;RightChild; else btp = btp-&gt;LeftChild; &#125; else &#123; printf(&quot;found\n&quot;); return btp; &#125; &#125; printf(&quot;error : not found!\n&quot;); return NULL;&#125; 插入123456789101112131415161718192021222324252627282930313233BTN_Ptr insert(BTN_Ptr &amp;btp, int key)&#123; if (btp == NULL) &#123; btp = new BTN; btp-&gt;data = key; btp-&gt;LeftChild = NULL; btp-&gt;RightChild = NULL; return btp; &#125; else &#123; BTN_Ptr saved_btp = btp; BTN_Ptr temp_btp = NULL; while ( btp != NULL) &#123; temp_btp = btp; if ( key &lt; btp-&gt;data ) btp = btp-&gt;LeftChild; else btp = btp-&gt;RightChild; &#125; btp = new BTN; btp-&gt;data = key; btp-&gt;LeftChild = NULL; btp-&gt;RightChild = NULL; if ( key &lt; temp_btp-&gt;data ) temp_btp-&gt;LeftChild = btp; else temp_btp-&gt;RightChild = btp; return saved_btp; &#125;&#125; 测试程序附上一个测试程序吧12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;#include &lt;stack&gt;using std::stack;using std::cout;using std::cin;using std::endl;int main(int argc, char **argv)&#123; BTN_Ptr my_btp = NULL; if (create_BT(&amp;my_btp) == -1) return -1; cout &lt;&lt; &quot;==============pre_order:==============&quot; &lt;&lt; endl; pre_order_traverse(&amp;my_btp); cout &lt;&lt; &quot;==============in_order:==============&quot; &lt;&lt; endl; in_order_traverse(&amp;my_btp); cout &lt;&lt; &quot;==============post_order:==============&quot; &lt;&lt; endl; post_order_traverse(&amp;my_btp); cout &lt;&lt; &quot;==============search : 24==============&quot; &lt;&lt; endl; search(my_btp, 24); cout &lt;&lt; &quot;==============search : 14==============&quot; &lt;&lt; endl; search(my_btp, 14); cout &lt;&lt; &quot;==============insert : 25==============&quot; &lt;&lt; endl; my_btp = insert(my_btp, 25); cout &lt;&lt; &quot;==============pre_order2:==============&quot; &lt;&lt; endl; pre_order_traverse(&amp;my_btp); return 0;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二叉树)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（五）]]></title>
    <url>%2F2014%2F09%2F23%2F(%E4%BA%8C%E5%8F%89%E6%A0%91)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[遍历如上图得到的相应的遍历的序列分别为： 先序遍历 ： ABCDEGF 中序遍历 ： CBEGDFA 后序遍历 ： CGEFDBA 递归遍历123456789101112131415161718192021222324252627282930void pre_order_traverse(const BTN_Ptr *btp)&#123; if ( *btp != NULL) &#123; cout &lt;&lt; (*btp)-&gt;data &lt;&lt; endl; pre_order_traverse( &amp;(*btp)-&gt;LeftChild ); pre_order_traverse( &amp;(*btp)-&gt;RightChild ); &#125;&#125;void in_order_traverse(const BTN_Ptr *btp)&#123; if ( *btp != NULL) &#123; in_order_traverse( &amp;(*btp)-&gt;LeftChild ); cout &lt;&lt; (*btp)-&gt;data &lt;&lt; endl; in_order_traverse( &amp;(*btp)-&gt;RightChild ); &#125;&#125;void post_order_traverse(const BTN_Ptr *btp)&#123; if ( *btp != NULL) &#123; post_order_traverse( &amp;(*btp)-&gt;LeftChild ); post_order_traverse( &amp;(*btp)-&gt;RightChild ); cout &lt;&lt; (*btp)-&gt;data &lt;&lt; endl; &#125;&#125; 非递归遍历 非递归的二叉树三种遍历方式其实思想是统一的 : 都是从左到右的将各个结点依次入栈, 当左边已经走到头了, 就开始走右边, 在适当的条件就出栈, 只是每个遍历方式的出栈条件不一样而已. 先序和中序遍历都很好理解, 着重讲一下后序遍历 :后序遍历的出栈条件有点不一样, 因为后序是先左后右再中的, 比如某个结点p要出栈, 需要遍历完了p的所有右子树之后才能出栈, 而不能第一次就出栈, 所以专门构造了一个结构体F_bt来记录他是否是第一次出栈 (F_bt结构体里有个is_first的数据来记录) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586void pre_order_traverse_non_recursion(const BTN_Ptr *btp)&#123; stack&lt;BTN_Ptr&gt; stack_bt; BTN_Ptr temp_btp = *btp; while ( !stack_bt.empty() || temp_btp != NULL ) &#123; while ( temp_btp != NULL ) &#123; cout &lt;&lt; temp_btp-&gt;data &lt;&lt; endl; stack_bt.push(temp_btp); temp_btp = temp_btp-&gt;LeftChild; &#125; if ( !stack_bt.empty() ) &#123; temp_btp = stack_bt.top()-&gt;RightChild; stack_bt.pop(); &#125; &#125;&#125;void in_order_traverse_non_recursion(const BTN_Ptr *btp)&#123; stack&lt;BTN_Ptr&gt; stack_bt; BTN_Ptr temp_btp = *btp; while ( !stack_bt.empty() || temp_btp != NULL ) &#123; while ( temp_btp != NULL ) &#123; stack_bt.push(temp_btp); temp_btp = temp_btp-&gt;LeftChild; &#125; if ( !stack_bt.empty() ) &#123; cout &lt;&lt; stack_bt.top()-&gt;data &lt;&lt; endl; temp_btp = stack_bt.top()-&gt;RightChild; stack_bt.pop(); &#125; &#125;&#125;typedef struct&#123; BTN_Ptr btnp; int is_first;&#125;F_bt, *F_btp;void post_order_traverse_non_recursion( const BTN_Ptr *btp)&#123; stack&lt;F_btp&gt; stack_F_btp; BTN_Ptr temp_btp = *btp; while ( !stack_F_btp.empty() || temp_btp != NULL ) &#123; while ( temp_btp != NULL ) &#123; F_btp temp_F_btp = new F_bt; temp_F_btp-&gt;btnp = temp_btp; temp_F_btp-&gt;is_first = 1; stack_F_btp.push(temp_F_btp); temp_btp = temp_btp-&gt;LeftChild; &#125; if ( !stack_F_btp.empty() ) &#123; if ( stack_F_btp.top()-&gt;is_first == 1 ) &#123; stack_F_btp.top()-&gt;is_first = 0; temp_btp = stack_F_btp.top()-&gt;btnp-&gt;RightChild; &#125; else &#123; cout &lt;&lt; stack_F_btp.top()-&gt;btnp-&gt;data &lt;&lt; endl; delete stack_F_btp.top(); stack_F_btp.top() = NULL; stack_F_btp.pop(); temp_btp = NULL; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二叉树)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（四）]]></title>
    <url>%2F2014%2F09%2F22%2F(%E4%BA%8C%E5%8F%89%E6%A0%91)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[接着上一篇， 上一篇主要说了各种排序算法， 但对几个常用的数据结构还未提及，所以这一篇主要讲二叉树, 二叉树已经包括很多链表的知识了。所有代码都是测试过的, 可以直接撸. 二叉树这里不举太多数字方面的东西， 我们直接看图， 直观感性的认识满二叉树和完全二叉树： 有一点性质需要牢记：具有n个结点的完全二叉树的最大高度为log2n+1 二叉树的二叉链式存储方案的代码表示： 123456typedef struct BinaryTreeNode&#123; int data; BinaryTreeNode *LeftChild, *RightChild; // BTN *LeftChild, *RightChild; // error : BTN doesn&apos;t name a typecat&#125;BTN, *BTN_Ptr; 创建12345678910111213141516171819202122int create_BT(BTN_Ptr *btp)&#123; int temp_data = 0; std::cin &gt;&gt; temp_data; if (temp_data == 0) &#123; *btp = NULL; printf(&quot;leaf\n&quot;); &#125; else &#123; if ( !(*btp = (BTN_Ptr)malloc( sizeof(BTN) ) ) ) &#123; printf(&quot;error : malloc error&quot;); return -1; &#125; (*btp)-&gt;data = temp_data; create_BT(&amp;((*btp)-&gt;LeftChild)); create_BT(&amp;((*btp)-&gt;RightChild)); &#125; return 0;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象的四大特征以及五大原则]]></title>
    <url>%2F2014%2F09%2F12%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9B%9B%E5%A4%A7%E7%89%B9%E5%BE%81%E4%BB%A5%E5%8F%8A%E4%BA%94%E5%A4%A7%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[面向对象的四大特征1.封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面，面向对象计算始于这个基本概念，即现实世界可以被描绘成一系列完全自治，封装的对象，这些对象通过一个受保护的接口访问其他对象 2.继承：继承是一种联结类的层次模型，并且允许和鼓励类的重用，它提供了一种明确表达共性的方法，对象的一个新类可以从现在的类中派生，这个过程成为继承，新类继承了原始类的特性，新类成为原始类的派生类，而原始类称为新类的基类，派生类可以从他的基类那里继承方法和实例变量，并且类可以修改或增加新的方法使之更加适合特殊的需求 3.抽象：抽象就是忽略一个主题中与当前目标无关的那些方面，以便充分的注意与当前目标有关的方面，抽象包括两个方面，一个是过程抽象，二是数据抽象 4.多态性：多态性是指允许不同类的对象对同一消息作出响应，多态性包括参数化多态性和包含多态性，多态性语言具有灵活，抽象，行为共享，代码共享的优势，很好的解决了应用程序函数同名的问题 面向对象的五大原则(记忆口诀 : 替开依(“凯隐”, 一个英雄联盟英雄名字)接单)单一职责原则（Single-Resposibility Principle） 其核心思想为：一个类，最好只做一件事，只有一个引起它的变化。单一职责原则可以看做是低耦合、高内聚在面向对象原则上的引申，将职责定义为引起变化的原因，以提高内聚性来减少引起变化的原因。职责过多，可能引起它变化的原因就越多，这将导致职责依赖，相互之间就产生影响，从而大大损伤其内聚性和耦合度。通常意义下的单一职责，就是指只有一种单一功能，不要为类实现过多的功能点，以保证实体只有一个引起它变化的原因。专注，是一个人优良的品质；同样的，单一也是一个类的优良设计。交杂不清的职责将使得代码看起来特别别扭牵一发而动全身，有失美感和必然导致丑陋的系统错误风险。 开放封闭原则（Open-Closed principle） 其核心思想是：软件实体应该是可扩展的，而不可修改的。也就是，对扩展开放，对修改封闭的。开放封闭原则主要体现在两个方面1、对扩展开放，意味着有新的需求或变化时，可以对现有代码进行扩展，以适应新的情况。2、对修改封闭，意味着类一旦设计完成，就可以独立完成其工作，而不要对其进行任何尝试的修改。实现开开放封闭原则的核心思想就是对抽象编程，而不对具体编程，因为抽象相对稳定。让类依赖于固定的抽象，所以修改就是封闭的；而通过面向对象的继承和多态机制，又可以实现对抽象类的继承，通过覆写其方法来改变固有行为，实现新的拓展方法，所以就是开放的。“需求总是变化”没有不变的软件，所以就需要用封闭开放原则来封闭变化满足需求，同时还能保持软件内部的封装体系稳定，不被需求的变化影响。 替换原则（Liskov-Substituion Principle） 其核心思想是：子类必须能够替换其基类。这一思想体现为对继承机制的约束规范，只有子类能够替换基类时，才能保证系统在运行期内识别子类，这是保证继承复用的基础。在父类和子类的具体行为中，必须严格把握继承层次中的关系和特征，将基类替换为子类，程序的行为不会发生任何变化。同时，这一约束反过来则是不成立的，子类可以替换基类，但是基类不一定能替换子类。Liskov替换原则，主要着眼于对抽象和多态建立在继承的基础上，因此只有遵循了Liskov替换原则，才能保证继承复用是可靠地。实现的方法是面向接口编程：将公共部分抽象为基类接口或抽象类，通过Extract Abstract Class，在子类中通过覆写父类的方法实现新的方式支持同样的职责。Liskov替换原则是关于继承机制的设计原则，违反了Liskov替换原则就必然导致违反开放封闭原则。Liskov替换原则能够保证系统具有良好的拓展性，同时实现基于多态的抽象机制，能够减少代码冗余，避免运行期的类型判别。 依赖倒置原则（Dependecy-Inversion Principle） 其核心思想是：依赖于抽象。具体而言就是高层模块不依赖于底层模块，二者都同依赖于抽象；抽象不依赖于具体，具体依赖于抽象。我们知道，依赖一定会存在于类与类、模块与模块之间。当两个模块之间存在紧密的耦合关系时，最好的方法就是分离接口和实现：在依赖之间定义一个抽象的接口使得高层模块调用接口，而底层模块实现接口的定义，以此来有效控制耦合关系，达到依赖于抽象的设计目标。抽象的稳定性决定了系统的稳定性，因为抽象是不变的，依赖于抽象是面向对象设计的精髓，也是依赖倒置原则的核心。依赖于抽象是一个通用的原则，而某些时候依赖于细节则是在所难免的，必须权衡在抽象和具体之间的取舍，方法不是一层不变的。依赖于抽象，就是对接口编程，不要对实现编程。 接口隔离原则（Interface-Segregation Principle） 其核心思想是：使用多个小的专门的接口，而不要使用一个大的总接口。具体而言，接口隔离原则体现在：接口应该是内聚的，应该避免“胖”接口。一个类对另外一个类的依赖应该建立在最小的接口上，不要强迫依赖不用的方法，这是一种接口污染。接口有效地将细节和抽象隔离，体现了对抽象编程的一切好处，接口隔离强调接口的单一性。而胖接口存在明显的弊端，会导致实现的类型必须完全实现接口的所有方法、属性等；而某些时候，实现类型并非需要所有的接口定义，在设计上这是“浪费”，而且在实施上这会带来潜在的问题，对胖接口的修改将导致一连串的客户端程序需要修改，有时候这是一种灾难。在这种情况下，将胖接口分解为多个特点的定制化方法，使得客户端仅仅依赖于它们的实际调用的方法，从而解除了客户端不会依赖于它们不用的方法。分离的手段主要有以下两种：1、委托分离，通过增加一个新的类型来委托客户的请求，隔离客户和接口的直接依赖，但是会增加系统的开销。2、多重继承分离，通过接口多继承来实现客户的需求，这种方式是较好的。]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(排序算法)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（三）]]></title>
    <url>%2F2014%2F08%2F22%2F(%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[快速排序 与归并排序一样， 快排也是用了分治的思想。你可以想象一个两副牌然后随意取出一张牌pivot，其他的所有牌都跟这张pivot牌比较， 大的放右边那一摞A，小的放左边B。接着再从左边这一摞B再随意取出一张牌pivot，其他的所有牌都跟这张pivot牌比较， 大的放右边那一摞，小的放左边，递归下去。A也重复上述步骤递归。递归结束之后， 左边的都比右边的小， 而且是有序的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546void swap(int *a, int *b)&#123; int temp = 0; temp = *a; *a = *b; *b = temp;&#125;int partition(int *array, int p, int r)&#123; int i = 0, j = 0, pivot = 0; pivot = array[r]; i = p-1; for(j=p; j&lt;=r-1; j++) &#123; if(array[j] &lt;= pivot) &#123; i++; swap(&amp;array[i], &amp;array[j]); &#125; &#125; swap(&amp;array[i+1], &amp;array[r]); return i+1;&#125;/*通常，我们可以向一个算法中加入随机化成分，以便对于所有输入，它均能获得较好的平均情况性能。将这种方法用于快速排序时，不是始终采用A[r]作为主元，而是从子数组A[p..r]中随机选择一个元素，即将A[r]与从A[p..r]中随机选出的一个元素交换。*/ int rand_patition(int test_arr[], int p, int r) &#123; srand(static_cast&lt;unsigned&gt;(time(nullptr))); int rand_index = (rand() % (r - p) ) + p + 1; swap(&amp;test_arr[rand_index], &amp;test_arr[r]); return partition(test_arr, p, r); &#125;void quick_sort(int *array, int p, int r)&#123; int q = 0; if(p &lt; r) &#123; q = rand_patition(array, p, r); quick_sort(array, p, q-1); quick_sort(array, q+1, r); &#125;&#125; 快速排序思想的应用 问题 : 查找数组中第k大的数字算法思想 : 因为快排每次将数组划分为两组加一个枢纽元素，每一趟划分你只需要将k与枢纽元素的下标进行比较，如果比枢纽元素下标大就从右边的子数组中找，如果比枢纽元素下标小从左边的子数组中找，如果一样则就是枢纽元素，找到，如果需要从左边或者右边的子数组中再查找的话，只需要递归一边查找即可，无需像快排一样两边都需要递归，所以复杂度必然降低。 二分查找 二分查找的复杂度计算方法：时间复杂度可以视为while循环的次数。总共有n个元素，渐渐跟下去就是n,n/2,n/4,….n/2^k（接下来操作元素的剩余个数），其中k就是循环的次数由于你n/2^k取整后&gt;=1（接下来操作元素的剩余个数至少为一个）即令n/2^k=1可得k=log2n,（是以2为底，n的对数）所以时间复杂度可以表示O(h)=O(log2n) 递归版本：123456789101112131415int binary_search(int arr[], int low, int high, int key)&#123; if ( low &lt;= high) &#123; int mid = (low + high) / 2; if ( key == arr[mid] ) return mid; else if ( key &lt; arr[mid]) binary_search(arr, low, mid - 1, key); else binary_search(arr, mid + 1, high, key); &#125; else return -1;&#125; 非递归版本：123456789101112131415int non_recursion_bs(int arr[], int low, int high, int key)&#123; int mid = 0; while (low &lt;= high) &#123; mid = ( low + high ) / 2; if ( key == arr[mid] ) return mid; else if ( key &lt; arr[mid] ) high = mid - 1; else low = mid + 1; &#125; return -1;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(排序算法)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（二）]]></title>
    <url>%2F2014%2F08%2F20%2F(%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[注：以下所有代码皆可以直接运行， 都已经测试过。 冒泡排序 想象就是很多泡泡，最大的泡泡每次浮到那个数组最后面 1234567891011121314void bubble_sort(int a[], int n)&#123; int i, j, temp; for (j = 0; j &lt; n - 1; j++) for (i = 0; i &lt; n - 1 - j; i++) &#123; if(a[i] &gt; a[i + 1]) &#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; &#125; &#125;&#125; 插入排序 想象手上有几张牌， 现在你抽了一张牌， 然后需要从手上最右边的牌开始比较，然后插入到相应位置 123456789101112131415161718192021void insertion_sort(int test_array[], size_t length)&#123; int i = 0, key = 0; for (size_t index = 1; index &lt; length; ++index) &#123; i = index - 1, key = test_array[index]; while (i &gt;= 0 &amp;&amp; key &lt; test_array[i]) &#123; test_array[i + 1] = test_array[i]; i = i - 1; &#125; test_array[i + 1] = key; &#125; for (size_t ii = 0; ii &lt; length; ++ii, ++test_array) &#123; cout &lt;&lt; *test_array &lt;&lt; endl; &#125;&#125; 归并排序 归并排序用了分治的思想，有很多算法在结构上是递归的：为了解决一个给定的问题，算法要一次或多次地递归调用其自身来解决相关的子问题。这些算法通常采用分治策略（divide-and-conquier）：将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。 分治模式在每一层递归上都有三个步骤： 分解（divide）：将原问题分解成一系列子问题； 解决（conquer）：递归地解各子问题。若子问题足够小，则直接求解； 合并：将子问题的结果合并成原问题的解。 下面是一个比较直白明了的归并c++实现（其实可以写成不用动态分配内存的，但是这里为了直白起见）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* * p: 左数组第一个元素下标 * q: 左数组最后一个元素下标 * r: 右数组最后一个元素下标 */void merge(int *array, int p, int q, int r)&#123; int n1, n2, i, j, k; int *left=NULL, *right=NULL; n1 = q-p+1; n2 = r-q; left = (int *)malloc(sizeof(int)*(n1)); right = (int *)malloc(sizeof(int)*(n2)); for(i=0; i&lt;n1; i++) &#123; left[i] = array[p+i]; &#125; for(j=0; j&lt;n2; j++) &#123; right[j] = array[q+1+j]; &#125; i = j = 0; k = p; while(i&lt;n1 &amp;&amp; j&lt;n2) &#123; if(left[i] &lt;= right[j]) &#123; array[k++] = left[i++]; &#125; else &#123; array[k++] = right[j++]; &#125; &#125; for(; i&lt;n1; i++) &#123; array[k++] = left[i]; &#125; for(; j&lt;n2; j++) &#123; array[k++] = right[j]; &#125; free(left); free(right); left = NULL; right = NULL;&#125; void merge_sort(int *array, int p, int r)&#123; int q; if(p &lt; r) &#123; q = (int)((p+r)/2); merge_sort(array, p, q); merge_sort(array, q+1, r); merge(array, p, q, r); &#125;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(排序算法)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（一）]]></title>
    <url>%2F2014%2F08%2F19%2F(%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[因为之前的笔记和书籍相关知识都是零零散散的， 没有一个汇总， 所以写了这篇博客。有些算法很简单，复杂度一眼都能看得出来， 几乎不需要记忆 ， 但是有些算法或者数据结构的操作的复杂度就不是一眼可以看得出来， 推导也是很费时间的， 所谓常识就是应该熟记于心且被认可的知识。 必须掌握的知识 常用算法的复杂度]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
</search>
